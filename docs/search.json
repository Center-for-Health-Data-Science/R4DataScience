[
  {
    "objectID": "solutions/solution_not_up.html",
    "href": "solutions/solution_not_up.html",
    "title": "Solution not up yet!",
    "section": "",
    "text": "Solutions will be available only after you’ve had a chance to work through the exercises on your own. If you’re unsure how to proceed, check the slides, cheat sheets, ask a peer, or reach out to a TA.\n\nEnjoy!"
  },
  {
    "objectID": "solutions/solution4_functions.html",
    "href": "solutions/solution4_functions.html",
    "title": "Exercise 4, Functions- Solutions",
    "section": "",
    "text": "Here we show the content inside solution4_functions.R. Remember, the file containing your outsourced functions needs to be an R script (.R), not a quarto document!\n\n\n\nmake_boxplot &lt;- function(df, plot_column){\n  \n  if (!is.numeric(df[[plot_column]])){\n    stop('The column to plot must be numcerial.')\n  }\n  \n  p &lt;- ggplot(df, aes(y = .data[[plot_column]])) +\n    geom_boxplot(fill = \"#03579A\") +\n    labs(title = paste(\"Boxplot of\", plot_column)) + \n    theme_bw()\n  \n  return(p)\n  \n}",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4, Functions - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3B.html",
    "href": "solutions/solution3B.html",
    "title": "Exercise 3 B - Solutions",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\n\n\nLoad data from the .rds file you created in Exercise 2.\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\nhead(diabetes_glucose)\n\n# A tibble: 6 × 12\n  ID    Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n  &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n1 9046  Male      34            84  24.7               93 Unknown 0       \n2 51676 Male      25            74  22.5              102 Unknown 0       \n3 60182 Male      50            80  34.5               98 Unknown 1       \n4 1665  Female    27            60  26.3               82 Never   0       \n5 56669 Male      35            84  35                 58 Smoker  1       \n6 53882 Female    31            78  43.3               59 Smoker  1       \n# ℹ 4 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 B - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3B.html#getting-started",
    "href": "solutions/solution3B.html#getting-started",
    "title": "Exercise 3 B - Solutions",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\n\n\nLoad data from the .rds file you created in Exercise 2.\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\nhead(diabetes_glucose)\n\n# A tibble: 6 × 12\n  ID    Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n  &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n1 9046  Male      34            84  24.7               93 Unknown 0       \n2 51676 Male      25            74  22.5              102 Unknown 0       \n3 60182 Male      50            80  34.5               98 Unknown 1       \n4 1665  Female    27            60  26.3               82 Never   0       \n5 56669 Male      35            84  35                 58 Smoker  1       \n6 53882 Female    31            78  43.3               59 Smoker  1       \n# ℹ 4 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 B - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3B.html#plotting---part-3-pca",
    "href": "solutions/solution3B.html#plotting---part-3-pca",
    "title": "Exercise 3 B - Solutions",
    "section": "Plotting - Part 3: PCA",
    "text": "Plotting - Part 3: PCA\nFor this exercise we will use this tutorial to make a principal component analysis (PCA). First, we perform some preprocessing to get our data into the right format.\n\nLet’s start by unnesting the OGTT data and using pivot wider so that each Glucose measurement time point gets its own column (again).\n\n\ndiabetes_glucose_unnest &lt;-  diabetes_glucose %&gt;% \n  unnest(OGTT) %&gt;% \n  pivot_wider(names_from = Measurement, \n              values_from = `Glucose (mmol/L)`, \n              names_prefix = \"Glucose_\")\n\ndiabetes_glucose_unnest\n\n# A tibble: 490 × 14\n   ID    Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n   &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n 1 9046  Male      34            84  24.7               93 Unknown 0       \n 2 51676 Male      25            74  22.5              102 Unknown 0       \n 3 60182 Male      50            80  34.5               98 Unknown 1       \n 4 1665  Female    27            60  26.3               82 Never   0       \n 5 56669 Male      35            84  35                 58 Smoker  1       \n 6 53882 Female    31            78  43.3               59 Smoker  1       \n 7 10434 Male      52            86  33.3               58 Never   1       \n 8 27419 Female    54            78  35.2               74 Former  1       \n 9 60491 Female    41            90  39.8               67 Smoker  1       \n10 12109 Female    36            82  30.8               81 Smoker  1       \n# ℹ 480 more rows\n# ℹ 6 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;,\n#   Glucose_0 &lt;dbl&gt;, Glucose_60 &lt;dbl&gt;, Glucose_120 &lt;dbl&gt;\n\n\n\nHave a look at your unnested diabetes data set. Can you use all the variables to perform PCA? Subset the dataset to only include the relevant variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nPCA can only be performed on numerical values. Extract these (except ID!) from the dataset. Numerical columns can easily be selected with the where(is.numeric) helper.\n\n\n\nExtract the numerical columns, including the OGTT measurements.\n\ndiabetes_glucose_numerical &lt;- diabetes_glucose_unnest %&gt;%\n  select(where(is.numeric))\n\ndiabetes_glucose_numerical\n\n# A tibble: 490 × 8\n     Age BloodPressure   BMI PhysicalActivity Serum_ca2 Glucose_0 Glucose_60\n   &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1    34            84  24.7               93       9.8      6.65       8.04\n 2    25            74  22.5              102       9.5      4.49       5.40\n 3    50            80  34.5               98       9.4     12.9       14.3 \n 4    27            60  26.3               82       9        5.76       6.52\n 5    35            84  35                 58       9.3     10.8       16.2 \n 6    31            78  43.3               59       9.6     11.1       12.8 \n 7    52            86  33.3               58       9.1     10.4       14.7 \n 8    54            78  35.2               74       9.3      6.79      10.1 \n 9    41            90  39.8               67       9.1      7.39      10.3 \n10    36            82  30.8               81       9.5     11.6       13.0 \n# ℹ 480 more rows\n# ℹ 1 more variable: Glucose_120 &lt;dbl&gt;\n\n\n\nPCA cannot handle NA’s in the dataset. Remove all rows with NA in any column in your numerical subset. Then, go back to the original unnested data diabetes_glucose_unnest (or what you have called it) and also here drop rows that have NAs in the numerical columns (so the same rows you dropped from the numeric subset).This is important because we want to use (categorical) columns present in the original data to later color the resulting PCA, so the two dataframes (original and only numeric columns) need to be aligned and contain the same rows.\n\n\ndiabetes_glucose_numerical &lt;- drop_na(diabetes_glucose_numerical)\nnrow(diabetes_glucose_numerical)\n\n[1] 488\n\n\nAlign original data.\n\ndiabetes_glucose_unnest &lt;- diabetes_glucose_unnest %&gt;%\n  drop_na(colnames(diabetes_glucose_numerical))\nnrow(diabetes_glucose_unnest)\n\n[1] 488\n\n\nNow our data is ready to make a PCA.\n\nCalculate the PCA by running prcomp on our prepared data (see the tutorial). Then, create a plot of the resulting PCA (also shown in tutorial).\n\n\nlibrary(ggfortify)\n\nWarning: pakke 'ggfortify' blev bygget under R version 4.2.3\n\npca_res &lt;- prcomp(diabetes_glucose_numerical, scale. = TRUE)\n\nautoplot(pca_res)\n\n\n\n\n\n\n\n\n\nColor your PCA plot and add loadings. Think about which variable you want to color by. Remember to refer to the dataset that has this variable (probably not your numeric subset!)\n\n\nautoplot(pca_res, data = diabetes_glucose_unnest, colour = 'Diabetes',\n         loadings = TRUE, loadings.colour = 'black',\n         loadings.label = TRUE, loadings.label.size = 3)\n\n\n\n\n\n\n\n\n\nAdd a ggplot theme and title to your plot and save it.\n\n\nautoplot(pca_res, data = diabetes_glucose_unnest, colour = \"Diabetes\",\n         loadings = TRUE, loadings.colour = \"grey30\", loadings.label.colour = \"black\",\n         loadings.label = TRUE, loadings.label.size = 3.5) + \n  theme_minimal() + \n  labs(title = \"PCA of Diabetes Dataset\")\n\n\n\n\n\n\n\nggsave('../figures/PCA_diabetes.png', width = 7, height = 5)\n\n\nCalculate the variance explained by each of the PC’s using the following formula:\n\n\\[\n\\text{Variance Explained} = \\frac{\\text{sdev}^2}{\\sum \\text{sdev}^2} \\times 100\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can access the standard deviation from the PCA object like this: pca_res$sdev.\n\n\n\n\nvariance_explained &lt;- ((pca_res$sdev^2) / sum(pca_res$sdev^2)) * 100\nvariance_explained\n\n[1] 46.70757453 15.34011234 12.49983700  8.74106790  7.52024687  5.14424345\n[7]  3.95709895  0.08981894\n\n\n\nCreate a two column data-frame with the names of the PC’s (PC1, PC2, ect) in one column and the variance explained by that PC in the other column.\n\n\ndf_variance_explained &lt;- tibble(PC = c(paste0('PC', 1:length(variance_explained))),\n                                variance_explained = variance_explained)\n\ndf_variance_explained\n\n# A tibble: 8 × 2\n  PC    variance_explained\n  &lt;chr&gt;              &lt;dbl&gt;\n1 PC1              46.7   \n2 PC2              15.3   \n3 PC3              12.5   \n4 PC4               8.74  \n5 PC5               7.52  \n6 PC6               5.14  \n7 PC7               3.96  \n8 PC8               0.0898\n\n\n\nNow create a bar plot (using geom_col), showing for each PC the amount of explained variance. This type of plot is called a scree plot.\n\n\ndf_variance_explained %&gt;% \n  ggplot(aes(x = PC, \n             y = variance_explained))+ \n  geom_col() + \n  labs(title = \"Varinace explained for each PC\", \n       y = \"Variance Explained\")\n\n\n\n\n\n\n\n\n\nLastly, render you quarto document and review the resulting html file.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 B - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3B.html#extra-exercises",
    "href": "solutions/solution3B.html#extra-exercises",
    "title": "Exercise 3 B - Solutions",
    "section": "Extra exercises",
    "text": "Extra exercises\ne1. The Oral Glucose Tolerance Test is used to diagnose diabetes so we are not surprised that it separates the dataset well. In this part, we will look at a PCA without the OGTT measurements and see how we fare. Omit the Glucose measurement columns, calculate a PCA and create the plot.\n\npca_no_gluc &lt;-diabetes_glucose_numerical %&gt;%\n  select(-Glucose_0,-Glucose_60,-Glucose_120) %&gt;%\n  prcomp(scale. = TRUE)\n\n\nautoplot(pca_no_gluc, data = diabetes_glucose_unnest, colour = \"Diabetes\",\n         loadings = TRUE, loadings.colour = \"grey30\", loadings.label.colour = \"black\",\n         loadings.label = TRUE, loadings.label.size = 3.5) + \n  theme_minimal() + \n  labs(title = \"PCA of Diabetes Dataset\")\n\n\n\n\n\n\n\n\nWithout the Glucose measurement data our strongest separating variables are BMI and Physical Activity.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 B - Solution"
    ]
  },
  {
    "objectID": "solutions/solution2.html",
    "href": "solutions/solution2.html",
    "title": "Exercise 2 - Solutions: Advanced Data Wrangling",
    "section": "",
    "text": "In this exercise you will do some more advance tidyverse operations such as pivoting and nesting.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 2 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution2.html#introduction",
    "href": "solutions/solution2.html#introduction",
    "title": "Exercise 2 - Solutions: Advanced Data Wrangling",
    "section": "",
    "text": "In this exercise you will do some more advance tidyverse operations such as pivoting and nesting.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 2 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution2.html#first-steps",
    "href": "solutions/solution2.html#first-steps",
    "title": "Exercise 2 - Solutions: Advanced Data Wrangling",
    "section": "First steps",
    "text": "First steps\n\nLoad packages.\n\n\nlibrary(tidyverse)\n\n\nLoad the joined diabetes data set you created in exercise 1 (e.g. “diabetes_join.xlsx”) and the glucose dataset df_glucose.xlsx from the data folder.\n\n\ndiabetes_join &lt;- readxl::read_excel('../out/diabetes_join.xlsx')\ndf_glucose &lt;- readxl::read_excel('../data/df_glucose.xlsx')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 2 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution2.html#wrangling",
    "href": "solutions/solution2.html#wrangling",
    "title": "Exercise 2 - Solutions: Advanced Data Wrangling",
    "section": "Wrangling",
    "text": "Wrangling\n\nHave a look at the glucose dataset. It has three columns with measurements from a Oral Glucose Tolerance Test where blood glucose is measured at fasting (Glucose_0), 1 hour/60 mins after glucose intake (Glucose_6), and 2 hours/120 mins after (Glucose_120). The last columns is an ID column. Change the data type of the ID column to factor in both diabetes_join and df_glucose.\n\n\nhead(df_glucose)\n\n# A tibble: 6 × 4\n  Glucose_0 Glucose_60 Glucose_120    ID\n      &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1      6.65       8.04       10.0   9046\n2      4.49       5.40        6.22 51676\n3      5.76       6.52        7.22  1665\n4      6.13       6.94        8.09 12095\n5      6.84       6.92        7.01 12175\n6      6.84       7.62        8.42  8213\n\n\n\ndf_glucose$ID &lt;- as.factor(df_glucose$ID)\ndiabetes_join$ID &lt;- as.factor(diabetes_join$ID)\n\n\nRestructure the glucose dataset into a long format. Name the column that describes which measurement the row refers to, i.e. Glucose_0, Glucose_60 or Glucose_120, Measurement. How many rows are there per ID? Does that make sense?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember the flow:\n\npivot_longer(cols = LIST_WITH_COLUMNS_TO_PIVOT,\n             names_to = \"NEW_COLUMN_CONTAINING_COLUMN_NAMES\",\n             values_to = \"NEW_COLUMN_CONTAINING_COLUMN_VALUES\")\n\nHave a look at slide 16 for a visual overview.\n\n\n\n\ndf_glucose_long &lt;- df_glucose %&gt;% \n  pivot_longer(cols = starts_with(\"Glucose\"),\n               names_to = \"Measurement\",\n               values_to = \"Glucose (mmol/L)\"\n               )\n\nhead(df_glucose_long)\n\n# A tibble: 6 × 3\n  ID    Measurement `Glucose (mmol/L)`\n  &lt;fct&gt; &lt;chr&gt;                    &lt;dbl&gt;\n1 9046  Glucose_0                 6.65\n2 9046  Glucose_60                8.04\n3 9046  Glucose_120              10.0 \n4 51676 Glucose_0                 4.49\n5 51676 Glucose_60                5.40\n6 51676 Glucose_120               6.22\n\n\nThere are three rows for each ID, corresponding to the three glucose measurements\n\ndf_glucose_long %&gt;%\n  count(ID) %&gt;%\n  head()\n\n# A tibble: 6 × 2\n  ID        n\n  &lt;fct&gt; &lt;int&gt;\n1 129       3\n2 210       3\n3 491       3\n4 530       3\n5 621       3\n6 712       3\n\n\n\nIn your long format dataframe you should have one column that described which measurement the row refers to, i.e. Glucose_0, Glucose_60 or Glucose_120. Transform this column so that you only have the numerical part, i.e. only 0, 60 or 120. Then change the data type of that column to factor. Check the order of the factor levels and if necessary change them to the proper order.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe stringr packages is a part of tidyverse and has many functions for manipulating strings. Find a function that can split the string so you can extract the numbers on the other side of the underscore.\nHave a look at the help for factors ?factors to see how to influence the levels.\n\n\n\n\ndf_glucose_long &lt;- df_glucose_long %&gt;% \n  mutate(Measurement = str_split_i(Measurement, '_', 2) %&gt;% as.factor())\n\nhead(df_glucose_long)\n\n# A tibble: 6 × 3\n  ID    Measurement `Glucose (mmol/L)`\n  &lt;fct&gt; &lt;fct&gt;                    &lt;dbl&gt;\n1 9046  0                         6.65\n2 9046  60                        8.04\n3 9046  120                      10.0 \n4 51676 0                         4.49\n5 51676 60                        5.40\n6 51676 120                       6.22\n\n\nCheck factor levels:\n\nlevels(df_glucose_long$Measurement)\n\n[1] \"0\"   \"120\" \"60\" \n\n\nAdjust levels to proper order:\n\ndf_glucose_long$Measurement &lt;- factor(df_glucose_long$Measurement, levels = c('0', '60','120'))\n\n\nMerge the glucose dataset with the joined diabetes dataset.\n\n\ndiabetes_glucose &lt;- diabetes_join %&gt;% \n  left_join(df_glucose_long, by = 'ID')\n\nhead(diabetes_glucose)\n\n# A tibble: 6 × 13\n  ID    Sex     Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n  &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n1 9046  Male     34            84  24.7               93 Unknown 0       \n2 9046  Male     34            84  24.7               93 Unknown 0       \n3 9046  Male     34            84  24.7               93 Unknown 0       \n4 51676 Male     25            74  22.5              102 Unknown 0       \n5 51676 Male     25            74  22.5              102 Unknown 0       \n6 51676 Male     25            74  22.5              102 Unknown 0       \n# ℹ 5 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;,\n#   Measurement &lt;fct&gt;, `Glucose (mmol/L)` &lt;dbl&gt;\n\n\n\nPull the glucose measurements from your favorite ID.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFirst filter for your favorite ID and then pull the columns.\n\n\n\n\ndiabetes_glucose %&gt;% \n  filter(ID == 9046) %&gt;% \n  pull(Measurement,`Glucose (mmol/L)`)\n\n  6.652593325614 8.04416787019778  10.016298115626 \n               0               60              120 \nLevels: 0 60 120\n\n\n\nCalculate the mean glucose measure for each measurement timepoint.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use group_by(), and summarise().\n\n\n\n\ndiabetes_glucose %&gt;%\n  group_by(Measurement) %&gt;%\n  summarise(mean = mean(`Glucose (mmol/L)`))\n\n# A tibble: 3 × 2\n  Measurement  mean\n  &lt;fct&gt;       &lt;dbl&gt;\n1 0            8.06\n2 60           9.73\n3 120         11.1 \n\n\n\nCalculate mean and standard deviation for all numeric columns.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use summarise() and across(), selecting numeric columns.\n\n\n\n\ndiabetes_glucose %&gt;%\n  summarise(across(where(is.numeric), list(mean=mean, sd=sd), \n                   .names = \"{.col}-{.fn}\"))\n\n# A tibble: 1 × 12\n  `Age-mean` `Age-sd` `BloodPressure-mean` `BloodPressure-sd` `BMI-mean`\n       &lt;dbl&gt;    &lt;dbl&gt;                &lt;dbl&gt;              &lt;dbl&gt;      &lt;dbl&gt;\n1         NA       NA                 72.7               12.9       30.2\n# ℹ 7 more variables: `BMI-sd` &lt;dbl&gt;, `PhysicalActivity-mean` &lt;dbl&gt;,\n#   `PhysicalActivity-sd` &lt;dbl&gt;, `Serum_ca2-mean` &lt;dbl&gt;, `Serum_ca2-sd` &lt;dbl&gt;,\n#   `Glucose (mmol/L)-mean` &lt;dbl&gt;, `Glucose (mmol/L)-sd` &lt;dbl&gt;\n\n\n\nNest the glucose measurements and values such that there is only one row per ID and call the nested column OGTT (Oral Glucose Tolerance Test). Display the resulting tibble to confirm that you have succeeded.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember the flow:\n\ngroup_by() %&gt;% \n  nest() %&gt;% \n  ungroup()\n\n\n\n\n\ndiabetes_glucose &lt;- diabetes_glucose %&gt;% \n  group_by(ID) %&gt;% \n  nest(OGTT = c(Measurement, `Glucose (mmol/L)`)) %&gt;% \n  ungroup()\n  \n#relocate the new nested column to after BMI so we can actually see it\nhead(relocate(diabetes_glucose, OGTT, .after = BMI))\n\n# A tibble: 6 × 12\n  ID    Sex      Age BloodPressure   BMI OGTT     PhysicalActivity Smoker \n  &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;              &lt;dbl&gt; &lt;chr&gt;  \n1 9046  Male      34            84  24.7 &lt;tibble&gt;               93 Unknown\n2 51676 Male      25            74  22.5 &lt;tibble&gt;              102 Unknown\n3 60182 Male      50            80  34.5 &lt;tibble&gt;               98 Unknown\n4 1665  Female    27            60  26.3 &lt;tibble&gt;               82 Never  \n5 56669 Male      35            84  35   &lt;tibble&gt;               58 Smoker \n6 53882 Female    31            78  43.3 &lt;tibble&gt;               59 Smoker \n# ℹ 4 more variables: Diabetes &lt;chr&gt;, Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;,\n#   Work &lt;chr&gt;\n\n\n\nExport the final dataset. Since the dataset is nested, you cannot export it as an excel file. Export the dataset as an .rds file. Have a guess at what the function is called.\n\n\nwrite_rds(diabetes_glucose, '../out/diabetes_glucose.rds')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 2 - Solution"
    ]
  },
  {
    "objectID": "slides/Quarto_example.html",
    "href": "slides/Quarto_example.html",
    "title": "R for Data Science - How to Quarto",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "slides/Quarto_example.html#load-packages",
    "href": "slides/Quarto_example.html#load-packages",
    "title": "R for Data Science - How to Quarto",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "slides/Quarto_example.html#load-data",
    "href": "slides/Quarto_example.html#load-data",
    "title": "R for Data Science - How to Quarto",
    "section": "Load Data",
    "text": "Load Data\n\ndiabetes &lt;- read_excel('../data/diabetes_clinical_toy_messy.xlsx')"
  },
  {
    "objectID": "slides/Quarto_example.html#inspect-data",
    "href": "slides/Quarto_example.html#inspect-data",
    "title": "R for Data Science - How to Quarto",
    "section": "Inspect Data",
    "text": "Inspect Data\nCheck dimensions of data\n\ndim(diabetes)\n\n[1] 532   9\n\n\nCheck structure of data\n\nstr(diabetes)\n\ntibble [532 × 9] (S3: tbl_df/tbl/data.frame)\n $ ID              : num [1:532] 9046 51676 31112 60182 1665 ...\n $ Sex             : chr [1:532] \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ Age             : num [1:532] 34 25 30 50 27 35 31 52 54 41 ...\n $ BloodPressure   : num [1:532] 84 74 0 80 60 84 78 86 78 90 ...\n $ BMI             : num [1:532] 24.7 22.5 32.3 34.5 26.3 35 43.3 33.3 35.2 39.8 ...\n $ PhysicalActivity: num [1:532] 93 102 75 98 82 58 59 58 74 67 ...\n $ Smoker          : chr [1:532] \"Unknown\" \"Unknown\" \"Former\" \"Unknown\" ...\n $ Diabetes        : num [1:532] 0 0 1 1 0 1 1 1 1 1 ...\n $ Serum_ca2       : num [1:532] 9.8 9.5 9.3 9.4 9 9.3 9.6 9.1 9.3 9.1 ...\n\n\nCheck for NA’s in each column\n\ncolSums(is.na(diabetes))\n\n              ID              Sex              Age    BloodPressure \n               0                0                3                0 \n             BMI PhysicalActivity           Smoker         Diabetes \n               3                0                0                0 \n       Serum_ca2 \n               0"
  },
  {
    "objectID": "slides/Quarto_example.html#exploratory-data-analysis",
    "href": "slides/Quarto_example.html#exploratory-data-analysis",
    "title": "R for Data Science - How to Quarto",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nPlot distribution of BMI\n\ndiabetes %&gt;% \n  ggplot(aes(x = BMI)) + \n  geom_histogram(bins = 10)\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_bin()`)."
  },
  {
    "objectID": "presentations/presentation6.html",
    "href": "presentations/presentation6.html",
    "title": "Presentation 6: ???",
    "section": "",
    "text": "print('Hello World')\n\n[1] \"Hello World\""
  },
  {
    "objectID": "presentations/presentation4_main_script.html",
    "href": "presentations/presentation4_main_script.html",
    "title": "Presentation 4: Scripting in R",
    "section": "",
    "text": "In this section we will learn more about flow control and how to make more complex code constructs in R.\nlibrary(tidyverse)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#if-else-statments",
    "href": "presentations/presentation4_main_script.html#if-else-statments",
    "title": "Presentation 4: Scripting in R",
    "section": "If-else statments",
    "text": "If-else statments\nIf-else statements are essential if you want your program to do different things depending on a condition. Here we see how to code them in R.\nFirst define some variables.\n\nnum1 &lt;- 8\nnum2 &lt;- 5\n\nNow that we have variables, we can test logical statement between them: Is num1 larger than num2? The result of a logical statement is always one of either TRUE or FALSE:\n\nnum1 &gt; num2\n\n[1] TRUE\n\n\nIs num1 smaller than num2?\n\nnum1 &lt; num2\n\n[1] FALSE\n\n\nWe use logical statements inside an if statement to define a condition.\n\nif (num1 &gt; num2){\n  statement &lt;- paste(num1, 'is larger than', num2)\n}\n\nprint(statement)\n\n[1] \"8 is larger than 5\"\n\n\nWe can add an else if to test multiple conditions. else is what applies when all previous checks where FALSE.\nNow we have three possible outcomes:\n\n#try with different values for num2\nnum2 &lt;- 10\n\nif (num1 &gt; num2){\n  statement &lt;- paste(num1, 'is larger than', num2)\n} else if (num1 &lt; num2) {\n  statement &lt;- paste(num1, 'is smaller than', num2)\n} else {\n  statement &lt;- paste(num1, 'is equal to', num2)\n} \n\nprint(statement)\n\n[1] \"8 is smaller than 10\"",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#for-loops",
    "href": "presentations/presentation4_main_script.html#for-loops",
    "title": "Presentation 4: Scripting in R",
    "section": "For-loops",
    "text": "For-loops\n\nDefining a for loop\nMany functions in R are already vectorized, i.e. \n\ndf &lt;- tibble(num1 = 1:10)\ndf\n\n# A tibble: 10 × 1\n    num1\n   &lt;int&gt;\n 1     1\n 2     2\n 3     3\n 4     4\n 5     5\n 6     6\n 7     7\n 8     8\n 9     9\n10    10\n\ndf$num2 &lt;- df$num1 * 10\ndf\n\n# A tibble: 10 × 2\n    num1  num2\n   &lt;int&gt; &lt;dbl&gt;\n 1     1    10\n 2     2    20\n 3     3    30\n 4     4    40\n 5     5    50\n 6     6    60\n 7     7    70\n 8     8    80\n 9     9    90\n10    10   100\n\n\nThe above code applies * 10 to each element of column num1 without us having to invoke a loop.\nBut sometimes we want to iterate over the elements manually because the situation requires it. For that case we can use a for loop.\nWe first define a list containing both numeric and character elements.\n\nlist1 &lt;- list(1, 2, 6, 3, 2, 'hello', 'world', 'yes', 7, 8, 12, 15)\n\nTo loop through list1, we define a loop variable (here called element), which takes the value of each item in the vector, one at a time.\n\nfor (element in list1) {\n  print(element)\n}\n\n[1] 1\n[1] 2\n[1] 6\n[1] 3\n[1] 2\n[1] \"hello\"\n[1] \"world\"\n[1] \"yes\"\n[1] 7\n[1] 8\n[1] 12\n[1] 15\n\n\nThe loop variable name is arbitrary - you can call it anything. For example, we can use THIS_VARIABLE and get the same result. Point is, it does not matter what you call the variable, just avoid overwriting an important variable of your script.\n\nfor (THIS_VARIABLE in list1) {\n  print(THIS_VARIABLE)\n}\n\n[1] 1\n[1] 2\n[1] 6\n[1] 3\n[1] 2\n[1] \"hello\"\n[1] \"world\"\n[1] \"yes\"\n[1] 7\n[1] 8\n[1] 12\n[1] 15\n\n\nAfter you loop through a vector or a list, the value of the loop variable is always the last element of your vector. The variable is hence a global variable.\n\nTHIS_VARIABLE\n\n[1] 15\n\n\n\n\nLoop control\nThere are two loop control statements we can use to\n\njump to the next iteration: next\nend the loop before finishing: break\n\n\n#example for next\n\nfor (element in list1) {\n  if(element == 'hello'){\n    next\n  }\n  \n  print(element)\n}\n\n[1] 1\n[1] 2\n[1] 6\n[1] 3\n[1] 2\n[1] \"world\"\n[1] \"yes\"\n[1] 7\n[1] 8\n[1] 12\n[1] 15\n\n\n\n#example for break\nfor (element in list1) {\n  if(element == 'hello'){\n    break\n  }\n  \n  print(element)\n}\n\n[1] 1\n[1] 2\n[1] 6\n[1] 3\n[1] 2\n\n\n\n\nWhich data constructs are iterable in R?\nVectors:\n\nmy_vector &lt;- c(1, 2, 3, 4, 5)\nfor (elem in my_vector) {\n  print(elem)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nLists:\n\nmy_list &lt;- list(a = 1, b = \"Hello\", c = TRUE)\nfor (elem in my_list) {\n  print(elem)\n}\n\n[1] 1\n[1] \"Hello\"\n[1] TRUE\n\n\nDataframes and tibbles:\n\nmy_df &lt;- data.frame(A = 1:3, B = c(\"X\", \"Y\", \"Z\"))\nmy_df\n\n  A B\n1 1 X\n2 2 Y\n3 3 Z\n\n#column-wise\n\nfor (col in my_df) {\n  print(col)\n}\n\n[1] 1 2 3\n[1] \"X\" \"Y\" \"Z\"\n\n\nFor row-wise iteration you can for example use the row index:\n\nfor (i in 1:nrow(my_df)) {\n  print(i)\n  #print row i\n  print(my_df[i,])\n}\n\n[1] 1\n  A B\n1 1 X\n[1] 2\n  A B\n2 2 Y\n[1] 3\n  A B\n3 3 Z\n\n\n\n\nIf-else in loops\nWe can now use what we have learned to loop through our list1 and multiply all numeric values with 10:\n\n#to remember contents:\nlist1\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 3\n\n[[5]]\n[1] 2\n\n[[6]]\n[1] \"hello\"\n\n[[7]]\n[1] \"world\"\n\n[[8]]\n[1] \"yes\"\n\n[[9]]\n[1] 7\n\n[[10]]\n[1] 8\n\n[[11]]\n[1] 12\n\n[[12]]\n[1] 15\n\n\n\nfor (element in list1) {\n  if (is.numeric(element)){\n    statement &lt;- paste(element, 'times 10 is', element*10)\n  } else {\n    statement &lt;- paste(element, 'is not a number!')\n  }\n  print(statement)\n}\n\n[1] \"1 times 10 is 10\"\n[1] \"2 times 10 is 20\"\n[1] \"6 times 10 is 60\"\n[1] \"3 times 10 is 30\"\n[1] \"2 times 10 is 20\"\n[1] \"hello is not a number!\"\n[1] \"world is not a number!\"\n[1] \"yes is not a number!\"\n[1] \"7 times 10 is 70\"\n[1] \"8 times 10 is 80\"\n[1] \"12 times 10 is 120\"\n[1] \"15 times 10 is 150\"\n\n\nNote: that this does not work with a vector, i.e. vec &lt;- c(1,2,'hello') because vectors can only contain one data type so all elements of vec are characters.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#user-defined-functions",
    "href": "presentations/presentation4_main_script.html#user-defined-functions",
    "title": "Presentation 4: Scripting in R",
    "section": "User defined Functions",
    "text": "User defined Functions\nUser defined functions help us to re-use and structure our code.\nWe will use BMI calculation as an example for this part.\n\n#measurements of one individual\n\nweight_kg &lt;- 70\nheight_m &lt;- 1.80\n\nWe calculate BMI with this formula:\n\nbmi &lt;- weight_kg/height_m^2\nbmi\n\n[1] 21.60494\n\n\nIf we plan to calculate BMI for multiple individuals it is convenient to write the calculation into a function.\n\nFunction name: calculate_bmi.\nFunction parameters: weight_kg and height_m.\nThe return value: bmi.\n\nThe return statement specifies the value that the function will return when called.\n\ncalculate_bmi &lt;- function(weight_kg, height_m){\n  \n  bmi &lt;- weight_kg/height_m^2\n  \n  return(bmi)\n  \n}\n\nWe can now call the function on our previously defined variables.\n\ncalculate_bmi(weight_kg = weight_kg, \n              height_m = height_m)\n\n[1] 21.60494\n\n\nWe can also pass numbers directly to the function.\n\ncalculate_bmi(weight_kg = 100, \n              height_m = 1.90)\n\n[1] 27.70083\n\n\nArgument Order in Function Calls\nIf we specify the parameter names, the order can be changed.\n\ncalculate_bmi(height_m = 1.90, \n              weight_kg = 100)\n\n[1] 27.70083\n\n\nIf we do not specify the parameter names, the arguments will be matched according to the position - so be careful with this.\n\ncalculate_bmi(1.90, \n              100)\n\n[1] 0.00019",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#combining-function-call-with-if-statement",
    "href": "presentations/presentation4_main_script.html#combining-function-call-with-if-statement",
    "title": "Presentation 4: Scripting in R",
    "section": "Combining function call with if-statement",
    "text": "Combining function call with if-statement\nWe can combine user-defined functions with if-else statements, so that the if-else will decide whether we execute the function or not.\n\n#measurements of one individual\nage &lt;- 45\nweight_kg &lt;- 85\nheight_m &lt;- 1.75\n\nFpr some BMI should only be calculated for individuals over the age of 18.\n\nif (age &gt;= 18){\n  calculate_bmi(weight_kg, height_m)\n}\n\n[1] 27.7551",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#combining-function-call-with-for-loops",
    "href": "presentations/presentation4_main_script.html#combining-function-call-with-for-loops",
    "title": "Presentation 4: Scripting in R",
    "section": "Combining function call with for-loops",
    "text": "Combining function call with for-loops\nOr we can choose to execute our function once for every element of an iterable, e.g. every row in a dataframe:\n\ndf &lt;- data.frame(row.names = 1:5, \n                 age = c(45, 16, 31, 56, 19), \n                 weight_kg = c(85, 65, 100, 45, 76), \n                 height_m = c(1.75, 1.45, 1.95, 1.51, 1.89))\n\ndf\n\n  age weight_kg height_m\n1  45        85     1.75\n2  16        65     1.45\n3  31       100     1.95\n4  56        45     1.51\n5  19        76     1.89\n\n\nPrint ID, weight, and height of all individuals.\n\nfor (id in rownames(df)){\n  \n  weight &lt;- df[id, 'weight_kg']\n  \n  height &lt;- df[id, 'height_m']\n  \n  print(c(id, weight, height))\n  \n}\n\n[1] \"1\"    \"85\"   \"1.75\"\n[1] \"2\"    \"65\"   \"1.45\"\n[1] \"3\"    \"100\"  \"1.95\"\n[1] \"4\"    \"45\"   \"1.51\"\n[1] \"5\"    \"76\"   \"1.89\"\n\n\nCall function to calculate BMI for all individuals.\n\nfor (id in rownames(df)) {\n  \n  weight &lt;- df[id, 'weight_kg']\n  \n  height &lt;- df[id, 'height_m']\n  \n  bmi &lt;- calculate_bmi(weight, height)\n  \n  print(c(id, bmi))\n  \n}\n\n[1] \"1\"                \"27.7551020408163\"\n[1] \"2\"                \"30.9155766944114\"\n[1] \"3\"                \"26.2984878369494\"\n[1] \"4\"                \"19.7359764922591\"\n[1] \"5\"                \"21.2760001119789\"\n\n\n\nCombination of function call, if-statement and for-loops.\nPrint BMI for individuals that are 18 years old or older.\n\nfor (id in rownames(df)) {\n  \n  if (df[id, 'age'] &gt;= 18) {\n    \n    weight &lt;- df[id, 'weight_kg']\n  \n    height &lt;- df[id, 'height_m']\n    \n    bmi &lt;- calculate_bmi(weight, height)\n    \n    print(c(id, bmi))\n\n  } else {\n    \n    print(paste(id, 'is under 18.'))\n    \n  }\n  \n}\n\n[1] \"1\"                \"27.7551020408163\"\n[1] \"2 is under 18.\"\n[1] \"3\"                \"26.2984878369494\"\n[1] \"4\"                \"19.7359764922591\"\n[1] \"5\"                \"21.2760001119789\"\n\n\nAdd BMI to the data frame.\n\nfor (id in rownames(df)){\n  \n  if (df[id, 'age'] &gt;= 18) {\n    \n    weight &lt;- df[id, 'weight_kg']\n  \n    height &lt;- df[id, 'height_m']\n    \n    bmi &lt;- calculate_bmi(weight, height)\n\n  } else {\n    \n    bmi &lt;- NA\n    \n  }\n  \n  df[id, 'bmi'] &lt;- bmi\n  \n}\n\nHave a look at the data frame.\n\ndf\n\n  age weight_kg height_m      bmi\n1  45        85     1.75 27.75510\n2  16        65     1.45       NA\n3  31       100     1.95 26.29849\n4  56        45     1.51 19.73598\n5  19        76     1.89 21.27600",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#error-handling-in-user-defined-functions",
    "href": "presentations/presentation4_main_script.html#error-handling-in-user-defined-functions",
    "title": "Presentation 4: Scripting in R",
    "section": "Error handling in user-defined functions",
    "text": "Error handling in user-defined functions\nCurrently our BMI function accepts all kinds of inputs. However, what happens if we give a negative weight?\n\ncalculate_bmi(weight_kg = -50, height_m = 1.80)\n\n[1] -15.4321\n\n\nWe should require that both weight and height need to be positive values:\n\ncalculate_bmi_2 &lt;- function(weight_kg, height_m) {\n  \n  # Check if weight and height are numeric\n  if (!is.numeric(weight_kg) | !is.numeric(height_m)) {\n    stop(\"Both weight_kg and height_m must be numeric values.\")\n  }\n  \n  # Check if weight and height are positive\n  if (weight_kg &lt;= 0) {\n    stop(\"Weight must be a positive value.\")\n  }\n  if (height_m &lt;= 0) {\n    stop(\"Height must be a positive value.\")\n  }\n  \n  # Calculate BMI\n  bmi &lt;- weight_kg / height_m^2\n  \n  # Check if BMI is within a reasonable range\n  if (bmi &lt; 10 | bmi &gt; 60) {\n    warning(\"The calculated BMI is outside the normal range. Please check your input values.\")\n  }\n  \n  return(bmi)\n  \n}\n\nWhen we try to run calculate_bmi_2 with a negative weight we now receive an error:\n\ncalculate_bmi_2(weight_kg = -50, height_m = 1.80)\n\nWe also added a check whether the calculated BMI is within the normal range:\n\ncalculate_bmi_2(weight_kg = 25, height_m = 1.80)\n\nWarning in calculate_bmi_2(weight_kg = 25, height_m = 1.8): The calculated BMI\nis outside the normal range. Please check your input values.\n\n\n[1] 7.716049\n\n\nRunning calculate_bmi_2 with appropriate inputs:\n\ncalculate_bmi_2(weight_kg = 75, height_m = 1.80)\n\n[1] 23.14815",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#out-sourcing-functions-to-an-rscript-you-source",
    "href": "presentations/presentation4_main_script.html#out-sourcing-functions-to-an-rscript-you-source",
    "title": "Presentation 4: Scripting in R",
    "section": "Out-sourcing functions to an Rscript you source",
    "text": "Out-sourcing functions to an Rscript you source\nIt is cleaner to collect all your functions in one place, and perhaps that place should not be your analysis script. You can instead save your functions in a separate R script and source it inside your analysis script to have access to all your functions without them cluttering your workflow.\nWe have create a file named presentation4_functions.R and copied our two function definitions for calculate_bmi and calculate_bmi_2 into it.\nNow we remove our function definitions from the global environment to demonstrate how to source them from an external file.\n\nrm(list = \"calculate_bmi\", \"calculate_bmi_2\")\n\nBy sourcing a script, all global variables (including functions) in that script will be loaded and appear in the Global environment in the top left corner. Here we source the functions.R script. Check the environment to confirm that the two functions appeared.\n\nsource('./presentation4_functions.R')\n\nAfter we sourced the functions script the calculate_bmi function can be used just like if it was defined in the main script. If you work on a larger project and write multiple functions, it is best practice to have a function script and source it in your main script.\n\ncalculate_bmi_2(weight_kg = 67, \n              height_m = 1.70)\n\n[1] 23.18339\n\n\nYou can also use mapply as an alternative to calling the function in a for-loop:\n\nmapply(FUN = calculate_bmi_2, \n       weight_kg = df$weight_kg, \n       height_m = df$height_m)\n\n[1] 27.75510 30.91558 26.29849 19.73598 21.27600",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation3.html",
    "href": "presentations/presentation3.html",
    "title": "Presentation 3 - Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "In exercises 3A and B you will a deeper look at the diabetes data. To prepare for that, we will hear learn some extra ggplot tricks!",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "presentations/presentation3.html#load-packages",
    "href": "presentations/presentation3.html#load-packages",
    "title": "Presentation 3 - Exploratory Data Analysis (EDA)",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(readxl)\nlibrary(tidyverse)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "presentations/presentation3.html#load-data",
    "href": "presentations/presentation3.html#load-data",
    "title": "Presentation 3 - Exploratory Data Analysis (EDA)",
    "section": "Load data",
    "text": "Load data\n\ndf_sales &lt;- read_excel('../out/sales_data_2.xlsx')\ndf_sales\n\n# A tibble: 10 × 12\n      ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n 1     1 Alice      25 Female        100        110        120        100 happy\n 2     2 Bob        30 Male          200        210        220        230 happy\n 3     3 Charlie    22 Male          150        160        170        200 happy\n 4     4 Sophie     35 Female        300        320        340        250 happy\n 5     5 Eve        28 Female        250        240        250        270 happy\n 6     6 Frank      NA Male           NA        260        270        280 happy\n 7     7 Grace      40 Female        400        420        430        450 happy\n 8     8 Hannah     29 Female        500        510         NA        500 happy\n 9     9 Ian        21 Male          450        460        470        480 happy\n10    10 Jack       33 Male          300        310        320        290 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "presentations/presentation3.html#ggplot-recap",
    "href": "presentations/presentation3.html#ggplot-recap",
    "title": "Presentation 3 - Exploratory Data Analysis (EDA)",
    "section": "ggplot recap",
    "text": "ggplot recap\nWe will not go into much detail here since this section mostly serves as a recap of the ggplot material covered in the previous course, From Excel to R.\nThe creed of ggplot is summarized is that every information that should be put into the plot must be in a column. There is one column that describes the x-axis and one for the y-axis, and one for each additional aesthetic like color, size, shape, ect.\n\nggplot(df_sales, aes(x = Name, y = sales_2022, color = Sex)) +\n  geom_point()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nThe long format is ggplot’s best friend\nIt follows that if I need to plot all sales data, I will need to change the dataframe’s format such that all data points referring to sales are in the same column. As shown in pres 2 we do that with pivot_longer:\n\nsales_long &lt;- df_sales %&gt;%\n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"sales_year\",\n               values_to = \"sales_value\")\nsales_long\n\n# A tibble: 40 × 10\n      ID Name      Age Sex    mood  raise group     City  sales_year sales_value\n   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1     1 Alice      25 Female happy no    young_fe… Miami sales_2020         100\n 2     1 Alice      25 Female happy no    young_fe… Miami sales_2021         110\n 3     1 Alice      25 Female happy no    young_fe… Miami sales_2022         120\n 4     1 Alice      25 Female happy no    young_fe… Miami sales_2023         100\n 5     2 Bob        30 Male   happy yes   mature_m… Miami sales_2020         200\n 6     2 Bob        30 Male   happy yes   mature_m… Miami sales_2021         210\n 7     2 Bob        30 Male   happy yes   mature_m… Miami sales_2022         220\n 8     2 Bob        30 Male   happy yes   mature_m… Miami sales_2023         230\n 9     3 Charlie    22 Male   happy yes   young_ma… LA    sales_2020         150\n10     3 Charlie    22 Male   happy yes   young_ma… LA    sales_2021         160\n# ℹ 30 more rows\n\n\n\nggplot(sales_long, aes(x = Name, y = sales_value, color = Sex)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nYou can pipe into ggplot\nYou know what sucks? Having 10 million dataframes with very similar names in your environment. If you you don’t need to use your long format dataframe for anything else, instead of saving it and then plugging it into ggplot, you can pipe directly into ggplot:\n\ndf_sales %&gt;%\n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"sales_year\",\n               values_to = \"sales_value\") %&gt;%\n  #we omit the dataframe to plot because that is being piped into ggplot\n  #remember that different plot layers are still combined with '+'\n  ggplot(aes(x = Name, y = sales_value, color = Sex)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nPlotting several dataframes\nSometimes we would like to add more information to a plot. Consider the one we just made above. It shows 3 or 4 dots for each amployee, which the 3 or 4 different years we have information for. I can now calculate a mean across the 4 years per employee:\n\nsales_mean &lt;- sales_long %&gt;%\n  group_by(Name) %&gt;%\n  summarise(mean = mean(sales_value, na.rm = T))\n\nsales_mean\n\n# A tibble: 10 × 2\n   Name     mean\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 Alice    108.\n 2 Bob      215 \n 3 Charlie  170 \n 4 Eve      252.\n 5 Frank    270 \n 6 Grace    425 \n 7 Hannah   503.\n 8 Ian      465 \n 9 Jack     305 \n10 Sophie   302.\n\n\nAnd I would like to add it to the plot:\n\n#copy pasta code above\ndf_sales %&gt;%\n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"sales_year\",\n               values_to = \"sales_value\") %&gt;%\n  #we omit the dataframe to plot because that is being piped into ggplot\n  #remember that different plot layers are still combined with '+'\n  ggplot(aes(x = Name, y = sales_value, color = Sex)) +\n  geom_point() +\n  #add mean data by switching the dataframe!\n  #I need to specify a color aesthetic because there is no Sex column in sales_mean\n  geom_point(data = sales_mean, aes(x = Name, y = mean), color = 'black')\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nPlots are objects\nggplot plots are objects like any other R object and they can therefore be stored in a variable and displayed by invoking the variable’s name:\n\nawesome_plot &lt;- df_sales %&gt;%\n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"sales_year\",\n               values_to = \"sales_value\") %&gt;%\n  #we omit the dataframe to plot because that is being piped into ggplot\n  #remember that different plot layers are still combined with '+'\n  ggplot(aes(x = Name, y = sales_value, color = Sex)) +\n  geom_point() +\n  #add mean data by switching the dataframe!\n  #I need to specify a color aesthetic because there is no Sex column in sales_mean\n  geom_point(data = sales_mean, aes(x = Name, y = mean), color = 'black')\n\nawesome_plot\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIf R is every being pesky about showing you plots (e.g. if you want to display them in a loop) wrapping print() around the plot name usually helps:\n\nprint(awesome_plot)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nAliasing column names\nLastly, we’re going to show you how to alias a column name. Have you noticed that we always need to specify the literal name of the column we want to plot? What if we want to give the column name in a variable?\n\nplot_this &lt;- 'Name'\n\nggplot(df_sales, aes(x = plot_this, y = sales_2022, color = Sex)) +\n  geom_point()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nCertainly not the expected outcome! We can see that ggplot didn’t evaluate plot_this to the name of the actual column, Name. We’ll have to do it this way:\n\nplot_this &lt;- 'Name'\n\nggplot(df_sales, aes(x = .data[[plot_this]], y = sales_2022, color = Sex)) +\n  geom_point()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWe hear you say ‘But that is cumbersome!’. Unfortunately we’re neither the developers nor maintainers of ggplot so we all suffer together.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "presentations/presentation1.html",
    "href": "presentations/presentation1.html",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "",
    "text": "In this section we will look at some differences between base R and tidyverse and also learn how to prepare a clean dataset.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#load-packages",
    "href": "presentations/presentation1.html#load-packages",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Load Packages",
    "text": "Load Packages\n\nlibrary(tidyverse)\nlibrary(ggforce)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#load-dataset",
    "href": "presentations/presentation1.html#load-dataset",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Load Dataset",
    "text": "Load Dataset\nHere we load a dataframe that contains sales data for employees (in thousands DKK) from 2020 to 2023. We load the data as df_baseR which we will use to demonstrate base R commands. A copy of the same dataframe, df_tidyverse, is used to demonstrate tidyverse commands.\n\ndf_baseR &lt;- readxl::read_excel('../data/df_sales_1.xlsx') %&gt;% as.data.frame()\ndf_tidyverse &lt;- readxl::read_excel('../data/df_sales_1.xlsx') %&gt;% as_tibble()\n\nTable format in baseR is called data.frame. Have a look at the object in the terminal. It is very simple.\n\nclass(df_baseR)\n\n[1] \"data.frame\"\n\n\nTable format in tidyverse is called tibble. Have a look at the object in the terminal. The dimensions of the tibble is provided together with the classes of each column.\n\nclass(df_tidyverse)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#accessing-and-manipulating-data-with-base-r-and-tidyverse",
    "href": "presentations/presentation1.html#accessing-and-manipulating-data-with-base-r-and-tidyverse",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Accessing and manipulating Data with Base R and Tidyverse",
    "text": "Accessing and manipulating Data with Base R and Tidyverse\nMany operations in R can be done in several ways. We illustrate here the base R and tidyverse ways to achieve common operations.\n\nAccessing Data\nAccess the Age column:\n\n# Base R \ndf_baseR['Age']\n\n# Tidyverse \ndf_tidyverse %&gt;% select(Age)\n\nAccess the Age column as a vector:\n\n# Base R \ndf_baseR[['Age']]\ndf_tidyverse$Age\n\n# Tidyverse \ndf_tidyverse %&gt;% pull(Age)\n\n\n\nManipulating Data\nAdd a column.\n\n# Base R \ndf_baseR$mood &lt;- \"happy\"\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  mutate(mood = \"happy\")\n\nAdd a column containing the difference in sales in 2022 and 2022.\n\n# Base R \ndf_baseR$sales_diff &lt;- df_baseR$sales_2022 - df_baseR$sales_2020\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  mutate(sales_diff = sales_2022 - sales_2020)\n\nRemove the sales_diff column.\n\n# Base R \ndf_baseR$sales_diff &lt;- NULL\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  select(-sales_diff)\n\nAdding a column with content based on a condition with ifelse.\n\n# Base R \ndf_baseR$raise &lt;- ifelse(df_baseR$sales_2023 &gt; df_baseR$sales_2022, \"yes\", \"no\")\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  mutate(raise = ifelse(sales_2023 &gt; sales_2022, \"yes\", \"no\"))\n\nExtension of ifelse: case_when\n\n# Base R \ndf_baseR$group &lt;- ifelse(df_baseR$Age &lt; 30 & df_baseR$Sex == \"Female\", \"young_female\",\n                  ifelse(df_baseR$Age &lt; 30 & df_baseR$Sex == \"Male\", \"young_male\",\n                  ifelse(df_baseR$Age &gt;= 30 & df_baseR$Sex == \"Female\", \"mature_female\",\n                  ifelse(df_baseR$Age &gt;= 30 & df_baseR$Sex == \"Male\", \"mature_male\", NA))))\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  mutate(group = case_when(Age &lt; 30 & Sex == \"Female\" ~ \"young_female\",\n                           Age &lt; 30 & Sex == \"Male\" ~ \"young_male\",\n                           Age &gt;= 30 & Sex == \"Female\" ~ \"mature_female\",\n                           Age &gt;= 30 & Sex == \"Male\" ~ \"mature_male\", \n                           .default = NA))\n\n\n\nSubestting Data\nSelect columns with sales numbers.\n\n# Base R \ndf_baseR[, startsWith(colnames(df_baseR), 'sales_')]\n\n# Tidyverse \ndf_tidyverse %&gt;% \n  select(starts_with('sales_'))\n\nFilter rows for people older than 25.\n\n# Base R \ndf_baseR[df_baseR$Age &gt; 25 ,]\n\n# Tidyverse \ndf_tidyverse %&gt;% \n  filter(Age &gt; 25)\n\nFilter rows for people that are 30 years old or younger and have sales in 2022 over 200.\n\n# Base R \ndf_baseR[!is.na(df_baseR$Age) & !is.na(df_baseR$sales_2022) &\n         df_baseR$Age &lt;= 30 & df_baseR$sales_2022 &gt; 200 ,]\n\n# Tidyverse \ndf_tidyverse %&gt;% \n  filter(Age &lt;= 30, sales_2022 &gt; 200)\n\nFilter rows for people that are 30 years old or younger and have sales in 2022 over 200, then and select the Name and Sex column. This far, do you prefer the base R or tidyverse way? Do you see pros and cons with both?\n\n# Base R, NAs not removed\ndf_baseR[!is.na(df_baseR$Age) & !is.na(df_baseR$sales_2022) &\n         df_baseR$Age &lt;= 30 & df_baseR$sales_2022 &gt; 200 , c('Age', 'Sex')]\n\n# Shorter Base R if there are no NAs:\n#df_baseR_no_na[df_baseR_no_na$Age &lt;= 30 & df_baseR_no_na$sales_2022 &gt; 200 , c('Age', 'Sex')]\n\n# Tidyverse \ndf_tidyverse %&gt;% \n  filter(Age &lt;= 30, sales_2022 &gt; 200) %&gt;% \n  select(Age, Sex)\n\n\n\nJoining Dataframes\nThe df_location data frame contains information about the cities of the sales people.\n\nset.seed(101)\n\ndf_location &lt;- data.frame(\n  ID = sample(10),\n  City = c(\"New York\", \"LA\", \"New York\", \"Chicago\", \"Miami\", \"Miami\", \"LA\", \"Chicago\", \"LA\", \"New York\")\n)\n\nhead(df_location)\n\nJoin df and df_location. For base R we use merge and for tidyverse we use left_join.\n\n# Base R \ndf_baseR_merged &lt;- merge(df_baseR, df_location, by = 'ID')\nhead(df_baseR_merged)\n\n# Tidyverse \ndf_tidyverse_join &lt;- df_tidyverse %&gt;% left_join(df_location, by = 'ID')\nhead(df_tidyverse_join)\n\n\n\nInvestigating Data\nCheck which columns have NAs.\n\n# Base R\ncolSums(is.na(df_baseR))\n\n# Tidyverse\ndf_tidyverse %&gt;% summarise(across(everything(), ~ sum(is.na(.))))\n\nRemove rows with any NAs.\n\n# Base R\ndf_baseR_no_na &lt;- df_baseR[complete.cases(df_baseR), ]\n\n# Tidyverse\ndf_tidyverse_no_na &lt;- df_tidyverse %&gt;% drop_na()\n\nSort data based on sales in 2022 in descending order.\n\n# Base R \ndf_baseR[order(-df_baseR$sales_2022) ,]\n\n# Tidyverse \ndf_tidyverse %&gt;% arrange(desc(sales_2022))\n\nCheck variable type:\n\n#base R\nclass(df_baseR$Age)\n\n[1] \"numeric\"\n\n#tidyserve\ndf_tidyverse_join %&gt;%\n  map_chr(typeof)\n\n         ID        Name         Age         Sex  sales_2020  sales_2021 \n   \"double\" \"character\"    \"double\" \"character\"    \"double\"    \"double\" \n sales_2022  sales_2023        mood       raise       group        City \n   \"double\"    \"double\" \"character\" \"character\" \"character\" \"character\" \n\n\nYou also see variable types displayed under the column name in tibbles:\n\nhead(df_tidyverse_join)\n\n# A tibble: 6 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female        100        110        120        100 happy\n2     2 Bob        30 Male          200        210        220        230 happy\n3     3 Charlie    22 Male          150        160        170        200 happy\n4     4 Sophie     35 Female        300        320        340        250 happy\n5     5 Eve        28 Female        250        240        250        270 happy\n6     6 Frank      NA Male           NA        260        270        280 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\nCounting the number of occurrences for each level of a categorical variable.\n\n# Base R\ntable(df_baseR_merged$City)\n\n# Tidyverse\ndf_tidyverse_join %&gt;% count(City)\n\nChecking the range of a variable.\n\n# Base R\nrange(df_baseR$Age, na.rm = TRUE)\n\n[1] 21 40\n\n# Tidyverse \ndf_tidyverse %&gt;%\n  summarise(min_value = min(Age, na.rm = TRUE), \n            max_value = max(Age, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  min_value max_value\n      &lt;dbl&gt;     &lt;dbl&gt;\n1        21        40\n\n\n\n\nPlotting distributions\nFor continuous variables we may want to see how they are distributed:\n\n#base R\n\n#no native violin plots, but you could use the vioplot package\n\nhist(df_tidyverse_join$Age)\n\n\n\n\n\n\n\n\n\n#tidyverse: \n\nggplot(df_tidyverse_join, aes(x=1,y=Age)) +\n  geom_violin()\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n\n\n\n\n\n\n  #if you want to add dots for the actual data points\n  #geom_sina()\n\nggplot(df_tidyverse_join, aes(x=Age)) +\n  geom_histogram(bins = 5)\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_bin()`).",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#string-manipulation",
    "href": "presentations/presentation1.html#string-manipulation",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "String manipulation",
    "text": "String manipulation\nWe will do string manipulation the tidyverse way.\nThe paste function concatenates two strings to one.\n\npaste('Alice', 'Hansen')\n\n[1] \"Alice Hansen\"\n\n\nThe sep argument is a space by default, but can be changed to any character.\n\npaste('Alice', 'Hansen', sep = \"_\")\n\n[1] \"Alice_Hansen\"\n\n\nThe paste0 function concatenates two strings to one without adding any separator between them.\n\npaste0('Alice', 'Hansen')\n\n[1] \"AliceHansen\"\n\n\nLet’s give all the employees the last name Hansen.\n\ndf_tidyverse_join &lt;- df_tidyverse_join %&gt;% \n  mutate(Name = paste(Name, 'Hansen'))\n\nhead(df_tidyverse_join)\n\n# A tibble: 6 × 12\n     ID Name         Age Sex   sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice Han…    25 Fema…        100        110        120        100 happy\n2     2 Bob Hansen    30 Male         200        210        220        230 happy\n3     3 Charlie H…    22 Male         150        160        170        200 happy\n4     4 Sophie Ha…    35 Fema…        300        320        340        250 happy\n5     5 Eve Hansen    28 Fema…        250        240        250        270 happy\n6     6 Frank Han…    NA Male          NA        260        270        280 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\nWe can use the str_split function to split a string into multiple parts in a list.\n\nstr_split('Alice Hansen', pattern = ' ')\n\n[[1]]\n[1] \"Alice\"  \"Hansen\"\n\n\n\nstr_split('Alice_Hansen_Jensen', pattern = '_')\n\n[[1]]\n[1] \"Alice\"  \"Hansen\" \"Jensen\"\n\n\nIndexing one of the strings in the list using the str_split_i function.\n\nstr_split_i('Alice_Hansen_Jensen', pattern = '_', i = 2)\n\n[1] \"Hansen\"\n\n\nLet’s remove the last name we just gave the employees.\n\ndf_tidyverse_join &lt;- df_tidyverse_join %&gt;% \n  mutate(Name = str_split_i(Name, pattern = ' ', i = 1))\n\nhead(df_tidyverse_join)\n\n# A tibble: 6 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female        100        110        120        100 happy\n2     2 Bob        30 Male          200        210        220        230 happy\n3     3 Charlie    22 Male          150        160        170        200 happy\n4     4 Sophie     35 Female        300        320        340        250 happy\n5     5 Eve        28 Female        250        240        250        270 happy\n6     6 Frank      NA Male           NA        260        270        280 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\nDetect substring in main string using str_detect.\n\nstr_detect('Alice', 'A')\n\n[1] TRUE\n\n\n\nstr_detect('Alice', 'B')\n\n[1] FALSE\n\n\nAdd column that check if “A” or “a” in Name and place it after the Name column.\n\ndf_tidyverse_join %&gt;% \n  mutate(A_in_name = str_detect(Name, 'A|a'),\n         .after = Name) %&gt;% \n  head()\n\n# A tibble: 6 × 13\n     ID Name   A_in_name   Age Sex   sales_2020 sales_2021 sales_2022 sales_2023\n  &lt;dbl&gt; &lt;chr&gt;  &lt;lgl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1     1 Alice  TRUE         25 Fema…        100        110        120        100\n2     2 Bob    FALSE        30 Male         200        210        220        230\n3     3 Charl… TRUE         22 Male         150        160        170        200\n4     4 Sophie FALSE        35 Fema…        300        320        340        250\n5     5 Eve    FALSE        28 Fema…        250        240        250        270\n6     6 Frank  TRUE         NA Male          NA        260        270        280\n# ℹ 4 more variables: mood &lt;chr&gt;, raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#whitespace",
    "href": "presentations/presentation1.html#whitespace",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Whitespace",
    "text": "Whitespace\nWhitespace includes spaces, newlines, and other blank characters in text. It can cause errors or inconsistencies in data, so removing unnecessary whitespace is an important step in cleaning data.\nLet’s have a look at a version of the sales data frame with whitespaces. In the tibble format it cannot be spotted.\n\ndf_sales_messy &lt;- read_delim('../data/df_sales_messy.csv')\nhead(df_sales_messy)\n\n# A tibble: 6 × 8\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1     1 Alice      25 Female        100        110        120        100\n2     2 Bob        30 Male          200        210        220        230\n3     3 Charlie    22 Male          150        160        170        200\n4     4 Sophie     35 Female        300        320        340        250\n5     5 Eve        28 Female        250        240        250        270\n6     6 Frank      NA Male           NA        260        270        280\n\n\nAccessing the unique sexes of the Sex column before cleaning.\n\ndf_sales_messy$Sex %&gt;% unique()\n\n[1] \"Female\"  \"Male\"    \"Female \" \"Male \"  \n\n\nUse the str_trim function to remove whitespace.\n\ndf_sales_messy$Sex %&gt;% str_trim() %&gt;% unique()\n\n[1] \"Female\" \"Male\"  \n\n\nLike other function, the str_trim function can also be used inside the mutate function to alter the data frame.\n\ndf_sales_clean &lt;- df_sales_messy %&gt;% \n  mutate(Sex = str_trim(Sex))\n\nAccessing the unique sexes of the Sex column after cleaning.\n\ndf_sales_clean$Sex %&gt;% unique()\n\n[1] \"Female\" \"Male\"",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#export-dataset",
    "href": "presentations/presentation1.html#export-dataset",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Export Dataset",
    "text": "Export Dataset\nExport tidyverse dataset\n\nwritexl::write_xlsx(df_tidyverse_join, '../out/sales_data_2.xlsx')",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Data Science",
    "section": "",
    "text": "This 3 day course is a continuation of our 2 day course FromExceltoR and the material of that course is a prerequisite to this course. If you have not used R since you took the course, please go through the course material again (link to course). R for Data Science is an advanced course in R-programming for researchers at the Faculty of Health and Medical Sciences (SUND), University of Copenhagen. The course is build on code-along presentations and exercises in Quarto documents.\n\nThe course goes through the following topics:\n\nScript formats\nAdvanced tidyverse using real world data (build on material from our introduction to R course, FromExceltoR)\nScripting in R using functions, for-loops, if-else statements.\nModelling in R.\n\nThe material in this repository is for teaching purposes only and not to be distributed commercially.\nFinally… Dear course participants, it would greatly help us if you could complete our UPDATE LINK feedback form."
  },
  {
    "objectID": "index.html#welcome-to-the-main-page-of-r-for-data-science",
    "href": "index.html#welcome-to-the-main-page-of-r-for-data-science",
    "title": "R for Data Science",
    "section": "",
    "text": "This 3 day course is a continuation of our 2 day course FromExceltoR and the material of that course is a prerequisite to this course. If you have not used R since you took the course, please go through the course material again (link to course). R for Data Science is an advanced course in R-programming for researchers at the Faculty of Health and Medical Sciences (SUND), University of Copenhagen. The course is build on code-along presentations and exercises in Quarto documents.\n\nThe course goes through the following topics:\n\nScript formats\nAdvanced tidyverse using real world data (build on material from our introduction to R course, FromExceltoR)\nScripting in R using functions, for-loops, if-else statements.\nModelling in R.\n\nThe material in this repository is for teaching purposes only and not to be distributed commercially.\nFinally… Dear course participants, it would greatly help us if you could complete our UPDATE LINK feedback form."
  },
  {
    "objectID": "index.html#program",
    "href": "index.html#program",
    "title": "R for Data Science",
    "section": "Program",
    "text": "Program"
  },
  {
    "objectID": "exercises/exercise4.html",
    "href": "exercises/exercise4.html",
    "title": "Exercise 4 - Scripting in R",
    "section": "",
    "text": "In this exercise you will practice your scripting.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 4: Scripting in R"
    ]
  },
  {
    "objectID": "exercises/exercise4.html#getting-started",
    "href": "exercises/exercise4.html#getting-started",
    "title": "Exercise 4 - Scripting in R",
    "section": "Getting started",
    "text": "Getting started\nLoad libaries and data\n\nlibrary(tidyverse)\nlibrary(glue)\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\ndiabetes_glucose\n\n# A tibble: 490 × 12\n   ID    Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n   &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n 1 9046  Male      34            84  24.7               93 Unknown 0       \n 2 51676 Male      25            74  22.5              102 Unknown 0       \n 3 60182 Male      50            80  34.5               98 Unknown 1       \n 4 1665  Female    27            60  26.3               82 Never   0       \n 5 56669 Male      35            84  35                 58 Smoker  1       \n 6 53882 Female    31            78  43.3               59 Smoker  1       \n 7 10434 Male      52            86  33.3               58 Never   1       \n 8 27419 Female    54            78  35.2               74 Former  1       \n 9 60491 Female    41            90  39.8               67 Smoker  1       \n10 12109 Female    36            82  30.8               81 Smoker  1       \n# ℹ 480 more rows\n# ℹ 4 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 4: Scripting in R"
    ]
  },
  {
    "objectID": "exercises/exercise4.html#if-else-statements",
    "href": "exercises/exercise4.html#if-else-statements",
    "title": "Exercise 4 - Scripting in R",
    "section": "If-else statements",
    "text": "If-else statements\nIn these exercises we don’t use the dataframe yet, that comes later when we have loops. For this part, just declare variables to test your statements, e.g. bp &lt;- 120.\n\nWrite an if-else statement that prints whether a person has high (more than 100), low (lower than 50) or normal blood pressure (between 50 and 100).\nWrite an if-else statement that assigns people high, moderate or low diabetes risk based on their genetic risk score and BMI:\n\n\ngenetic Risk greater than 1 and BMI greater than 35 -&gt; high risk\ngenetic Risk greater than 1 or BMI greater than 35 -&gt; moderate risk\notherwise low risk\n\nVerify that your statement works for different combinations of risk score and BMI",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 4: Scripting in R"
    ]
  },
  {
    "objectID": "exercises/exercise4.html#loops",
    "href": "exercises/exercise4.html#loops",
    "title": "Exercise 4 - Scripting in R",
    "section": "Loops",
    "text": "Loops\n\nCreate a vector with at least 5 elements and loop over it.\nLoop over all column names of diabetes_glucose.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncolnames(df) creates a vector of column names.\n\n\n\n\nLoop over all rows of diabetes_glucose and determine whether the person’s blood pressure is high, low or normal with the same conditions as in 1.\nLoop over all rows of diabetes_glucose and determine the risk based on genetic risk score and BMI, with the same conditions as in 2. Print the genetic risk score and BMI as well as the risk level to make it easier to see whether your code works correctly.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAn easy way to printing several variables is to pass a vector into print: print(c(this,and_that,and_this_too))",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 4: Scripting in R"
    ]
  },
  {
    "objectID": "exercises/exercise4.html#user-defined-functions",
    "href": "exercises/exercise4.html#user-defined-functions",
    "title": "Exercise 4 - Scripting in R",
    "section": "User defined Functions",
    "text": "User defined Functions\nIn this part we will write some functions that create plots.\nSince we want to be able to pass the name of the column to plot as a variable we will need to use the syntax for aliased column names. We showed how to do that in the end of presentation 3 if you need a refresher.\n\nCreate a variable plot_column and assign “Age” to it. Now make a boxplot of that column. Switch plot_column to a different column in diabetes_glucose. Does it work?\nWrap your code for the boxplot into a function. The function should take two arguments: the dataframe to use and the name of the column to plot. Test your function. Add some customization to the plot like a theme or colors.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFunctions are good at returning objects so make your plot into an object and return that.\n\n\n\n\nAdd a check to your function whether the supplied column is numeric. Note here that you need to test the data type of the column you want to plot, not the data type of it’s name. Confirm that your check works.\nWrite code to apply your boxplot function to each numerical column in the dataframe. There are different ways to achieve this.\nCreate an R script file to contain your functions. Copy your functions there and remove them from your global environment with rm(list=\"name_of_your_function\"). Now source the function R script in your quarto document and test that the functions work.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 4: Scripting in R"
    ]
  },
  {
    "objectID": "exercises/exercise4.html#extra-exercises",
    "href": "exercises/exercise4.html#extra-exercises",
    "title": "Exercise 4 - Scripting in R",
    "section": "Extra exercises",
    "text": "Extra exercises\nFirst, unnest diabetes_glucose so you get back the Measurement and Glucose columns.\n\ndiabetes_glucose_unnest &lt;- diabetes_glucose %&gt;%\n  unnest(OGTT)\n\ne1. Calculate the mean Glucose (mmol/L) for each measuring time point (i.e. one value for 0, 60 and 120). Now stratify this mean by a second variable, Sex. You should have 6 mean values since there are 6 groups (0_female, 0_male, 60_female, ect). Now, create a variable category to which you pass the name of the column to stratify by (e.g. category &lt;- 'Sex') and use category in your code instead of the literal variable name.\ne2. We would like to make a plot that shows the means you calculated above. Again, use your category variable instead of the literal column name.\ne3. Wrap the code from e1 and e2 into a function show_mean_by_catergory so that you can call: show_mean_by_catergory(diabetes_glucose_unnest, 'Sex') and it will make you the plot. Test with different columns.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 4: Scripting in R"
    ]
  },
  {
    "objectID": "exercises/exercise3A.html",
    "href": "exercises/exercise3A.html",
    "title": "Exercise 3 A: Exploratory Data Analysis (EDA) - Plotting",
    "section": "",
    "text": "In this exercise you will do a lot of plotting with ggplot. For a reminder on how ggplot works you can have a look the ggplot material covered in our previous course, From Excel to R.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3 A: Exploratory Data Analysis - Plotting"
    ]
  },
  {
    "objectID": "exercises/exercise3A.html#getting-started",
    "href": "exercises/exercise3A.html#getting-started",
    "title": "Exercise 3 A: Exploratory Data Analysis (EDA) - Plotting",
    "section": "Getting started",
    "text": "Getting started\n\nLoad packages.\nLoad data from the .rds file you created in Exercise 2. Have a guess at what the function is called.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3 A: Exploratory Data Analysis - Plotting"
    ]
  },
  {
    "objectID": "exercises/exercise3A.html#plotting---part-1",
    "href": "exercises/exercise3A.html#plotting---part-1",
    "title": "Exercise 3 A: Exploratory Data Analysis (EDA) - Plotting",
    "section": "Plotting - Part 1",
    "text": "Plotting - Part 1\nYou will first do some basic plots to get started with ggplot again.\nIf it has been a while since you worked with ggplot, have a look at the ggplot material from the FromExceltoR course.\n\nCreate a scatter plot of Age and Blood Pressure. Do you notice a trend?\nCreate a scatter plot of PhysicalActivity and BMI. Do you notice a trend?\nNow, create the same two plots as before, but this time stratify them by Diabetes. Do you notice any trends?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can stratify a plot by a categorical variable in several ways, depending on the type of plot. The purpose of stratification is to distinguish samples based on their categorical values, making patterns or differences easier to identify. This can be done using aesthetics like color, fill, shape.\n\n\n\n\nCreate a boxplot of BMI stratified by Diabetes. Give the plot a meaningful title.\nCreate a boxplot of PhysicalActivity stratified by Smoker. Give the plot a meaningful title.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3 A: Exploratory Data Analysis - Plotting"
    ]
  },
  {
    "objectID": "exercises/exercise3A.html#plotting---part-2",
    "href": "exercises/exercise3A.html#plotting---part-2",
    "title": "Exercise 3 A: Exploratory Data Analysis (EDA) - Plotting",
    "section": "Plotting - Part 2",
    "text": "Plotting - Part 2\nIn order to plot the data inside the nested variable, the data needs to be unnested.\n\nCreate a boxplot of the glucose measurements at time 0 stratified by Diabetes. Give the plot a meaningful title.\nCreate these boxplots for each time point (0, 60, 120) by using faceting by Measurement. Give the plot a meaningful title.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFaceting allows you to create multiple plots based on the values of a categorical variable, making it easier to compare patterns across groups. In ggplot2, you can use facet_wrap for a single variable or facet_grid for multiple variables.\n\n\n\n\nCalculate the mean glucose levels for each time point.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use unnest(), group_by(), and summerise().\n\n\n\n\nMake the same calculation as above, but additionally group the results by Diabetes. Save the data frame in a variable. Compare your results to the boxplots you made above.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nGroup by several variables: group_by(var1, var2).\n\n\n\n\nCreate a plot that visualizes glucose measurements across time points, with one line for each patient ID. Then color the lines by their diabetes status. In summary, each patient’s glucose measurements should be connected with a line, grouped by their ID, and color-coded by Diabetes. Give the plot a meaningful title.\n\nIf your time points are strangely ordered have a look at the levels of your Measurement variable (the one that specifies which time point the measurement was taken at) and if necessary fix their order.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3 A: Exploratory Data Analysis - Plotting"
    ]
  },
  {
    "objectID": "exercises/exercise3A.html#extra-exercises",
    "href": "exercises/exercise3A.html#extra-exercises",
    "title": "Exercise 3 A: Exploratory Data Analysis (EDA) - Plotting",
    "section": "Extra exercises",
    "text": "Extra exercises\nThis exercise might be a bit more challenging. It requires multiple operations and might involve some techniques that were not explicitly shown in the presentations.\ne1. Recreate the plot you made in Exercise 12 and include the mean value for each glucose measurement for the two diabetes statuses (0 and 1) you calculated in Exercise 11. This plot should look like this:\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThere are several ways to solve this task. Here is a workflow suggestion:\n\nYou want to show both the raw data and the means in the same plot. Data from another dataset can be added to a plot by pointing the geom to a specific dataset like so: + geom_point(data = different_data, aes(x = VAR1, y = VAR2, group = VAR3))\ngeom_line needs a variable to group by in order to know which dots should be connected. In exercise 10, this grouping variable was the patient ID. Which variable in glucose_mean tells which points are connected? Pass it as group aesthetic.\ngeom_line has a linetype aestethic to define the kind of line (dashed or solid).",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3 A: Exploratory Data Analysis - Plotting"
    ]
  },
  {
    "objectID": "exercises/exercise1.html",
    "href": "exercises/exercise1.html",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "",
    "text": "In this exercise you will practice your R skills by loading, inspecting and cleaning a dataset. You can use base R and/or tidyverse to solve the exercises, it is up to you.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#getting-started",
    "href": "exercises/exercise1.html#getting-started",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Getting started",
    "text": "Getting started\n\nLoad the packages you think you will need. There is no need to spend too much time on this part. If you later realize you need another package just add it here and re-run the chunk.\n\n\n#your packages here\n\n\nLoad in the data set diabetes_clinical_toy_messy.xlsx.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#explore-the-data",
    "href": "exercises/exercise1.html#explore-the-data",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Explore the data",
    "text": "Explore the data\n\nHow many missing values (NA’s) are there in each column?\nCheck the distribution of each of the variables. Consider that the variables are of different classes. Do any values strike you as odd?",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#clean-up-the-data",
    "href": "exercises/exercise1.html#clean-up-the-data",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Clean up the data",
    "text": "Clean up the data\nNow that we have had a look at the data, it is time to correct fixable mistakes and remove observations that cannot be corrected.\nConsider the following:\n\nWhat should we do with the rows that contain NAs? Do we remove them or keep them?\nWhich mistakes in the data can be corrected, and which cannot?\nAre there zeros in the data? Are they true zeros or errors?\nDo you want to change any of the data types of the variables?\n\n\nClean the data according to your considerations.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nHave a look at BloodPressure, BMI, Sex, Diabetes and ID.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#meta-data",
    "href": "exercises/exercise1.html#meta-data",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Meta Data",
    "text": "Meta Data\nThere is some metadata to accompany the dataset you have just cleaned in diabetes_meta_toy_messy.csv. This is a csv file, not an excel sheet, so you need to use the read_delim function to load it. Load in the dataset and inspect it.\n\nNow clean the metadata and do data exploration by repeating step 3-5 from above.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#join-the-datasets",
    "href": "exercises/exercise1.html#join-the-datasets",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Join the datasets",
    "text": "Join the datasets\nWe will combine both datasets together into one tibble.\n\nConsider what variable the datasets should be joined on.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe joining variable must be the same type in both datasets.\n\n\n\n\nJoin the datasets by the variable you selected above.\nHow many rows does the joined dataset have? Explain why.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBecause we used left_join, only the IDs that are in diabetes_clinical_clean are kept.\n\n\n\n\nExport the joined dataset. Think about which directory you want to save the file in.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "data/data.html",
    "href": "data/data.html",
    "title": "Data",
    "section": "",
    "text": "DOWNLOAD DATA  \n\nAfter download, unzip the data folder and place it somewhere you can find it again.",
    "crumbs": [
      "Course Material",
      "Data️"
    ]
  },
  {
    "objectID": "data/data.html#download-data",
    "href": "data/data.html#download-data",
    "title": "Data",
    "section": "",
    "text": "DOWNLOAD DATA  \n\nAfter download, unzip the data folder and place it somewhere you can find it again.",
    "crumbs": [
      "Course Material",
      "Data️"
    ]
  },
  {
    "objectID": "data/data.html#download-presentations",
    "href": "data/data.html#download-presentations",
    "title": "Data",
    "section": "Download presentations",
    "text": "Download presentations\nIt can be nice to follow along the presentation scripts as we go through them.\n\n  DOWNLOAD PRESENTATIONS",
    "crumbs": [
      "Course Material",
      "Data️"
    ]
  },
  {
    "objectID": "about_heads.html",
    "href": "about_heads.html",
    "title": "About HeaDS",
    "section": "",
    "text": "In the Center for Health Data Science (HeaDS) we do both research and in the DataLab and Sandbox we develop and host course. Read more about all the cool stuff we do on our website.\n\n\nThe DataLab offers a range of services to support SUND employees in their data science analyses. Here’s an overview:\n\nCourses: We offer data science and bioinformatics courses for all SUND staff (researchers, administrative staff, technical staff, etc.). Our most popular courses include “From Excel to R,” “Python Tsunami,” and “Introduction to Bulk RNA-seq Analysis.”\nConsultations: We host drop-in sessions every Thursday from 13:00 to 15:00, where we assist with data science-related challenges and questions. Alternatively, you can reach out to arrange a one-on-one meeting on another day.\nCommissions: We conduct commissioned research, such as bioinformatics and data science analyses tailored to your needs. Additionally, we offer a commissioned supervision scheme if you would like to learn how to perform the analysis yourself.\nEvents: We host various data science events. Join us for our seminar series, “Talking HeaDS.” Our next session is in the spring (date and speeker TBA), and you can sign up here: https://eventsignup.ku.dk/talkingheadsspring2025."
  },
  {
    "objectID": "about_heads.html#center-for-health-data-science",
    "href": "about_heads.html#center-for-health-data-science",
    "title": "About HeaDS",
    "section": "",
    "text": "In the Center for Health Data Science (HeaDS) we do both research and in the DataLab and Sandbox we develop and host course. Read more about all the cool stuff we do on our website.\n\n\nThe DataLab offers a range of services to support SUND employees in their data science analyses. Here’s an overview:\n\nCourses: We offer data science and bioinformatics courses for all SUND staff (researchers, administrative staff, technical staff, etc.). Our most popular courses include “From Excel to R,” “Python Tsunami,” and “Introduction to Bulk RNA-seq Analysis.”\nConsultations: We host drop-in sessions every Thursday from 13:00 to 15:00, where we assist with data science-related challenges and questions. Alternatively, you can reach out to arrange a one-on-one meeting on another day.\nCommissions: We conduct commissioned research, such as bioinformatics and data science analyses tailored to your needs. Additionally, we offer a commissioned supervision scheme if you would like to learn how to perform the analysis yourself.\nEvents: We host various data science events. Join us for our seminar series, “Talking HeaDS.” Our next session is in the spring (date and speeker TBA), and you can sign up here: https://eventsignup.ku.dk/talkingheadsspring2025."
  },
  {
    "objectID": "exercises/exercise0.html",
    "href": "exercises/exercise0.html",
    "title": "Exercise 0: R script and Quarto",
    "section": "",
    "text": "Make a new directory for this course.\nGo to course website and to the Data tab. Press the Download Data button.\nMove the Data folder to your course directory.\nUnder your course directory, make a new folder for your scripts, one for our output, and another for the presentations you download.\n\nYour file tree should look something like this:",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#file-management-data-download",
    "href": "exercises/exercise0.html#file-management-data-download",
    "title": "Exercise 0: R script and Quarto",
    "section": "",
    "text": "Make a new directory for this course.\nGo to course website and to the Data tab. Press the Download Data button.\nMove the Data folder to your course directory.\nUnder your course directory, make a new folder for your scripts, one for our output, and another for the presentations you download.\n\nYour file tree should look something like this:",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#working-directories",
    "href": "exercises/exercise0.html#working-directories",
    "title": "Exercise 0: R script and Quarto",
    "section": "Working directories",
    "text": "Working directories\n\nOpen R studio.\nAccess your current working directory by writing getwd() in the console.\n\nThe working directory in R (or other programming environments) is the folder on your computer where R looks for files to read or write by default. When you load or save data, R will use the working directory unless you specify another path. A path can either be absolute or relative:\n\nAbsolute path: The path from the root of your file system to the input file.\nRelative path: The path from the working directory to the input file.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#r-script",
    "href": "exercises/exercise0.html#r-script",
    "title": "Exercise 0: R script and Quarto",
    "section": "R Script",
    "text": "R Script\n\nCreate an R script and save it in your work folder.\n\nAn R script is a plain text file containing a series of R commands and code used for data analysis. R scripts have a .R extension and can be executed line-by-line in an interactive R session or as a whole script. They are ideal for automating workflows and keeping your analyses reproducible and organized. R scripts can be submitted to a job on a supercomputer unlike Quarto documents.\n\nType getwd() in your R script and run the line. Compare the working directory with the one from the console.\nChange the working directory using setwd().\nRun getwd() again.\nType in a few lines of code and some comments and re-save the file.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#quarto",
    "href": "exercises/exercise0.html#quarto",
    "title": "Exercise 0: R script and Quarto",
    "section": "Quarto",
    "text": "Quarto\n\nCreate an Quarto document and save it in your work folder.\n\nQuarto is an open-source publishing system designed to help you create dynamic, reproducible documents, presentations, and websites. It extends the ideas of tools like R Markdown, combining simplicity with powerful customization options for modern scientific and technical communication.\n\nType getwd() in a code chunk in your Quarto document and run the line. Compare the working directory with the one from the console.\nChange the working directory in one chuck using setwd().\nRun getwd() in the same chunk as setwd() AND in another chunk. What do you observe?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nsetwd('')\ngetwd()\n\n\ngetwd()\n\n\n\n\n\nCreate some code chunks, write text and headers. Re-save the file.\nRender the Quarto document and have a look at the html file.\n\n\n\n\n\n\n\nResources for Quarto\n\n\n\n\n\n\nQuarto website\n\n“Get started with Quarto” tutorial for RStudio\n\n“Get started with Quarto” video for RStudio\nComprehensive guides to Quarto basics",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#r-project",
    "href": "exercises/exercise0.html#r-project",
    "title": "Exercise 0: R script and Quarto",
    "section": "R project",
    "text": "R project\nAn R project in RStudio creates a self-contained working environment tied to a specific folder, which becomes the default working directory for all scripts, data, and outputs. This structure helps organize files, ensures reproducibility, and simplifies path management. By default, a Quarto document’s working directory is its file location. While this can be changed chunk-wise, the working directory for R scripts can be set globally for all scripts in a folder by creating an R project. The R project is a small configuration file, usually placed in the root of the project folder, and requires no manual interaction—it quietly ensures your workflows remain well-organized.\n\n\n\n\n\n\nCreate an R project by clicking the Project (None) in the top right → New Project → Existing Directory and choose an appropriate location. Look at the top-right corner to check that you are in your R project.\nReopen the the R script and Quarto document you created in Exercise 7 and 13 respectively. Check each of their working directories. Are they as you expect? Explain.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe working directory of the R script is the same as the location of the .Rproj file.\nThe working directory of the Quarto document is always the same as the location of the document.\n\n\n\n\n\nIf you like the flow of the R project, keep it. If not, delete it. It is not necessary to have an R project. NB If you delete it, click the R project drop-down menu in the top-right corner → Close Project.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise2.html",
    "href": "exercises/exercise2.html",
    "title": "Exercise 2: Advanced Wrangling",
    "section": "",
    "text": "In this exercise you will do some more advance tidyverse operations such as pivoting and nesting.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "exercises/exercise2.html#getting-started",
    "href": "exercises/exercise2.html#getting-started",
    "title": "Exercise 2: Advanced Wrangling",
    "section": "Getting started",
    "text": "Getting started\n\nLoad packages.\nLoad the joined diabetes data set you created in exercise 1 (e.g. “diabetes_join.xlsx”) and the glucose dataset df_glucose.xlsx from the data folder.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "exercises/exercise2.html#wrangling",
    "href": "exercises/exercise2.html#wrangling",
    "title": "Exercise 2: Advanced Wrangling",
    "section": "Wrangling",
    "text": "Wrangling\n\nHave a look at the glucose dataset. It has three columns with measurements from a Oral Glucose Tolerance Test where blood glucose is measured at fasting (Glucose_0), 1 hour/60 mins after glucose intake (Glucose_6), and 2 hours/120 mins after (Glucose_120). The last columns is an ID column. Change the data type of the ID column to factor in both diabetes_join and df_glucose.\nRestructure the glucose dataset into a long format. Name the column that describes which measurement the row refers to, i.e. Glucose_0, Glucose_60 or Glucose_120, Measurement. How many rows are there per ID? Does that make sense?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember the flow:\n\npivot_longer(cols = LIST_WITH_COLUMNS_TO_PIVOT,\n             names_to = \"NEW_COLUMN_CONTAINING_COLUMN_NAMES\",\n             values_to = \"NEW_COLUMN_CONTAINING_COLUMN_VALUES\")\n\nHave a look at slide 16 for a visual overview.\n\n\n\n\nIn your long format dataframe you should have one column that described which measurement the row refers to, i.e. Glucose_0, Glucose_60 or Glucose_120. Transform this column so that you only have the numerical part, i.e. only 0, 60 or 120. Then change the data type of that column to factor. Check the order of the factor levels and if necessary change them to the proper order.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe stringr packages is a part of tidyverse and has many functions for manipulating strings. Find a function that can split the string so you can extract the numbers on the other side of the underscore.\nHave a look at the help for factors ?factors to see how to influence the levels.\n\n\n\n\nMerge the glucose dataset with the joined diabetes dataset.\nPull the glucose measurements from your favorite ID.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFirst filter for your favorite ID and then pull the columns.\n\n\n\n\nCalculate the mean glucose measure for each measurement timepoint.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use group_by(), and summerise().\n\n\n\n\nCalculate mean and standard deviation for all numeric columns.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use summarise() and across(), selecting numeric columns.\n\n\n\n\nNest the glucose measurements and values such that there is only one row per ID and call the nested column OGTT (Oral Glucose Tolerance Test). Display the resulting tibble to confirm that you have succeeded.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember the flow:\n\ngroup_by() %&gt;% \n  nest() %&gt;% \n  ungroup()\n\n\n\n\n\nExport the final dataset. Since the dataset is nested, you cannot export it as an excel file. Export the dataset as an .rds file. Have a guess at what the function is called.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "exercises/exercise3B.html",
    "href": "exercises/exercise3B.html",
    "title": "Exercise 3 B: Exploratory Data Analysis (EDA) - PCA",
    "section": "",
    "text": "This exercise deals with creating and visualizing a principal component analysis (PCA). For a quick introduction to the main idea behind PCA you can have a look at this video.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3 B: Exploratory Data Analysis - PCA"
    ]
  },
  {
    "objectID": "exercises/exercise3B.html#getting-started",
    "href": "exercises/exercise3B.html#getting-started",
    "title": "Exercise 3 B: Exploratory Data Analysis (EDA) - PCA",
    "section": "Getting started",
    "text": "Getting started\n\nLoad packages.\nLoad data from the .rds file you created in Exercise 2.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3 B: Exploratory Data Analysis - PCA"
    ]
  },
  {
    "objectID": "exercises/exercise3B.html#pca",
    "href": "exercises/exercise3B.html#pca",
    "title": "Exercise 3 B: Exploratory Data Analysis (EDA) - PCA",
    "section": "PCA",
    "text": "PCA\nFor this exercise we will use this tutorial to make a principal component analysis (PCA). First, we perform some preprocessing to get our data into the right format.\n\nLet’s start by unnesting the OGTT data and using pivot wider so that each Glucose measurement time point gets its own column (again).\nHave a look at your unnested diabetes data set. Can you use all the variables to perform PCA? Subset the dataset to only include the relevant variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nPCA can only be performed on numerical values. Extract these (except ID!) from the dataset. Numerical columns can easily be selected with the where(is.numeric) helper.\n\n\n\n\nPCA cannot handle NA’s in the dataset. Remove all rows with NA in any column in your numerical subset. Then, go back to the original unnested data diabetes_glucose_unnest (or what you have called it) and also here drop rows that have NAs in the numerical columns (so the same rows you dropped from the numeric subset).This is important because we want to use (categorical) columns present in the original data to later color the resulting PCA, so the two dataframes (original and only numeric columns) need to be aligned and contain the same rows.\n\nNow our data is ready to make a PCA.\n\nCalculate the PCA by running prcomp on our prepared data (see the tutorial). Then, create a plot of the resulting PCA (also shown in tutorial).\nColor your PCA plot and add loadings. Think about which variable you want to color by. Remember to refer to the dataset that has this variable (probably not your numeric subset!)\nAdd a ggplot theme and title to your plot and save it.\nCalculate the variance explained by each of the PC’s using the following formula:\n\n\\[\n\\text{Variance Explained} = \\frac{\\text{sdev}^2}{\\sum \\text{sdev}^2} \\times 100\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can access the standard deviation from the PCA object like this: pca_res$sdev.\n\n\n\n\nCreate a two column data-frame with the names of the PC’s (PC1, PC2, ect) in one column and the variance explained by that PC in the other column.\nNow create a bar plot (using geom_col), showing for each PC the amount of explained variance. This type of plot is called a scree plot.\nLastly, render you quarto document and review the resulting html file.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3 B: Exploratory Data Analysis - PCA"
    ]
  },
  {
    "objectID": "exercises/exercise3B.html#extra-exercises",
    "href": "exercises/exercise3B.html#extra-exercises",
    "title": "Exercise 3 B: Exploratory Data Analysis (EDA) - PCA",
    "section": "Extra exercises",
    "text": "Extra exercises\ne1. The Oral Glucose Tolerance Test is used to diagnose diabetes so we are not surprised that it separates the dataset well. In this part, we will look at a PCA without the OGTT measurements and see how we fare. Omit the Glucose measurement columns, calculate a PCA and create the plot.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3 B: Exploratory Data Analysis - PCA"
    ]
  },
  {
    "objectID": "exercises/exercise5.html",
    "href": "exercises/exercise5.html",
    "title": "Exercise 5 - Modelling in R",
    "section": "",
    "text": "In this exercise you will fit and interpret simple models.\n\nLoad packages",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 5: Modelling in R"
    ]
  },
  {
    "objectID": "exercises/exercise5.html#introduction",
    "href": "exercises/exercise5.html#introduction",
    "title": "Exercise 5 - Modelling in R",
    "section": "",
    "text": "In this exercise you will fit and interpret simple models.\n\nLoad packages",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 5: Modelling in R"
    ]
  },
  {
    "objectID": "exercises/exercise5.html#part-1-linear-regression",
    "href": "exercises/exercise5.html#part-1-linear-regression",
    "title": "Exercise 5 - Modelling in R",
    "section": "Part 1: Linear regression",
    "text": "Part 1: Linear regression\nWe will use the dataset described below to fit a linear regression model.\n\nLoad the data boston.csv and inspect it.\n\nThis dataset describes conditions surrounding the Boston housing market in the 1970s. Each row describes a zone in the Boston area (so there is more than one house in each row).\nThe columns are:\ncrim - per capita crime rate\nindus - proportion of non-retail businesses\nnox - Nitrogen oxides concentration (air pollution)\nrm - average number of rooms\nneighborhood - the type of neighborhood the zone is in\nmedv - median value per house in 1000s\n\nExplore the data\n\nDoes the datatype of each column fit to it what it describes? Do you need to change any data types?\n\n\n\nMaking a model\n\nSplit the dataset into test and training data.\nFit a model of how well the number of rooms (rm), crime rate (crim) and neighborhood type (neighborhood) predict the value of the houses (medv).\nDescribe what information you get from the model summary.\nScale the numeric predictor columns and redo the modelling. What has changed?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThere is a scale function, see ?scale().",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 5: Modelling in R"
    ]
  },
  {
    "objectID": "exercises/exercise5.html#part-2-logistic-regression",
    "href": "exercises/exercise5.html#part-2-logistic-regression",
    "title": "Exercise 5 - Modelling in R",
    "section": "Part 2: Logistic regression",
    "text": "Part 2: Logistic regression\nFor this part we will use the joined diabetes data since it has a categorical outcome (Diabetes yes or no). We will not use the oral Glucose measurements as predictors since this is literally how you define diabetes, so we’re loading the joined dataset we created in exercise 1, e.g. ‘diabetes_join.xlsx’ or what you have named it.\nWe choose to make a regression model of Diabetes as predicted by serum calcium levels (Serum_ca2), BMI and smoking habits (Smoker).\n\nWe cannot have NA values in our predictors so remove all rows with NAs and save the result into a new dataframe diabetes_nona.\nMake the outcome variable into a factor if it is not already.\nScale all numeric predictors. Check your result.\nSplit your data into training and test data. Take care that the two classes of the outcome variable are in the same ratio in both training and test data.\nFit a regression model with Serum_ca2, BMI and Smoker as predictors. Check the model summary.\nCreate a second model with only BMI and Smoker as predictors. Compare the fit of your second model to the first one (including Serum_ca2). Is there a significant gain, i.e. better fit when including the serum calcium levels as predictor? Which model do you think is better?",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 5: Modelling in R"
    ]
  },
  {
    "objectID": "exercises/exercise5.html#part-3-clustering",
    "href": "exercises/exercise5.html#part-3-clustering",
    "title": "Exercise 5 - Modelling in R",
    "section": "Part 3: Clustering",
    "text": "Part 3: Clustering\nIn this part we will run clustering on the joined diabetes dataset from exercise 1. Load it here if you don’t have it already from Part 2.\n\nRun the k-means clustering algorithm with 4 centers on the data. Consider which columns you can use and if you have to manipulate them before. If you get an error, check whether you have values that might not be admissible, such as NA.\nCheck whether the data you have run k-means on has the same number of rows as the dataframe with meta information, e.g. whether the person had diabetes. If they are not aligned, create a dataframe with Diabetes info that matches the dataframe you ran clustering on.\nVisualize the results of your clustering.\nInvestigate the best number of clusters.\nRe-do the clustering (plus visualization) with that number.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 5: Modelling in R"
    ]
  },
  {
    "objectID": "exercises/exercise5.html#extra-exercises",
    "href": "exercises/exercise5.html#extra-exercises",
    "title": "Exercise 5 - Modelling in R",
    "section": "Extra exercises",
    "text": "Extra exercises\ne1. Find the best single predictor in the Diabetes dataset. This is done by comparing the null model (no predictors) to all possible models with one predictor, i.e. outcome ~ predictor, outcome ~ predictor2, ect. The null model can be formulated like so: outcome ~ 1 (only the intercept). Fit all possible one predictor models and compare their fit to the null model with a likelihood ratio test. Find the predictor with the lowest p-value in the likelihood ratio test. This can be done in a loop in order to avoid writing out all models.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo use a formula with a variable you will need to combine the literal part and the variable with paste, e.g. paste(\"Outcome ~\", my_pred).\n\n\n\ne2. Write a function that handles visualization of k-means clustering results. Think about which information you need to pass and what it should return.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 5: Modelling in R"
    ]
  },
  {
    "objectID": "presentations/named_lists.html",
    "href": "presentations/named_lists.html",
    "title": "R Objects: Named lists",
    "section": "",
    "text": "In our last exercise ‘3B: PCA’ we encountered the object pca_res &lt;- prcomp(df, scale. = TRUE) (or what you have named it). Lets have a deeper look at its structure because this is a type of object you will encounter many times while using R.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "R Objects: Named Lists"
    ]
  },
  {
    "objectID": "presentations/named_lists.html#creating-a-pca-object",
    "href": "presentations/named_lists.html#creating-a-pca-object",
    "title": "R Objects: Named lists",
    "section": "Creating a PCA object",
    "text": "Creating a PCA object\n\n#build-in dataset: Iris\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\n#create PCA object\npca_res &lt;- prcomp(iris[1:4], scale. = TRUE)\n\npca_res is a named list:\n\ntypeof(pca_res)\n\n[1] \"list\"\n\n\nThis is means it has several elements inside it and they are named. You can investigate them by clicking on pca_res in the Environment which will show their name, type and some example values. Lists are great because their elements can have different data types while vectors cannot.\nWe can also list the elements of a named list (or any other named object such as dataframes/tibbles):\n\nnames(pca_res)\n\n[1] \"sdev\"     \"rotation\" \"center\"   \"scale\"    \"x\"       \n\nnames(iris)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\nElements of a named list are always accessed with the $ symbol:\n\n#the standard deviations of the principal components\npca_res$sdev\n\n[1] 1.7083611 0.9560494 0.3830886 0.1439265\n\n\nElements of a named list (or any list) can themselves be multi-dimensional, such as the coordinates of each data point in the PC space, x:\n\nhead(pca_res$x)\n\n           PC1        PC2         PC3          PC4\n[1,] -2.257141 -0.4784238  0.12727962  0.024087508\n[2,] -2.074013  0.6718827  0.23382552  0.102662845\n[3,] -2.356335  0.3407664 -0.04405390  0.028282305\n[4,] -2.291707  0.5953999 -0.09098530 -0.065735340\n[5,] -2.381863 -0.6446757 -0.01568565 -0.035802870\n[6,] -2.068701 -1.4842053 -0.02687825  0.006586116\n\n\nMany named list objects have a summary:\n\nsummary(pca_res)\n\nImportance of components:\n                          PC1    PC2     PC3     PC4\nStandard deviation     1.7084 0.9560 0.38309 0.14393\nProportion of Variance 0.7296 0.2285 0.03669 0.00518\nCumulative Proportion  0.7296 0.9581 0.99482 1.00000\n\n\nSome named list objects also have a class attribute. Named lists with a class attribute are also referred to as S3 objects. Or the other way around: S3 objects are named lists that have a class.\n\nclass(pca_res)\n\n[1] \"prcomp\"\n\n\nR uses the class to figure out how to process the object, for example inside summary(). So class is about what the object is whereas Type (as in typeof()) is about the structure of an object and how you can interact with it.\nBonus info: A ggplot is also an S3 object. Bet you didn’t know that!",
    "crumbs": [
      "Course Material",
      "Presentations",
      "R Objects: Named Lists"
    ]
  },
  {
    "objectID": "presentations/presentation2.html",
    "href": "presentations/presentation2.html",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "",
    "text": "In this section we will learn more about data manipulation in the tidyverse framework and how to get your data into the correct format for a task.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#load-packages",
    "href": "presentations/presentation2.html#load-packages",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(readxl)\nlibrary(tidyverse)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#load-data",
    "href": "presentations/presentation2.html#load-data",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Load data",
    "text": "Load data\n\ndf_sales &lt;- read_excel('../out/sales_data_2.xlsx')",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#formats-pivot-long-and-wider",
    "href": "presentations/presentation2.html#formats-pivot-long-and-wider",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Formats: Pivot long and wider",
    "text": "Formats: Pivot long and wider\nIn tidyverse we primarily use two different formats: long and wide. The wide format is how you are probably used to seeing data presented with one column for each measured variable. However, when we need to plot, analyse or model data, we will often need them to be in the long format instead. It is therefore important that we know how to switch between them.\n\nPivot into long format\nThe goal of this section is to make a plot like this where we visualize the sales for each year across each employee.\n\n\n\n\n\nThe data is now in wide format. Can we make the plot in the way the data is formatted now?\n\n Hint \n\nNo. To create the plot, we need a column for the years to use on the x-axis, a column for sales in thousands DKK, and a column for Names. While the Names column is already present, the sales data is spread across four separate columns, and there is no column for the year.\n\n\n\nhead(df_sales)\n\n# A tibble: 6 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female        100        110        120        100 happy\n2     2 Bob        30 Male          200        210        220        230 happy\n3     3 Charlie    22 Male          150        160        170        200 happy\n4     4 Sophie     35 Female        300        320        340        250 happy\n5     5 Eve        28 Female        250        240        250        270 happy\n6     6 Frank      NA Male           NA        260        270        280 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\nThe data set is in wide format. The data can be restructured to long format such that there is one line per year per person. For this we use the pivot_longer function.\n\ndf_sales_longer &lt;- df_sales %&gt;% \n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"year\",\n               values_to = \"sales\"\n               )\n\nhead(df_sales_longer)\n\n# A tibble: 6 × 10\n     ID Name    Age Sex    mood  raise group        City  year       sales\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n1     1 Alice    25 Female happy no    young_female Miami sales_2020   100\n2     1 Alice    25 Female happy no    young_female Miami sales_2021   110\n3     1 Alice    25 Female happy no    young_female Miami sales_2022   120\n4     1 Alice    25 Female happy no    young_female Miami sales_2023   100\n5     2 Bob      30 Male   happy yes   mature_male  Miami sales_2020   200\n6     2 Bob      30 Male   happy yes   mature_male  Miami sales_2021   210\n\n\nWe can transform the year to integer.\n\ndf_sales_longer &lt;- df_sales_longer %&gt;% \n  mutate(year = str_remove(year, 'sales_') %&gt;% as.integer()) \n\nhead(df_sales_longer)\n\n# A tibble: 6 × 10\n     ID Name    Age Sex    mood  raise group        City   year sales\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1     1 Alice    25 Female happy no    young_female Miami  2020   100\n2     1 Alice    25 Female happy no    young_female Miami  2021   110\n3     1 Alice    25 Female happy no    young_female Miami  2022   120\n4     1 Alice    25 Female happy no    young_female Miami  2023   100\n5     2 Bob      30 Male   happy yes   mature_male  Miami  2020   200\n6     2 Bob      30 Male   happy yes   mature_male  Miami  2021   210\n\n\nMake the plot explained above (scatter and line plot over the sales development over the years for each person).\n\ndf_sales_longer %&gt;% \n  ggplot(aes(x = year, \n             y = sales, \n             color = Name)) + \n  geom_point() + \n  geom_line() + \n  theme_bw()\n\n\n\n\n\n\n\n# Saving the plot\n# ggsave('../out/sales_2_plot.png', width = 10.37, height = 7.55, units = 'in')\n\n\n\nPivot back into wide format\nThe pivot_wider function is used to get data to wide format.\n\ndf_sales_wider &lt;- df_sales_longer %&gt;% \n  pivot_wider(names_from = year, \n              values_from = sales,\n              names_prefix = 'sales_')\n\n# Same content\nhead(df_sales)\n\n# A tibble: 6 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female        100        110        120        100 happy\n2     2 Bob        30 Male          200        210        220        230 happy\n3     3 Charlie    22 Male          150        160        170        200 happy\n4     4 Sophie     35 Female        300        320        340        250 happy\n5     5 Eve        28 Female        250        240        250        270 happy\n6     6 Frank      NA Male           NA        260        270        280 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\nhead(df_sales_wider)\n\n# A tibble: 6 × 12\n     ID Name      Age Sex    mood  raise group       City  sales_2020 sales_2021\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1     1 Alice      25 Female happy no    young_fema… Miami        100        110\n2     2 Bob        30 Male   happy yes   mature_male Miami        200        210\n3     3 Charlie    22 Male   happy yes   young_male  LA           150        160\n4     4 Sophie     35 Female happy no    mature_fem… New …        300        320\n5     5 Eve        28 Female happy yes   young_fema… LA           250        240\n6     6 Frank      NA Male   happy yes   &lt;NA&gt;        New …         NA        260\n# ℹ 2 more variables: sales_2022 &lt;dbl&gt;, sales_2023 &lt;dbl&gt;",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#nesting",
    "href": "presentations/presentation2.html#nesting",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Nesting",
    "text": "Nesting\nThe long format can contain many repetitions e.g. information on the sales employee in df_sales_longer is repeated for every year. Instead of having many nearly identical rows we can use nesting to have just one row with the employee information and the associated sales data in its own ‘mini-tibble’.\nWe’ll group data by Name and nest year and sales into a single column that we will name sales_data.\n\ndf_sales_longer_nested &lt;- df_sales_longer %&gt;%  \n  group_by(Name) %&gt;% \n  nest(sales_data = c(year, sales)) %&gt;% \n  ungroup()\n\nhead(df_sales_longer_nested)\n\n# A tibble: 6 × 9\n     ID Name      Age Sex    mood  raise group         City     sales_data      \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;    &lt;list&gt;          \n1     1 Alice      25 Female happy no    young_female  Miami    &lt;tibble [4 × 2]&gt;\n2     2 Bob        30 Male   happy yes   mature_male   Miami    &lt;tibble [4 × 2]&gt;\n3     3 Charlie    22 Male   happy yes   young_male    LA       &lt;tibble [4 × 2]&gt;\n4     4 Sophie     35 Female happy no    mature_female New York &lt;tibble [4 × 2]&gt;\n5     5 Eve        28 Female happy yes   young_female  LA       &lt;tibble [4 × 2]&gt;\n6     6 Frank      NA Male   happy yes   &lt;NA&gt;          New York &lt;tibble [4 × 2]&gt;\n\n\nYou can see that the newly made column sales_data has the data type list because it contains not one value per row, like City or group do, but instead an entire little tibble.\nNow we have a structured dataset which is more readable.\nNote: Nested data cannot be exported as an Excel or CSV file. Instead, you need to export it as an RDS file, a format specifically designed to save R objects.\nWe can extract the sales information for a particular employee using the pull function.\n\ndf_sales_longer_nested %&gt;% \n  filter(Name == 'Bob') %&gt;% \n  pull(sales_data)\n\n[[1]]\n# A tibble: 4 × 2\n   year sales\n  &lt;int&gt; &lt;dbl&gt;\n1  2020   200\n2  2021   210\n3  2022   220\n4  2023   230\n\n\nFor operations on the information contained in nested columns they first need to be unnested:\n\ndf_sales_longer_nested %&gt;%\n  unnest(sales_data) %&gt;%\n  summarise(mean_sales = mean(sales, na.rm = T))\n\n# A tibble: 1 × 1\n  mean_sales\n       &lt;dbl&gt;\n1       297.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#tidyverse-helpers-across-and-where",
    "href": "presentations/presentation2.html#tidyverse-helpers-across-and-where",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Tidyverse helpers: across() and where()",
    "text": "Tidyverse helpers: across() and where()\n\nUsing across() to select columns\nYou probably noticed that we used a function to help us to summarise() all columns in Presentation 1:\n\ndf_tidyverse %&gt;% summarise(across(everything(), ~ sum(is.na(.))))\n\nIn this section we will say a bit more about the so called tidyverse helpers such as across(), where(), and starts_with(). These helpers are useful when we want to apply a functions, i.e. summarise(), or mutate() to several columns.\nLet’s have an example. We know we can calculate the mean of each sales column like so:\n\ndf_sales %&gt;%\n  summarise(mean(sales_2020),\n            mean(sales_2021),\n            mean(sales_2022),\n            mean(sales_2023))\n\n# A tibble: 1 × 4\n  `mean(sales_2020)` `mean(sales_2021)` `mean(sales_2022)` `mean(sales_2023)`\n               &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1                 NA                300                 NA                305\n\n\nNote: We got some NAs because sales_2020 and 2022 contain NA values and we didn’t specify na.rm=TRUE. We will continue to see these in the below examples. Don’t worry about them for now, we will show you how to deal with them later!\nBut then we need to name every column we want to apply summarise to. across() instead lets us select the columns across which we want to apply summarise in a dynamic fashion:\n\ndf_sales %&gt;%\n  summarise(across(everything(), mean))\n\n# A tibble: 1 × 12\n     ID  Name   Age   Sex sales_2020 sales_2021 sales_2022 sales_2023  mood\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1   5.5    NA    NA    NA         NA        300         NA        305    NA\n# ℹ 3 more variables: raise &lt;dbl&gt;, group &lt;dbl&gt;, City &lt;dbl&gt;\n\n\nWe put the columns we want to select inside the brackets of across(). everything(), as you have probably guessed means all columns.\nWe will probably not want to calculate means on non-numeric columns, so let’s select only numeric columns. For that we need another helper caller where() that lets us select columns based on their properties, like data type.\n\ndf_sales %&gt;%\n  summarise(across(where(is.numeric), mean))\n\n# A tibble: 1 × 6\n     ID   Age sales_2020 sales_2021 sales_2022 sales_2023\n  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1   5.5    NA         NA        300         NA        305\n\n\nThere is another group of helpers that refers to column names:\n\nstarts_with()\nends_with()\ncontains()\n\nAnd we can use them to select only columns starting with ‘sales’:\n\ndf_sales %&gt;%\n  summarise(across(starts_with('sales'), mean))\n\n# A tibble: 1 × 4\n  sales_2020 sales_2021 sales_2022 sales_2023\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1         NA        300         NA        305\n\n\nIf the column names follow some pattern like ‘sales_XXXX’ we can also employ num_range to specify them:\n\ndf_sales %&gt;%\n  summarise(across(num_range('sales_', 2020:2023), mean))\n\n# A tibble: 1 × 4\n  sales_2020 sales_2021 sales_2022 sales_2023\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1         NA        300         NA        305\n\n\nLastly, we can always straight up supply the names of the columns we want to select in a vector:\n\ndf_sales %&gt;%\n  summarise(across(c(sales_2020, sales_2021), mean))\n\n# A tibble: 1 × 2\n  sales_2020 sales_2021\n       &lt;dbl&gt;      &lt;dbl&gt;\n1         NA        300\n\n\nAll these ways can be used to select columns in tidyverse, also outside of across(). As an example, you’ve already see starts_with() in the Long Format section when we selected the columns to convert with pivot_longer():\n\ndf_sales %&gt;% \n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"year\",\n               values_to = \"sales\")\n\n\n\nsummarise() becomes more powerful!\nAlright, so we now know how save ourselves from having to name every column we want to operate on, but what if we want to calculate several summary stats? There’s more to numbers than means!\nNow that we have across() we can supply summarise with a list of summary functions to execute:\n\ndf_sales %&gt;%\n  summarise(across(starts_with(\"sales\"), list(mean, sd, min, max)))\n\n# A tibble: 1 × 16\n  sales_2020_1 sales_2020_2 sales_2020_3 sales_2020_4 sales_2021_1 sales_2021_2\n         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1           NA           NA           NA           NA          300         131.\n# ℹ 10 more variables: sales_2021_3 &lt;dbl&gt;, sales_2021_4 &lt;dbl&gt;,\n#   sales_2022_1 &lt;dbl&gt;, sales_2022_2 &lt;dbl&gt;, sales_2022_3 &lt;dbl&gt;,\n#   sales_2022_4 &lt;dbl&gt;, sales_2023_1 &lt;dbl&gt;, sales_2023_2 &lt;dbl&gt;,\n#   sales_2023_3 &lt;dbl&gt;, sales_2023_4 &lt;dbl&gt;\n\n\nNow we get one long row with mean, sd, min and max for every column starting with sales. We’re probably not super happy with the column names sales_2020_1, sales_2020_2, ect, so let’s add names that contain the function we’re executing (mean, ect). In order for this to work we must also name the functions:\n\ndf_sales %&gt;%\n  summarise(across(starts_with(\"sales\"), \n                   list(mean = mean, sd = sd, min = min, max = max),\n                   .names = \"{.col}-{.fn}\"))\n\n# A tibble: 1 × 16\n  `sales_2020-mean` `sales_2020-sd` `sales_2020-min` `sales_2020-max`\n              &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n1                NA              NA               NA               NA\n# ℹ 12 more variables: `sales_2021-mean` &lt;dbl&gt;, `sales_2021-sd` &lt;dbl&gt;,\n#   `sales_2021-min` &lt;dbl&gt;, `sales_2021-max` &lt;dbl&gt;, `sales_2022-mean` &lt;dbl&gt;,\n#   `sales_2022-sd` &lt;dbl&gt;, `sales_2022-min` &lt;dbl&gt;, `sales_2022-max` &lt;dbl&gt;,\n#   `sales_2023-mean` &lt;dbl&gt;, `sales_2023-sd` &lt;dbl&gt;, `sales_2023-min` &lt;dbl&gt;,\n#   `sales_2023-max` &lt;dbl&gt;\n\n\nStill not your preferred format? You can probably pivot your way out of that!\n\ndf_sales %&gt;%\n  #run summarise on all sales columns\n  summarise(across(starts_with(\"sales\"), \n                   list(mean = mean, sd = sd, min = min, max = max),\n                   .names = \"{.col}-{.fn}\")) %&gt;%\n  #add reformating\n  pivot_longer(cols = everything(), \n               names_to = c(\"variable\", \"statistic\"), \n               names_sep = \"-\") %&gt;%\n  pivot_wider(names_from = statistic, values_from = value)\n\n# A tibble: 4 × 5\n  variable    mean    sd   min   max\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 sales_2020    NA   NA     NA    NA\n2 sales_2021   300  131.   110   510\n3 sales_2022    NA   NA     NA    NA\n4 sales_2023   305  131.   100   500",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#the-anonymous-function-and-.",
    "href": "presentations/presentation2.html#the-anonymous-function-and-.",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "The anonymous function: ~ and .",
    "text": "The anonymous function: ~ and .\nBut wait! We still have those pesky NAs in our summary stats. Let’s just add the na.rm=TRUE argument. To not have too many things going on at once we’ll only do mean() for now:\n\ndf_sales %&gt;%\n  summarise(across(starts_with(\"sales\"), \n                   list(mean = mean(na.rm = TRUE)),\n                   .names = \"{.col}-{.fn}\"))\n\nError in `summarise()`:\nℹ In argument: `across(...)`.\nCaused by error in `mean.default()`:\n! argument \"x\" is missing, with no default\n\n\nBrrrtt! We may not.\n\n\n\n\n\nWhy? We are requesting a function call across several columns and we’re doing it in shorthand. This is only permitted is there are no arguments to the function (mean(), sd(), ect). You will also notice that we didn’t use brackets after their names, which is part of using the function short hand.\nIf we need to pass arguments to functions inside another function call (i.e. calling mean inside summarise) we need to invoke the anonymous function. Don’t worry, it is much less ominous than it sounds! It is written as a ~ and looks like this:\n\ndf_sales %&gt;%\n  summarise(across(starts_with(\"sales\"), \n                   list(mean = ~ mean(., na.rm = TRUE)),\n                   .names = \"{.col}-{.fn}\"))\n\n# A tibble: 1 × 4\n  `sales_2020-mean` `sales_2021-mean` `sales_2022-mean` `sales_2023-mean`\n              &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1              294.               300              288.               305\n\n\nThe observant reader will also have noticed that a . has appeared in the brackets behind mean(). It simply means ‘the data previously referred to’, in this case every column starting with ‘sales’. We need to use the . because mean when called as a proper function needs to have an argument (a vector of numbers) to work on:\n\nmean(df_sales$sales_2020,na.rm=TRUE)\n\n[1] 294.4444\n\n\nSo this is it, we invoke the anonymous function for every statistic we want to calculate and now we may pass arguments:\n\ndf_sales %&gt;%\n  #across and starts_with selects columns\n  summarise(across(starts_with(\"sales\"), \n                   #list the functions to execute\n                   list(mean = ~ mean(., na.rm=T),\n                        sd = ~ sd(., na.rm=T), \n                        min = ~ min(., na.rm=T), \n                        max = ~ max(., na.rm=T)),\n                   #specify names of output columns\n                   .names = \"{.col}-{.fn}\")) %&gt;%\n  \n  #add reformating\n  pivot_longer(cols = everything(), \n               names_to = c(\"variable\", \"statistic\"), \n               names_sep = \"-\") %&gt;%\n  pivot_wider(names_from = statistic, values_from = value)\n\n# A tibble: 4 × 5\n  variable    mean    sd   min   max\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 sales_2020  294.  136.   100   500\n2 sales_2021  300   131.   110   510\n3 sales_2022  288.  115.   120   470\n4 sales_2023  305   131.   100   500\n\n\n\nOther usage examples\nThe anonymous function and across are also useful inside mutate()! Our data has sales in thousands DKK, so lets multiply every value in every sales column with 1000:\n\ndf_sales %&gt;% head(n=3)\n\n# A tibble: 3 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female        100        110        120        100 happy\n2     2 Bob        30 Male          200        210        220        230 happy\n3     3 Charlie    22 Male          150        160        170        200 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\n\ndf_sales %&gt;%\n  mutate(across(starts_with(\"sales\"), ~ . * 1000)) %&gt;%\n  head(n=3)\n\n# A tibble: 3 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female     100000     110000     120000     100000 happy\n2     2 Bob        30 Male       200000     210000     220000     230000 happy\n3     3 Charlie    22 Male       150000     160000     170000     200000 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\n\nWhat is happening here is we first select all columns starting with ‘sales’ by using across() and starts_with(). Then we say that we want to execute a function on each of these columns. The function shall be ‘multiply this column by 1000’. Multiplying by 1000 is written as * 1000 in R, ‘this column’ is . as we discussed before and ~ tells R that we’re executing a function.\nAnother cool example: Replacing NAs with 0s only in the columns starting with ‘sales’:\n\ndf_sales %&gt;%\n  mutate(across(starts_with(\"sales\"), ~ replace_na(.,0)))\n\n# A tibble: 10 × 12\n      ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n 1     1 Alice      25 Female        100        110        120        100 happy\n 2     2 Bob        30 Male          200        210        220        230 happy\n 3     3 Charlie    22 Male          150        160        170        200 happy\n 4     4 Sophie     35 Female        300        320        340        250 happy\n 5     5 Eve        28 Female        250        240        250        270 happy\n 6     6 Frank      NA Male            0        260        270        280 happy\n 7     7 Grace      40 Female        400        420        430        450 happy\n 8     8 Hannah     29 Female        500        510          0        500 happy\n 9     9 Ian        21 Male          450        460        470        480 happy\n10    10 Jack       33 Male          300        310        320        290 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\nThis is it for now but there will be user-defined functions later!",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation4_functions.html",
    "href": "presentations/presentation4_functions.html",
    "title": "Presentation 4, Functions",
    "section": "",
    "text": "Here we show the contents of presentation4_functions.R:\n\n\n# Packages should be loaded in the main script.\n\n# Function to calculate BMI\ncalculate_bmi &lt;- function(weight_kg, height_m){\n  \n  bmi &lt;- weight_kg/height_m^2\n  \n  return(bmi)\n  \n}\n\n# Function to calculate BMI, with control points and error checking. \ncalculate_bmi_2 &lt;- function(weight_kg, height_m) {\n  \n  # Check if weight and height are numeric\n  if (!is.numeric(weight_kg) | !is.numeric(height_m)) {\n    stop(\"Both weight_kg and height_m must be numeric values.\")\n  }\n  \n  # Check if weight and height are positive\n  if (weight_kg &lt;= 0) {\n    stop(\"Weight must be a positive value.\")\n  }\n  if (height_m &lt;= 0) {\n    stop(\"Height must be a positive value.\")\n  }\n  \n  # Calculate BMI\n  bmi &lt;- weight_kg / height_m^2\n  \n  # Check if BMI is within a reasonable range\n  if (bmi &lt; 10 | bmi &gt; 60) {\n    warning(\"The calculated BMI is outside the normal range. Please check your input values.\")\n  }\n  \n  return(bmi)\n  \n}",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4, Functions: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html",
    "href": "presentations/presentation5.html",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "",
    "text": "In this section we’ll look at how to define and fit a model in R.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#load-packages",
    "href": "presentations/presentation5.html#load-packages",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(caTools)\nlibrary(ModelMetrics)\nlibrary(ggfortify)\nlibrary(readxl)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#load-data",
    "href": "presentations/presentation5.html#load-data",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Load data",
    "text": "Load data\nIn order to focus on the technical aspects we’ll use a very simple toy dataset. It contains the number of cigarettes smoked per day and how long the person lived. It is inspired by this paper if you want to take a look.\n\ndf_smoke &lt;- as_tibble(read.csv('../data/smoking_cat.csv'))\ndf_smoke\n\n# A tibble: 100 × 3\n   daily_cigarettes  life exercise\n              &lt;int&gt; &lt;int&gt;    &lt;int&gt;\n 1                7    76        0\n 2               11    73        0\n 3               27    72        1\n 4               23    71        0\n 5               13    74        0\n 6               11    76        1\n 7               20    71        0\n 8                6    76        1\n 9               23    72        1\n10               32    70        2\n# ℹ 90 more rows\n\n\nWe will use this to perform a linear regression.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#linear-regression",
    "href": "presentations/presentation5.html#linear-regression",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nSplit Data into Training and Test Set\nFirst, we will split our data into a test and a training set. There are numerous ways to do this. We here show sample_frac from dplyr:\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#add an ID column to keep track of observations\ndf_smoke$ID &lt;- 1:nrow(df_smoke)\n\ntrain &lt;- df_smoke %&gt;% sample_frac(.75)\nnrow(train)\n\n[1] 75\n\nhead(train)\n\n# A tibble: 6 × 4\n  daily_cigarettes  life exercise    ID\n             &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt;\n1               29    72        1    31\n2               16    73        0    79\n3                5    78        1    51\n4                3    77        0    14\n5                4    79        2    67\n6               23    71        1    42\n\n\nAs you can see, the ID’s in train are shuffled and it only has 75 rows since we asked for 75% of the data. Now all we have to do is identify the other 25%, i.e. the observations not in train. dpylr has a neat function called anti_join for that:\n\n#from df_smoke remove what is in train by checking the ID column\ntest  &lt;- anti_join(df_smoke, train, by = 'ID') \nnrow(test)\n\n[1] 25\n\nhead(test)\n\n# A tibble: 6 × 4\n  daily_cigarettes  life exercise    ID\n             &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt;\n1                7    76        0     1\n2               11    73        0     2\n3               27    72        1     3\n4               32    70        2    10\n5                8    75        0    11\n6               16    75        2    24\n\n\n\n\nDefining the model\nAs stated above, a linear regression model generally has the form of:\n\\[y=b_0+b_1*x_i\\]\nWhere we refer to \\(b_0\\) as the intercept and \\(b_1\\) as the coefficient. There will typically be one coefficient for each predictor. The goal of modelling is to estimate the values of \\(b_0\\) and all \\(b_i\\).\nWe need to tell R which of our variables is the outcome, \\(y\\) and which predictors \\(x_i\\) we want to include in the model. This is referred to in documentation as the model’s formula. Have a look:\n\n#the formula is written like so:\nlm(y ~ x_1 + x_2 + ...)\n#see the help\n?lm\n\nIn our case, \\(y\\) is the number of years lived and we have a singular predictor \\(x_1\\), the number of cigarettes smoked per day. So that will be our model formulation:\n\n#remember to select the training data subset we defined above! \nmodel &lt;- lm(life ~ daily_cigarettes, data = train)\n\n\n\nModelling results\nBy calling lm we have already trained our model! The return of lm() is, just like the return of prcomp(), a named list.\n\ntypeof(model)\n\n[1] \"list\"\n\nclass(model)\n\n[1] \"lm\"\n\nnames(model)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\n\nLets have a look at the results. The summary gives us a lot of information about the model we trained:\n\n# View model summary\nsummary(model)\n\n\nCall:\nlm(formula = life ~ daily_cigarettes, data = train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.71479 -1.03035 -0.06517  0.82928  2.84669 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      78.71479    0.26847  293.20   &lt;2e-16 ***\ndaily_cigarettes -0.28074    0.01351  -20.77   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.251 on 73 degrees of freedom\nMultiple R-squared:  0.8553,    Adjusted R-squared:  0.8533 \nF-statistic: 431.5 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nIt beings with Call which displays the formula used to fit the model.\nThe Residuals section summarizes the distribution of the residuals, which is the difference between the actual observed \\(y\\) values and the fitted \\(y\\) values.\nThe Coefficients table shows the estimated values for each coefficient including the intercept, along with their standard errors, t-values, and p-values. These help to determine the significance of each predictor. Smaller p-values indicate stronger evidence against the null hypothesis that the true coefficient is zero.\nIn the bottom section we have some information about how well model fits the training data. The Residual Standard Error (RSE) provides a measure of accuracy as it represents the average size of the residuals. The R-squared value indicates the proportion of variance explained by the model, with the Adjusted R-squared accounting for the number of predictors to prevent overfitting. Finally, the F-statistic and its p-value test whether the model as a whole explains a significant portion of the variance in the response variable (the outcome \\(y\\)).\nOverall, the summary helps us to assess the model fit and identify significant predictors and their effect size (size of the coefficient).\nWe can extract the model object’s components with $:\n\nmodel$coefficients\n\n     (Intercept) daily_cigarettes \n      78.7147894       -0.2807398 \n\nhist(model$residuals, breaks = 30, main = 'Histogram of residuals', \n     xlab = 'Residual')\n\n\n\n\n\n\n\n\n\n\nModel interpretation\nWhat do these results mean? Our model formulation is:\n\\[life=b_0+b_1*cigarettes\\]\nAnd we estimated these values:\n\nmodel$coefficients\n\n     (Intercept) daily_cigarettes \n      78.7147894       -0.2807398 \n\n\nTherefore:\n\nThe intercept \\(b_0\\) is the number of years we estimated a person in this dataset will live if they smoke 0 cigarettes. It is 78.7 years\nThe coefficient of cigarettes per day is -0.28. This means for every 1 unit increase in cigarettes (one additional cigarette per day) the life expectancy decreases by 0.28 years.\n\n\n\nModel performance\nWe now use our held out test data to evaluate the model performance. For that we will predict life expectancy for the 25 observations in test and compare with the actual values.\n\n#use the fitted model to make predictions for the test data\ny_pred &lt;- predict(model, test)\ny_pred\n\n       1        2        3        4        5        6        7        8 \n76.74961 75.62665 71.13481 69.73112 76.46887 74.22295 77.59183 70.29260 \n       9       10       11       12       13       14       15       16 \n73.38073 70.01186 76.46887 75.62665 75.34591 76.46887 73.38073 75.34591 \n      17       18       19       20       21       22       23       24 \n76.18813 71.41555 73.66147 71.13481 71.97703 75.34591 72.25777 75.90739 \n      25 \n78.71479 \n\n\nLet’s see how that fits with the known values.\n\npred &lt;- tibble(pred = y_pred, real = test$life)\n\nggplot(pred, aes(x=real, y=pred)) +\n  geom_point()\n\n\n\n\n\n\n\n\nNot too bad! We usually calculate the mean square error (mse) between predictions and the known true values to numerically evaluate regression performance:\n\nmse(pred$real,pred$pred)\n\n[1] 1.742902\n\n\nOur predictions are on average 1.7 years wrong.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#regression-with-categorical-features",
    "href": "presentations/presentation5.html#regression-with-categorical-features",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Regression with categorical features",
    "text": "Regression with categorical features\nNow that we know how to make a simple linear model, how can we include categorical variables and what is the interpretation of their coefficients? To investigate this we include the other predictor variable we have: Exercise level.\n\ndistinct(df_smoke, exercise)\n\n# A tibble: 3 × 1\n  exercise\n     &lt;int&gt;\n1        0\n2        1\n3        2\n\n\nAlright, we have three different levels of exercise. They are: low == 0, moderate == 1 and high == 2. Before we go on, let’s have a look if our data is represented correctly:\n\nstr(df_smoke)\n\ntibble [100 × 4] (S3: tbl_df/tbl/data.frame)\n $ daily_cigarettes: int [1:100] 7 11 27 23 13 11 20 6 23 32 ...\n $ life            : int [1:100] 76 73 72 71 74 76 71 76 72 70 ...\n $ exercise        : int [1:100] 0 0 1 0 0 1 0 1 1 2 ...\n $ ID              : int [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n\n\nWe can see that the exercise column is interpreted as an integer. However, it is actually a category! In R categorical variables are known as factors and have their own datatype. Let’s convert exercise to a factor:\n\ndf_smoke$exercise &lt;- as.factor(df_smoke$exercise)\nstr(df_smoke)\n\ntibble [100 × 4] (S3: tbl_df/tbl/data.frame)\n $ daily_cigarettes: int [1:100] 7 11 27 23 13 11 20 6 23 32 ...\n $ life            : int [1:100] 76 73 72 71 74 76 71 76 72 70 ...\n $ exercise        : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 1 2 1 1 2 1 2 2 3 ...\n $ ID              : int [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n\n\nAs before, before fitting the model we’ll split up the data in train and test. Since we’re using the same seed we should get the same observations, i.e. rows into training and test as above.\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#add an ID column to keep track of observations\ndf_smoke$ID &lt;- 1:nrow(df_smoke)\n\ntrain &lt;- df_smoke %&gt;% sample_frac(.75)\ntest  &lt;- anti_join(df_smoke, train, by = 'ID') \n\nAnd now we extend our previous model formula with the new predictor:\n\nmodel2 &lt;- lm(life ~ daily_cigarettes + exercise, data = train)\n\n\nsummary(model2)\n\n\nCall:\nlm(formula = life ~ daily_cigarettes + exercise, data = train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.58295 -0.53972 -0.01596  0.53773  1.70257 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      77.582954   0.234237 331.216  &lt; 2e-16 ***\ndaily_cigarettes -0.285521   0.009401 -30.372  &lt; 2e-16 ***\nexercise1         1.095475   0.249402   4.392 3.84e-05 ***\nexercise2         2.372227   0.260427   9.109 1.48e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8578 on 71 degrees of freedom\nMultiple R-squared:  0.9338,    Adjusted R-squared:  0.931 \nF-statistic: 333.7 on 3 and 71 DF,  p-value: &lt; 2.2e-16\n\n\nWhen we check the summary we see that it has two additional coefficients, exercise1 and exercise2. What are they?\nBecause exercise is a categorical variable it is dummy coded. That means our model formula mathematically looks something like this:\n\\[y=b_0+b_1*x_1 + b_2 *x_2 + b_3*x_3\\]\nwith:\n\n\n\nExercise level\n\\(x_2\\)\n\\(x_3\\)\n\n\n\n\n0\n0\n0\n\n\n1\n1\n0\n\n\n2\n0\n1\n\n\n\nAnd for our coefficients it means:\n\nmodel2$coefficients\n\n     (Intercept) daily_cigarettes        exercise1        exercise2 \n      77.5829543       -0.2855213        1.0954747        2.3722266 \n\n\n\nIntercept == \\(b_0\\): The life expectancy at 0 cigarettes and exercise level 0\ndaily_cigerettes == \\(b_1\\): The change in life expectancy for each additional cigarette.\nexercise1 == \\(b_2\\): The change in life expectancy if the exercise level is 1 (assuming the number of cigarettes stays constant).\nexercise2 == \\(b_3\\): The change in life expectancy if the exercise level is 2 (assuming the number of cigarettes stays constant).\n\nWhy is there no coefficient for exercise level 0 (low amount of exercise)? This case is covered in the Intercept. It is referred to as the reference level of the categorical variable. You can change which level is regarded as the reference and the effect of having this level will always be modelled in the intercept.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#classification",
    "href": "presentations/presentation5.html#classification",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Classification",
    "text": "Classification\nClassification is what we apply when the outcome has two or more classes.\nIn order to have a categorical outcome, we’ll add a column to our toy data that describes whether the person died before age 75 or not.\n\ndf_smoke &lt;- df_smoke %&gt;%\n  mutate(early_death = factor(ifelse(life &lt; 75, 'yes', 'no')))\n\ndf_smoke %&gt;%\n  count(early_death)\n\n# A tibble: 2 × 2\n  early_death     n\n  &lt;fct&gt;       &lt;int&gt;\n1 no             49\n2 yes            51\n\n\n\nTraining and Test set with class data\nLet’s remake our training and test data. This time we have classes that we would like to be in the same ratios in training and test set. Therefore, we cannot just grab 75% of the data as we did before. We’ll use sample.split from caTools to achieve balanced classes:\n\n# Set seed to ensure reproducibility\nset.seed(123)\n\nsplit &lt;- sample.split(df_smoke$early_death, SplitRatio = 0.75)\n\n#split is a vector of true and false values we can now directly apply to our tibble\nsplit\n\n  [1]  TRUE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE\n [13]  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE\n [25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE  TRUE\n [37] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE\n [49]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [61]  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE\n [73]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE\n [85]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n [97]  TRUE  TRUE  TRUE  TRUE\n\ntrain &lt;- df_smoke[split,]\ntest &lt;- df_smoke[!split,] #! negates the vector, so true becomes false and vice verse\n\ncount(train,early_death)\n\n# A tibble: 2 × 2\n  early_death     n\n  &lt;fct&gt;       &lt;int&gt;\n1 no             37\n2 yes            38\n\ncount(test, early_death)\n\n# A tibble: 2 × 2\n  early_death     n\n  &lt;fct&gt;       &lt;int&gt;\n1 no             12\n2 yes            13\n\n\nNow we can perform logistic regression to see whether there is an influence of the number of cigarettes and amount of exercise on the odds of the person dying before 75.\nLogistic regression belongs to the family of generalized linear models. They all look like this:\n\\[ y \\sim \\beta * X \\]\nwith:\n\n\\(y\\) the outcome\n\\(\\beta\\) the coefficient matrix\n\\(X\\) the matrix of predictors\n\\(\\sim\\) the link function\n\nIn a logistic regression model the link function is the logit. In a linear model the link function is the identity function (so ~ becomes =).\n\n\nLogistic regression: Math\nIn order to understand what that means we’ll need a tiny bit of math.\nWe see some issues right of the bat. Our \\(y\\) is either 0 or 1 (the person is either dead or not). However we cannot model that so instead we will model the probability of the outcome being 1: \\(P(earlydeath == 1)\\). Except probabilities are bounded between 0 and 1 which is mathematically difficult to impose (it means all \\(y\\)’s have to be between these two values and how are we gonna enforce that?) So instead, we will model the log-odds of early death:\n\\[ y = \\log(\\frac{P(earlydeath == 1)}{1-P(earlydeath == 1)})\\]\nIt may not look like it but we promise you this \\(y\\) is a well behaved number because it can be anywhere between - infinity and + infinity. So therefore our actual model is:\n\\[ \\log(\\frac{P(earlydeath == 1)}{1-P(earlydeath == 1)} =  \\beta * X\\]\nAnd if we want to know what the means for the probability of dying we just take the logit of \\(y\\) :\n\\[ P(earlydeath == 1) = \\frac{1}{1+ e^{(-y)}} \\]\nWhich makes the link between what we’re actually interested in (people’s chances of dying) and what we’re modelling the logit. End of math.\n\n\nModel formulation in R\nSo in order to fit a logistic regression we will use the function for generalized linear models, glm. We will specify that we want logistic regression (using the logit as the link) by setting family = binomial:\n\nmodel_log &lt;- glm(early_death ~ daily_cigarettes + exercise, data = train, family = \"binomial\")\nsummary(model_log)\n\n\nCall:\nglm(formula = early_death ~ daily_cigarettes + exercise, family = \"binomial\", \n    data = train)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-1.49830  -0.08900   0.00052   0.01900   2.64289  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)      -11.0307     4.0190  -2.745  0.00606 **\ndaily_cigarettes   0.8380     0.2836   2.955  0.00313 **\nexercise1         -1.6493     2.0986  -0.786  0.43191   \nexercise2         -2.5922     2.4751  -1.047  0.29497   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 103.959  on 74  degrees of freedom\nResidual deviance:  13.717  on 71  degrees of freedom\nAIC: 21.717\n\nNumber of Fisher Scoring iterations: 8\n\n\n\n\nModel interpretation\nWe see from looking at the summary that the coefficient of exercise level 1 and level 2 is not significant. This means that we are not confident that doing a high amount of exercise (level 3) has a significant impact on the probability of dying before 75 compare to doing moderate or low amounts of exercise. This does not mean that there can be no influence, merely that we do not have enough data to detect it if it is there.\nAre you surprised? Exercise level was significant when we modelled the number of years lived, which is arguably a more fine-grained information than the binary split and perhaps therefore we picked up the influence.\nWith the number of daily cigarettes predictor we have a high degree of certainty that it influences the probability of dying before 75 (in this dataset!), but what does a coefficient of 0.84 mean?\nWe know that:\n\\[ P(earlydeath == 1) = \\frac{1}{1+ e^{(-y)}} \\]\nand (leaving out the exercise level since it’s not significant):\n\\[ y = \\beta_0 + \\beta_1 * cigs \\]\nSo how does \\(y\\) change as \\(0.84 * cigs\\) becomes larger? Let’s agree that \\(y\\) becomes larger. What does that mean for the probability of dying? Is \\(e^{(-y)}\\) a large number if \\(y\\) is large? Luckily we have a calculator handy\n\n#exp(b) is e^b in R\n\nexp(-1)\n\n[1] 0.3678794\n\nexp(-10)\n\n[1] 4.539993e-05\n\nexp(-100)\n\n[1] 3.720076e-44\n\n\nWe see that \\(e^{(-y)}\\) becomes increasingly smaller with larger \\(y\\) which means that\n\\[ P(earlydeath == 1) = \\frac{1}{1+ small} \\sim \\frac{1}{1} \\]\nSo the larger \\(y\\) the smaller \\(e^{(-y)}\\) and the closer we get to \\(P(earlydeath == 1)\\) being 1. That was a lot of math for: If the coefficient is positive you increase the likelihood of getting the outcome, i.e. dying.\n\n\nModel comparison\nSo now we know how to fit linear models and interpret the results. But often there are several predictors we could include or not include, so how do we know that one model is better than another?\nThere are several ways to compare models. One is the likelihood ratio test which tests whether adding predictors significantly improves model fit by comparing the log-likelihoods of the two models. Another much used comparison is to look at the AIC (Akaike Information Criterion) or BIC (Bayesian Information Criterion). Lower AIC/BIC values generally indicate a better trade-off between model fit and complexity.\nFor example we have made this model above:\n\nsummary(model_log)\n\n\nCall:\nglm(formula = early_death ~ daily_cigarettes + exercise, family = \"binomial\", \n    data = train)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-1.49830  -0.08900   0.00052   0.01900   2.64289  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)      -11.0307     4.0190  -2.745  0.00606 **\ndaily_cigarettes   0.8380     0.2836   2.955  0.00313 **\nexercise1         -1.6493     2.0986  -0.786  0.43191   \nexercise2         -2.5922     2.4751  -1.047  0.29497   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 103.959  on 74  degrees of freedom\nResidual deviance:  13.717  on 71  degrees of freedom\nAIC: 21.717\n\nNumber of Fisher Scoring iterations: 8\n\n\nBut exercise does not have a significant p-value. Perhaps we would have a better model if we only use dialy_cigarettes?\nLet’s compare them:\n\nmodel_reduced &lt;- glm(early_death ~ daily_cigarettes, data = train, family = \"binomial\")\nsummary(model_reduced)\n\n\nCall:\nglm(formula = early_death ~ daily_cigarettes, family = \"binomial\", \n    data = train)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-1.45758  -0.07341   0.00096   0.03880   2.56010  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)      -11.7674     3.7944  -3.101  0.00193 **\ndaily_cigarettes   0.7753     0.2547   3.044  0.00233 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 103.959  on 74  degrees of freedom\nResidual deviance:  15.006  on 73  degrees of freedom\nAIC: 19.006\n\nNumber of Fisher Scoring iterations: 8\n\n\nWe can use an anova with the Chi-square test to compare the log-likelihood of the two models:\n\nanova(model_log, model_reduced, test = 'Chisq')\n\nAnalysis of Deviance Table\n\nModel 1: early_death ~ daily_cigarettes + exercise\nModel 2: early_death ~ daily_cigarettes\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1        71     13.717                     \n2        73     15.006 -2  -1.2891   0.5249\n\n\nThe p-value of the Chi-square test tells us if there is evidence that the difference in log-likelihoods is significant. If it is not significant, we do not have evidence that one model is a better fit than the other and we would therefore choose the less complex model with fewer predictors since that gives us more statistical power and less overfitting.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#clustering",
    "href": "presentations/presentation5.html#clustering",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Clustering",
    "text": "Clustering\nClustering is a type of unsupervised learning technique used to group similar data points together based on their features. The goal is to find inherent patterns or structures within the data, e.g. to see whether the data points fall into distinct groups with distinct features or not.\n\nWine dataset\nFor this we will use the wine data set as an example:\n\nlibrary(ContaminatedMixt)\ndata('wine') #load dataset\ndf_wine &lt;- wine #convert to tibble\ndf_wine\n\n          Type Alcohol Malic  Ash Alcalinity Magnesium Phenols Flavanoids\n1       Barolo   14.23  1.71 2.43       15.6       127    2.80       3.06\n2       Barolo   13.20  1.78 2.14       11.2       100    2.65       2.76\n3       Barolo   13.16  2.36 2.67       18.6       101    2.80       3.24\n4       Barolo   14.37  1.95 2.50       16.8       113    3.85       3.49\n5       Barolo   13.24  2.59 2.87       21.0       118    2.80       2.69\n6       Barolo   14.20  1.76 2.45       15.2       112    3.27       3.39\n7       Barolo   14.39  1.87 2.45       14.6        96    2.50       2.52\n8       Barolo   14.06  2.15 2.61       17.6       121    2.60       2.51\n9       Barolo   14.83  1.64 2.17       14.0        97    2.80       2.98\n10      Barolo   13.86  1.35 2.27       16.0        98    2.98       3.15\n11      Barolo   14.10  2.16 2.30       18.0       105    2.95       3.32\n12      Barolo   14.12  1.48 2.32       16.8        95    2.20       2.43\n13      Barolo   13.75  1.73 2.41       16.0        89    2.60       2.76\n14      Barolo   14.75  1.73 2.39       11.4        91    3.10       3.69\n15      Barolo   14.38  1.87 2.38       12.0       102    3.30       3.64\n16      Barolo   13.63  1.81 2.70       17.2       112    2.85       2.91\n17      Barolo   14.30  1.92 2.72       20.0       120    2.80       3.14\n18      Barolo   13.83  1.57 2.62       20.0       115    2.95       3.40\n19      Barolo   14.19  1.59 2.48       16.5       108    3.30       3.93\n20      Barolo   13.64  3.10 2.56       15.2       116    2.70       3.03\n21      Barolo   14.06  1.63 2.28       16.0       126    3.00       3.17\n22      Barolo   12.93  3.80 2.65       18.6       102    2.41       2.41\n23      Barolo   13.71  1.86 2.36       16.6       101    2.61       2.88\n24      Barolo   12.85  1.60 2.52       17.8        95    2.48       2.37\n25      Barolo   13.50  1.81 2.61       20.0        96    2.53       2.61\n26      Barolo   13.05  2.05 3.22       25.0       124    2.63       2.68\n27      Barolo   13.39  1.77 2.62       16.1        93    2.85       2.94\n28      Barolo   13.30  1.72 2.14       17.0        94    2.40       2.19\n29      Barolo   13.87  1.90 2.80       19.4       107    2.95       2.97\n30      Barolo   14.02  1.68 2.21       16.0        96    2.65       2.33\n31      Barolo   13.73  1.50 2.70       22.5       101    3.00       3.25\n32      Barolo   13.58  1.66 2.36       19.1       106    2.86       3.19\n33      Barolo   13.68  1.83 2.36       17.2       104    2.42       2.69\n34      Barolo   13.76  1.53 2.70       19.5       132    2.95       2.74\n35      Barolo   13.51  1.80 2.65       19.0       110    2.35       2.53\n36      Barolo   13.48  1.81 2.41       20.5       100    2.70       2.98\n37      Barolo   13.28  1.64 2.84       15.5       110    2.60       2.68\n38      Barolo   13.05  1.65 2.55       18.0        98    2.45       2.43\n39      Barolo   13.07  1.50 2.10       15.5        98    2.40       2.64\n40      Barolo   14.22  3.99 2.51       13.2       128    3.00       3.04\n41      Barolo   13.56  1.71 2.31       16.2       117    3.15       3.29\n42      Barolo   13.41  3.84 2.12       18.8        90    2.45       2.68\n43      Barolo   13.88  1.89 2.59       15.0       101    3.25       3.56\n44      Barolo   13.24  3.98 2.29       17.5       103    2.64       2.63\n45      Barolo   13.05  1.77 2.10       17.0       107    3.00       3.00\n46      Barolo   14.21  4.04 2.44       18.9       111    2.85       2.65\n47      Barolo   14.38  3.59 2.28       16.0       102    3.25       3.17\n48      Barolo   13.90  1.68 2.12       16.0       101    3.10       3.39\n49      Barolo   14.10  2.02 2.40       18.8       103    2.75       2.92\n50      Barolo   13.94  1.73 2.27       17.4       108    2.88       3.54\n51      Barolo   13.05  1.73 2.04       12.4        92    2.72       3.27\n52      Barolo   13.83  1.65 2.60       17.2        94    2.45       2.99\n53      Barolo   13.82  1.75 2.42       14.0       111    3.88       3.74\n54      Barolo   13.77  1.90 2.68       17.1       115    3.00       2.79\n55      Barolo   13.74  1.67 2.25       16.4       118    2.60       2.90\n56      Barolo   13.56  1.73 2.46       20.5       116    2.96       2.78\n57      Barolo   14.22  1.70 2.30       16.3       118    3.20       3.00\n58      Barolo   13.29  1.97 2.68       16.8       102    3.00       3.23\n59      Barolo   13.72  1.43 2.50       16.7       108    3.40       3.67\n60  Grignolino   12.37  0.94 1.36       10.6        88    1.98       0.57\n61  Grignolino   12.33  1.10 2.28       16.0       101    2.05       1.09\n62  Grignolino   12.64  1.36 2.02       16.8       100    2.02       1.41\n63  Grignolino   13.67  1.25 1.92       18.0        94    2.10       1.79\n64  Grignolino   12.37  1.13 2.16       19.0        87    3.50       3.10\n65  Grignolino   12.17  1.45 2.53       19.0       104    1.89       1.75\n66  Grignolino   12.37  1.21 2.56       18.1        98    2.42       2.65\n67  Grignolino   13.11  1.01 1.70       15.0        78    2.98       3.18\n68  Grignolino   12.37  1.17 1.92       19.6        78    2.11       2.00\n69  Grignolino   13.34  0.94 2.36       17.0       110    2.53       1.30\n70  Grignolino   12.21  1.19 1.75       16.8       151    1.85       1.28\n71  Grignolino   12.29  1.61 2.21       20.4       103    1.10       1.02\n72  Grignolino   13.86  1.51 2.67       25.0        86    2.95       2.86\n73  Grignolino   13.49  1.66 2.24       24.0        87    1.88       1.84\n74  Grignolino   12.99  1.67 2.60       30.0       139    3.30       2.89\n75  Grignolino   11.96  1.09 2.30       21.0       101    3.38       2.14\n76  Grignolino   11.66  1.88 1.92       16.0        97    1.61       1.57\n77  Grignolino   13.03  0.90 1.71       16.0        86    1.95       2.03\n78  Grignolino   11.84  2.89 2.23       18.0       112    1.72       1.32\n79  Grignolino   12.33  0.99 1.95       14.8       136    1.90       1.85\n80  Grignolino   12.70  3.87 2.40       23.0       101    2.83       2.55\n81  Grignolino   12.00  0.92 2.00       19.0        86    2.42       2.26\n82  Grignolino   12.72  1.81 2.20       18.8        86    2.20       2.53\n83  Grignolino   12.08  1.13 2.51       24.0        78    2.00       1.58\n84  Grignolino   13.05  3.86 2.32       22.5        85    1.65       1.59\n85  Grignolino   11.84  0.89 2.58       18.0        94    2.20       2.21\n86  Grignolino   12.67  0.98 2.24       18.0        99    2.20       1.94\n87  Grignolino   12.16  1.61 2.31       22.8        90    1.78       1.69\n88  Grignolino   11.65  1.67 2.62       26.0        88    1.92       1.61\n89  Grignolino   11.64  2.06 2.46       21.6        84    1.95       1.69\n90  Grignolino   12.08  1.33 2.30       23.6        70    2.20       1.59\n91  Grignolino   12.08  1.83 2.32       18.5        81    1.60       1.50\n92  Grignolino   12.00  1.51 2.42       22.0        86    1.45       1.25\n93  Grignolino   12.69  1.53 2.26       20.7        80    1.38       1.46\n94  Grignolino   12.29  2.83 2.22       18.0        88    2.45       2.25\n95  Grignolino   11.62  1.99 2.28       18.0        98    3.02       2.26\n96  Grignolino   12.47  1.52 2.20       19.0       162    2.50       2.27\n97  Grignolino   11.81  2.12 2.74       21.5       134    1.60       0.99\n98  Grignolino   12.29  1.41 1.98       16.0        85    2.55       2.50\n99  Grignolino   12.37  1.07 2.10       18.5        88    3.52       3.75\n100 Grignolino   12.29  3.17 2.21       18.0        88    2.85       2.99\n101 Grignolino   12.08  2.08 1.70       17.5        97    2.23       2.17\n102 Grignolino   12.60  1.34 1.90       18.5        88    1.45       1.36\n103 Grignolino   12.34  2.45 2.46       21.0        98    2.56       2.11\n104 Grignolino   11.82  1.72 1.88       19.5        86    2.50       1.64\n105 Grignolino   12.51  1.73 1.98       20.5        85    2.20       1.92\n106 Grignolino   12.42  2.55 2.27       22.0        90    1.68       1.84\n107 Grignolino   12.25  1.73 2.12       19.0        80    1.65       2.03\n108 Grignolino   12.72  1.75 2.28       22.5        84    1.38       1.76\n109 Grignolino   12.22  1.29 1.94       19.0        92    2.36       2.04\n110 Grignolino   11.61  1.35 2.70       20.0        94    2.74       2.92\n111 Grignolino   11.46  3.74 1.82       19.5       107    3.18       2.58\n112 Grignolino   12.52  2.43 2.17       21.0        88    2.55       2.27\n113 Grignolino   11.76  2.68 2.92       20.0       103    1.75       2.03\n114 Grignolino   11.41  0.74 2.50       21.0        88    2.48       2.01\n115 Grignolino   12.08  1.39 2.50       22.5        84    2.56       2.29\n116 Grignolino   11.03  1.51 2.20       21.5        85    2.46       2.17\n117 Grignolino   11.82  1.47 1.99       20.8        86    1.98       1.60\n118 Grignolino   12.42  1.61 2.19       22.5       108    2.00       2.09\n119 Grignolino   12.77  3.43 1.98       16.0        80    1.63       1.25\n120 Grignolino   12.00  3.43 2.00       19.0        87    2.00       1.64\n121 Grignolino   11.45  2.40 2.42       20.0        96    2.90       2.79\n122 Grignolino   11.56  2.05 3.23       28.5       119    3.18       5.08\n123 Grignolino   12.42  4.43 2.73       26.5       102    2.20       2.13\n124 Grignolino   13.05  5.80 2.13       21.5        86    2.62       2.65\n125 Grignolino   11.87  4.31 2.39       21.0        82    2.86       3.03\n126 Grignolino   12.07  2.16 2.17       21.0        85    2.60       2.65\n127 Grignolino   12.43  1.53 2.29       21.5        86    2.74       3.15\n128 Grignolino   11.79  2.13 2.78       28.5        92    2.13       2.24\n129 Grignolino   12.37  1.63 2.30       24.5        88    2.22       2.45\n130 Grignolino   12.04  4.30 2.38       22.0        80    2.10       1.75\n131    Barbera   12.86  1.35 2.32       18.0       122    1.51       1.25\n132    Barbera   12.88  2.99 2.40       20.0       104    1.30       1.22\n133    Barbera   12.81  2.31 2.40       24.0        98    1.15       1.09\n134    Barbera   12.70  3.55 2.36       21.5       106    1.70       1.20\n135    Barbera   12.51  1.24 2.25       17.5        85    2.00       0.58\n136    Barbera   12.60  2.46 2.20       18.5        94    1.62       0.66\n137    Barbera   12.25  4.72 2.54       21.0        89    1.38       0.47\n138    Barbera   12.53  5.51 2.64       25.0        96    1.79       0.60\n139    Barbera   13.49  3.59 2.19       19.5        88    1.62       0.48\n140    Barbera   12.84  2.96 2.61       24.0       101    2.32       0.60\n141    Barbera   12.93  2.81 2.70       21.0        96    1.54       0.50\n142    Barbera   13.36  2.56 2.35       20.0        89    1.40       0.50\n143    Barbera   13.52  3.17 2.72       23.5        97    1.55       0.52\n144    Barbera   13.62  4.95 2.35       20.0        92    2.00       0.80\n145    Barbera   12.25  3.88 2.20       18.5       112    1.38       0.78\n146    Barbera   13.16  3.57 2.15       21.0       102    1.50       0.55\n147    Barbera   13.88  5.04 2.23       20.0        80    0.98       0.34\n148    Barbera   12.87  4.61 2.48       21.5        86    1.70       0.65\n149    Barbera   13.32  3.24 2.38       21.5        92    1.93       0.76\n150    Barbera   13.08  3.90 2.36       21.5       113    1.41       1.39\n151    Barbera   13.50  3.12 2.62       24.0       123    1.40       1.57\n152    Barbera   12.79  2.67 2.48       22.0       112    1.48       1.36\n153    Barbera   13.11  1.90 2.75       25.5       116    2.20       1.28\n154    Barbera   13.23  3.30 2.28       18.5        98    1.80       0.83\n155    Barbera   12.58  1.29 2.10       20.0       103    1.48       0.58\n156    Barbera   13.17  5.19 2.32       22.0        93    1.74       0.63\n157    Barbera   13.84  4.12 2.38       19.5        89    1.80       0.83\n158    Barbera   12.45  3.03 2.64       27.0        97    1.90       0.58\n159    Barbera   14.34  1.68 2.70       25.0        98    2.80       1.31\n160    Barbera   13.48  1.67 2.64       22.5        89    2.60       1.10\n161    Barbera   12.36  3.83 2.38       21.0        88    2.30       0.92\n162    Barbera   13.69  3.26 2.54       20.0       107    1.83       0.56\n163    Barbera   12.85  3.27 2.58       22.0       106    1.65       0.60\n164    Barbera   12.96  3.45 2.35       18.5       106    1.39       0.70\n165    Barbera   13.78  2.76 2.30       22.0        90    1.35       0.68\n166    Barbera   13.73  4.36 2.26       22.5        88    1.28       0.47\n167    Barbera   13.45  3.70 2.60       23.0       111    1.70       0.92\n168    Barbera   12.82  3.37 2.30       19.5        88    1.48       0.66\n169    Barbera   13.58  2.58 2.69       24.5       105    1.55       0.84\n170    Barbera   13.40  4.60 2.86       25.0       112    1.98       0.96\n171    Barbera   12.20  3.03 2.32       19.0        96    1.25       0.49\n172    Barbera   12.77  2.39 2.28       19.5        86    1.39       0.51\n173    Barbera   14.16  2.51 2.48       20.0        91    1.68       0.70\n174    Barbera   13.71  5.65 2.45       20.5        95    1.68       0.61\n175    Barbera   13.40  3.91 2.48       23.0       102    1.80       0.75\n176    Barbera   13.27  4.28 2.26       20.0       120    1.59       0.69\n177    Barbera   13.17  2.59 2.37       20.0       120    1.65       0.68\n178    Barbera   14.13  4.10 2.74       24.5        96    2.05       0.76\n    Nonflavanoid Proanthocyanins     Color   Hue Dilution Proline\n1           0.28            2.29  5.640000 1.040     3.92    1065\n2           0.26            1.28  4.380000 1.050     3.40    1050\n3           0.30            2.81  5.680000 1.030     3.17    1185\n4           0.24            2.18  7.800000 0.860     3.45    1480\n5           0.39            1.82  4.320000 1.040     2.93     735\n6           0.34            1.97  6.750000 1.050     2.85    1450\n7           0.30            1.98  5.250000 1.020     3.58    1290\n8           0.31            1.25  5.050000 1.060     3.58    1295\n9           0.29            1.98  5.200000 1.080     2.85    1045\n10          0.22            1.85  7.220000 1.010     3.55    1045\n11          0.22            2.38  5.750000 1.250     3.17    1510\n12          0.26            1.57  5.000000 1.170     2.82    1280\n13          0.29            1.81  5.600000 1.150     2.90    1320\n14          0.43            2.81  5.400000 1.250     2.73    1150\n15          0.29            2.96  7.500000 1.200     3.00    1547\n16          0.30            1.46  7.300000 1.280     2.88    1310\n17          0.33            1.97  6.200000 1.070     2.65    1280\n18          0.40            1.72  6.600000 1.130     2.57    1130\n19          0.32            1.86  8.700000 1.230     2.82    1680\n20          0.17            1.66  5.100000 0.960     3.36     845\n21          0.24            2.10  5.650000 1.090     3.71     780\n22          0.25            1.98  4.500000 1.030     3.52     770\n23          0.27            1.69  3.800000 1.110     4.00    1035\n24          0.26            1.46  3.930000 1.090     3.63    1015\n25          0.28            1.66  3.520000 1.120     3.82     845\n26          0.47            1.92  3.580000 1.130     3.20     830\n27          0.34            1.45  4.800000 0.920     3.22    1195\n28          0.27            1.35  3.950000 1.020     2.77    1285\n29          0.37            1.76  4.500000 1.250     3.40     915\n30          0.26            1.98  4.700000 1.040     3.59    1035\n31          0.29            2.38  5.700000 1.190     2.71    1285\n32          0.22            1.95  6.900000 1.090     2.88    1515\n33          0.42            1.97  3.840000 1.230     2.87     990\n34          0.50            1.35  5.400000 1.250     3.00    1235\n35          0.29            1.54  4.200000 1.100     2.87    1095\n36          0.26            1.86  5.100000 1.040     3.47     920\n37          0.34            1.36  4.600000 1.090     2.78     880\n38          0.29            1.44  4.250000 1.120     2.51    1105\n39          0.28            1.37  3.700000 1.180     2.69    1020\n40          0.20            2.08  5.100000 0.890     3.53     760\n41          0.34            2.34  6.130000 0.950     3.38     795\n42          0.27            1.48  4.280000 0.910     3.00    1035\n43          0.17            1.70  5.430000 0.880     3.56    1095\n44          0.32            1.66  4.360000 0.820     3.00     680\n45          0.28            2.03  5.040000 0.880     3.35     885\n46          0.30            1.25  5.240000 0.870     3.33    1080\n47          0.27            2.19  4.900000 1.040     3.44    1065\n48          0.21            2.14  6.100000 0.910     3.33     985\n49          0.32            2.38  6.200000 1.070     2.75    1060\n50          0.32            2.08  8.900000 1.120     3.10    1260\n51          0.17            2.91  7.200000 1.120     2.91    1150\n52          0.22            2.29  5.600000 1.240     3.37    1265\n53          0.32            1.87  7.050000 1.010     3.26    1190\n54          0.39            1.68  6.300000 1.130     2.93    1375\n55          0.21            1.62  5.850000 0.920     3.20    1060\n56          0.20            2.45  6.250000 0.980     3.03    1120\n57          0.26            2.03  6.380000 0.940     3.31     970\n58          0.31            1.66  6.000000 1.070     2.84    1270\n59          0.19            2.04  6.800000 0.890     2.87    1285\n60          0.28            0.42  1.950000 1.050     1.82     520\n61          0.63            0.41  3.270000 1.250     1.67     680\n62          0.53            0.62  5.750000 0.980     1.59     450\n63          0.32            0.73  3.800000 1.230     2.46     630\n64          0.19            1.87  4.450000 1.220     2.87     420\n65          0.45            1.03  2.950000 1.450     2.23     355\n66          0.37            2.08  4.600000 1.190     2.30     678\n67          0.26            2.28  5.300000 1.120     3.18     502\n68          0.27            1.04  4.680000 1.120     3.48     510\n69          0.55            0.42  3.170000 1.020     1.93     750\n70          0.14            2.50  2.850000 1.280     3.07     718\n71          0.37            1.46  3.050000 0.906     1.82     870\n72          0.21            1.87  3.380000 1.360     3.16     410\n73          0.27            1.03  3.740000 0.980     2.78     472\n74          0.21            1.96  3.350000 1.310     3.50     985\n75          0.13            1.65  3.210000 0.990     3.13     886\n76          0.34            1.15  3.800000 1.230     2.14     428\n77          0.24            1.46  4.600000 1.190     2.48     392\n78          0.43            0.95  2.650000 0.960     2.52     500\n79          0.35            2.76  3.400000 1.060     2.31     750\n80          0.43            1.95  2.570000 1.190     3.13     463\n81          0.30            1.43  2.500000 1.380     3.12     278\n82          0.26            1.77  3.900000 1.160     3.14     714\n83          0.40            1.40  2.200000 1.310     2.72     630\n84          0.61            1.62  4.800000 0.840     2.01     515\n85          0.22            2.35  3.050000 0.790     3.08     520\n86          0.30            1.46  2.620000 1.230     3.16     450\n87          0.43            1.56  2.450000 1.330     2.26     495\n88          0.40            1.34  2.600000 1.360     3.21     562\n89          0.48            1.35  2.800000 1.000     2.75     680\n90          0.42            1.38  1.740000 1.070     3.21     625\n91          0.52            1.64  2.400000 1.080     2.27     480\n92          0.50            1.63  3.600000 1.050     2.65     450\n93          0.58            1.62  3.050000 0.960     2.06     495\n94          0.25            1.99  2.150000 1.150     3.30     290\n95          0.17            1.35  3.250000 1.160     2.96     345\n96          0.32            3.28  2.600000 1.160     2.63     937\n97          0.14            1.56  2.500000 0.950     2.26     625\n98          0.29            1.77  2.900000 1.230     2.74     428\n99          0.24            1.95  4.500000 1.040     2.77     660\n100         0.45            2.81  2.300000 1.420     2.83     406\n101         0.26            1.40  3.300000 1.270     2.96     710\n102         0.29            1.35  2.450000 1.040     2.77     562\n103         0.34            1.31  2.800000 0.800     3.38     438\n104         0.37            1.42  2.060000 0.940     2.44     415\n105         0.32            1.48  2.940000 1.040     3.57     672\n106         0.66            1.42  2.700000 0.860     3.30     315\n107         0.37            1.63  3.400000 1.000     3.17     510\n108         0.48            1.63  3.300000 0.880     2.42     488\n109         0.39            2.08  2.700000 0.860     3.02     312\n110         0.29            2.49  2.650000 0.960     3.26     680\n111         0.24            3.58  2.900000 0.750     2.81     562\n112         0.26            1.22  2.000000 0.900     2.78     325\n113         0.60            1.05  3.800000 1.230     2.50     607\n114         0.42            1.44  3.080000 1.100     2.31     434\n115         0.43            1.04  2.900000 0.930     3.19     385\n116         0.52            2.01  1.900000 1.710     2.87     407\n117         0.30            1.53  1.950000 0.950     3.33     495\n118         0.34            1.61  2.060000 1.060     2.96     345\n119         0.43            0.83  3.400000 0.700     2.12     372\n120         0.37            1.87  1.280000 0.930     3.05     564\n121         0.32            1.83  3.250000 0.800     3.39     625\n122         0.47            1.87  6.000000 0.930     3.69     465\n123         0.43            1.71  2.080000 0.920     3.12     365\n124         0.30            2.01  2.600000 0.730     3.10     380\n125         0.21            2.91  2.800000 0.750     3.64     380\n126         0.37            1.35  2.760000 0.860     3.28     378\n127         0.39            1.77  3.940000 0.690     2.84     352\n128         0.58            1.76  3.000000 0.970     2.44     466\n129         0.40            1.90  2.120000 0.890     2.78     342\n130         0.42            1.35  2.600000 0.790     2.57     580\n131         0.21            0.94  4.100000 0.760     1.29     630\n132         0.24            0.83  5.400000 0.740     1.42     530\n133         0.27            0.83  5.700000 0.660     1.36     560\n134         0.17            0.84  5.000000 0.780     1.29     600\n135         0.60            1.25  5.450000 0.750     1.51     650\n136         0.63            0.94  7.100000 0.730     1.58     695\n137         0.53            0.80  3.850000 0.750     1.27     720\n138         0.63            1.10  5.000000 0.820     1.69     515\n139         0.58            0.88  5.700000 0.810     1.82     580\n140         0.53            0.81  4.920000 0.890     2.15     590\n141         0.53            0.75  4.600000 0.770     2.31     600\n142         0.37            0.64  5.600000 0.700     2.47     780\n143         0.50            0.55  4.350000 0.890     2.06     520\n144         0.47            1.02  4.400000 0.910     2.05     550\n145         0.29            1.14  8.210000 0.650     2.00     855\n146         0.43            1.30  4.000000 0.600     1.68     830\n147         0.40            0.68  4.900000 0.580     1.33     415\n148         0.47            0.86  7.650000 0.540     1.86     625\n149         0.45            1.25  8.420000 0.550     1.62     650\n150         0.34            1.14  9.400000 0.570     1.33     550\n151         0.22            1.25  8.600000 0.590     1.30     500\n152         0.24            1.26 10.800000 0.480     1.47     480\n153         0.26            1.56  7.100000 0.610     1.33     425\n154         0.61            1.87 10.520000 0.560     1.51     675\n155         0.53            1.40  7.600000 0.580     1.55     640\n156         0.61            1.55  7.900000 0.600     1.48     725\n157         0.48            1.56  9.010000 0.570     1.64     480\n158         0.63            1.14  7.500000 0.670     1.73     880\n159         0.53            2.70 13.000000 0.570     1.96     660\n160         0.52            2.29 11.750000 0.570     1.78     620\n161         0.50            1.04  7.650000 0.560     1.58     520\n162         0.50            0.80  5.880000 0.960     1.82     680\n163         0.60            0.96  5.580000 0.870     2.11     570\n164         0.40            0.94  5.280000 0.680     1.75     675\n165         0.41            1.03  9.580000 0.700     1.68     615\n166         0.52            1.15  6.620000 0.780     1.75     520\n167         0.43            1.46 10.680000 0.850     1.56     695\n168         0.40            0.97 10.260000 0.720     1.75     685\n169         0.39            1.54  8.660000 0.740     1.80     750\n170         0.27            1.11  8.500000 0.670     1.92     630\n171         0.40            0.73  5.500000 0.660     1.83     510\n172         0.48            0.64  9.899999 0.570     1.63     470\n173         0.44            1.24  9.700000 0.620     1.71     660\n174         0.52            1.06  7.700000 0.640     1.74     740\n175         0.43            1.41  7.300000 0.700     1.56     750\n176         0.43            1.35 10.200000 0.590     1.56     835\n177         0.53            1.46  9.300000 0.600     1.62     840\n178         0.56            1.35  9.200000 0.610     1.60     560\n\n\nThis dataset contains 178 wine, each corresponding to one of three different cultivars of wine. It has 13 numerical columns that record different features of the wine.\nWe will try out a popular method, k-means clustering. It works by initializing K centroids and assigning each data point to the nearest centroid. The algorithm then recalculates the centroids as the mean of the points in each cluster, repeating the process until the clusters stabilize. You can see an illustration of the process below. Its weakness is that we need to define the number of centroids, i.e. clusters, beforehand.\n\n\n\n\n\n\n\nRunning k-means\nFor k-means it is very important that the data is numeric and scaled so we will do that before running the algorithm.\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#run kmeans\nkmeans_res &lt;- df_wine %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  kmeans(centers = 4, nstart = 25)\n\nkmeans_res\n\nK-means clustering with 4 clusters of sizes 28, 56, 49, 45\n\nCluster means:\n     Alcohol       Malic        Ash Alcalinity   Magnesium    Phenols\n1 -0.7869073  0.04195151  0.2157781  0.3683284  0.43818899  0.6543578\n2  0.9580555 -0.37748461  0.1969019 -0.8214121  0.39943022  0.9000233\n3  0.1860184  0.90242582  0.2485092  0.5820616 -0.05049296 -0.9857762\n4 -0.9051690 -0.53898599 -0.6498944  0.1592193 -0.71473842 -0.4537841\n  Flavanoids Nonflavanoid Proanthocyanins      Color        Hue    Dilution\n1  0.5746004   -0.5429201       0.8888549 -0.7346332  0.2830335  0.60628629\n2  0.9848901   -0.6204018       0.5575193  0.2423047  0.4799084  0.76926636\n3 -1.2327174    0.7148253      -0.7474990  0.9857177 -1.1879477 -1.29787850\n4 -0.2408779    0.3315072      -0.4329238 -0.9177666  0.5202140  0.07869143\n     Proline\n1 -0.5169332\n2  1.2184972\n3 -0.3789756\n4 -0.7820425\n\nClustering vector:\n  [1] 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2\n [38] 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 1 4 1 2 4 4 1 4 1 4 1\n [75] 1 4 4 4 1 1 4 4 4 3 1 4 4 4 4 4 4 4 4 1 1 1 1 4 1 1 4 4 1 4 4 4 4 4 4 1 1\n[112] 4 4 4 4 4 4 4 4 4 1 1 1 1 1 4 1 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[149] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n\nWithin cluster sum of squares by cluster:\n[1] 307.0966 268.5747 302.9915 289.9515\n (between_SS / total_SS =  49.2 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nWe get a lot of results. kmeans_res$cluster is the cluster assigned to every wine bottle, i.e. row:\n\nkmeans_res$cluster\n\n  [1] 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2\n [38] 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 1 4 1 2 4 4 1 4 1 4 1\n [75] 1 4 4 4 1 1 4 4 4 3 1 4 4 4 4 4 4 4 4 1 1 1 1 4 1 1 4 4 1 4 4 4 4 4 4 1 1\n[112] 4 4 4 4 4 4 4 4 4 1 1 1 1 1 4 1 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[149] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n\n\nAnd kmeans_res$centers shows us at which values the centroids are:\n\nkmeans_res$centers\n\n     Alcohol       Malic        Ash Alcalinity   Magnesium    Phenols\n1 -0.7869073  0.04195151  0.2157781  0.3683284  0.43818899  0.6543578\n2  0.9580555 -0.37748461  0.1969019 -0.8214121  0.39943022  0.9000233\n3  0.1860184  0.90242582  0.2485092  0.5820616 -0.05049296 -0.9857762\n4 -0.9051690 -0.53898599 -0.6498944  0.1592193 -0.71473842 -0.4537841\n  Flavanoids Nonflavanoid Proanthocyanins      Color        Hue    Dilution\n1  0.5746004   -0.5429201       0.8888549 -0.7346332  0.2830335  0.60628629\n2  0.9848901   -0.6204018       0.5575193  0.2423047  0.4799084  0.76926636\n3 -1.2327174    0.7148253      -0.7474990  0.9857177 -1.1879477 -1.29787850\n4 -0.2408779    0.3315072      -0.4329238 -0.9177666  0.5202140  0.07869143\n     Proline\n1 -0.5169332\n2  1.2184972\n3 -0.3789756\n4 -0.7820425\n\n\nFor example the center of cluster 1 is placed at the coordinates -0.79 for Alcohol, 0.04 for Malic Acid, 0.22 for Ash and so on. Since our data has 13 dimensions, i.e. features, the cluster centers also do.\nThis is not super practical if we would like to visually inspect the clustering since we cannot plot in 13 dimensions. How could we solve this?\n\n\nVisualizing k-means results\nWe would like to see where our wine bottles and their clusters lie in a low-dimensional space so we will calculate a PCA of the wine data and map the cluster centers to the PCA space.\nSince we want the PCA space and the clustering to have the same mapping we’ll scale the data before running prcomp(). Basically we are making sure that the PCA is calculated on the same data as we passed into the clustering algorithm.\n\npca_wine &lt;- df_wine %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  prcomp()\n\nLet’s have a look. Since there is no missing data in this set we can easily use the original dataframe to color by wine type:\n\nautoplot(pca_wine, data = df_wine, color = 'Type',\n         loadings = TRUE, loadings.colour = \"grey30\", \n         loadings.label.colour = \"black\",\n         loadings.label = TRUE, loadings.label.size = 3.5,\n         scale = 0)\n\n\n\n\n\n\n\n\nNow we would like to add the cluster centriods to the plot. Just as a wine bottle with 13 dimensions has a certain PC1/PC2 coordinate, the centriod also does:\n\n#this is the first wine bottle in the set\ndf_wine[1,]\n\n    Type Alcohol Malic  Ash Alcalinity Magnesium Phenols Flavanoids\n1 Barolo   14.23  1.71 2.43       15.6       127     2.8       3.06\n  Nonflavanoid Proanthocyanins Color  Hue Dilution Proline\n1         0.28            2.29  5.64 1.04     3.92    1065\n\n\n\n#this bottle is placed at -3.3/1.4 in the PCA plot\npca_wine$x[1,]\n\n        PC1         PC2         PC3         PC4         PC5         PC6 \n-3.30742097  1.43940225 -0.16527283  0.21502463  0.69109335  0.22325037 \n        PC7         PC8         PC9        PC10        PC11        PC12 \n 0.59474883 -0.06495586 -0.63963836  1.01808396  0.45029317  0.53928914 \n       PC13 \n-0.06605231 \n\n\nWe can find the PC1/PC2 coordinates of cluster 1, 2 and 3 by putting their position in the original 13-dim space into the PCA object:\n\n#project cluster centers from kmeans into the pca space\ncenters_pca &lt;- predict(pca_wine, newdata = kmeans_res$centers)\ncenters_pca\n\n         PC1        PC2         PC3         PC4        PC5         PC6\n1 -1.0206234 -0.8723669  1.09853134 -0.60290901  0.7830261 -0.09575498\n2 -2.3751274  0.9408631 -0.32103480  0.10604257 -0.2867197  0.19871649\n3  2.7362113  1.2107751 -0.17674684 -0.07667507  0.0919792 -0.10663848\n4  0.6113385 -1.9464455 -0.09156296  0.32666993 -0.2305646 -0.07159330\n           PC7          PC8           PC9        PC10        PC11          PC12\n1  0.186100194 -0.136838314 -0.0104191856 -0.13765106  0.09655731 -0.0858676784\n2 -0.008947737 -0.005075841  0.0739699820  0.06932845 -0.01239409  0.0008655842\n3 -0.072766741  0.040644444  0.0002573087 -0.05571503  0.00485592  0.0042899679\n4 -0.025425819  0.047203159 -0.0858486648  0.06004162 -0.04994390  0.0476803079\n         PC13\n1 -0.09281421\n2  0.04132451\n3 -0.06520735\n4  0.07732857\n\nkmeans_res$centers\n\n     Alcohol       Malic        Ash Alcalinity   Magnesium    Phenols\n1 -0.7869073  0.04195151  0.2157781  0.3683284  0.43818899  0.6543578\n2  0.9580555 -0.37748461  0.1969019 -0.8214121  0.39943022  0.9000233\n3  0.1860184  0.90242582  0.2485092  0.5820616 -0.05049296 -0.9857762\n4 -0.9051690 -0.53898599 -0.6498944  0.1592193 -0.71473842 -0.4537841\n  Flavanoids Nonflavanoid Proanthocyanins      Color        Hue    Dilution\n1  0.5746004   -0.5429201       0.8888549 -0.7346332  0.2830335  0.60628629\n2  0.9848901   -0.6204018       0.5575193  0.2423047  0.4799084  0.76926636\n3 -1.2327174    0.7148253      -0.7474990  0.9857177 -1.1879477 -1.29787850\n4 -0.2408779    0.3315072      -0.4329238 -0.9177666  0.5202140  0.07869143\n     Proline\n1 -0.5169332\n2  1.2184972\n3 -0.3789756\n4 -0.7820425\n\n\nLet’s make this into a dataframe and add labels:\n\n#project cluster centers from kmeans into the pca space\ncenters_pca &lt;- predict(pca_wine, newdata = kmeans_res$centers) %&gt;% as.data.frame()\n# Label clusters\ncenters_pca$cluster &lt;- as.factor(1:nrow(centers_pca))  \ncenters_pca\n\n         PC1        PC2         PC3         PC4        PC5         PC6\n1 -1.0206234 -0.8723669  1.09853134 -0.60290901  0.7830261 -0.09575498\n2 -2.3751274  0.9408631 -0.32103480  0.10604257 -0.2867197  0.19871649\n3  2.7362113  1.2107751 -0.17674684 -0.07667507  0.0919792 -0.10663848\n4  0.6113385 -1.9464455 -0.09156296  0.32666993 -0.2305646 -0.07159330\n           PC7          PC8           PC9        PC10        PC11          PC12\n1  0.186100194 -0.136838314 -0.0104191856 -0.13765106  0.09655731 -0.0858676784\n2 -0.008947737 -0.005075841  0.0739699820  0.06932845 -0.01239409  0.0008655842\n3 -0.072766741  0.040644444  0.0002573087 -0.05571503  0.00485592  0.0042899679\n4 -0.025425819  0.047203159 -0.0858486648  0.06004162 -0.04994390  0.0476803079\n         PC13 cluster\n1 -0.09281421       1\n2  0.04132451       2\n3 -0.06520735       3\n4  0.07732857       4\n\n\nAlright! The last step is to add these 4 points, one for each cluster, to the autoplot. Did you know you can add ggplot geoms to autoplots?\n\nautoplot(pca_wine, data = df_wine, color = 'Type',\n         loadings = TRUE, loadings.colour = \"grey30\", \n         loadings.label.colour = \"black\",\n         loadings.label = TRUE, loadings.label.size = 3.5,\n         scale = 0) +\n  # Cluster centers\n  geom_point(data = centers_pca, aes(x = PC1, y = PC2, color = cluster),\n             shape = 8, size = 6, stroke = 2)\n\n\n\n\n\n\n\n\nWe are still coloring the PCA plot by the known wine type. Let’s switch it to instead display which cluster each bottle has been assigned to by k-means:\n\n#add cluster info to the dataframe\ndf_wine$Cluster &lt;- factor(kmeans_res$cluster)\n\nautoplot(pca_wine, data = df_wine, color = 'Cluster',\n         loadings = TRUE, loadings.colour = \"grey30\", \n         loadings.label.colour = \"black\",\n         loadings.label = TRUE, loadings.label.size = 3.5,\n         scale = 0) +\n  # Cluster centers\n  geom_point(data = centers_pca, aes(x = PC1, y = PC2, color = cluster),\n             shape = 8, size = 6, stroke = 2)\n\n\n\n\n\n\n\n\nWell the centroids are in the middle of their respective clusters but this does not look ideal. Perhaps 4 is not the best number of clusters for this dataset.\n\n\nOptimal number of clusters\nThere are several ways to investigate the ideal number of clusters and fviz_nbclust from the factoextra package provides three of them:\nThe so-called elbow method observes how the sum of squared errors (sse) changes as we vary the number of clusters. This is also sometimes referred to as “within sum of square” (wss).\n\nlibrary(factoextra)\n\nWarning: pakke 'factoextra' blev bygget under R version 4.2.3\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\ndf_wine %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  fviz_nbclust(kmeans, method = \"wss\")\n\n\n\n\n\n\n\n\nThe silhouette coefficient is a measure of cluster cohesion and separation. It quantifies how well a data point fits into its assigned cluster, by looking at how close it is to other points in its cluster and how far from points of other clusters. You need to have at least 2 clusters for the silhouette coefficient to be defined.\nUnlike the elbow of the sums of square errors, the silhouette score is supposed to peak:\n\ndf_wine %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  fviz_nbclust(kmeans, method = \"silhouette\")\n\n\n\n\n\n\n\n\nThe gap statistic compares the within-cluster variation (how compact the clusters are) for different values of K to the expected variation under a null reference distribution (i.e., random clustering).\n\ndf_wine %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  fviz_nbclust(kmeans, method = \"gap_stat\")\n\n\n\n\n\n\n\n\nAll three of them tell us there should be three clusters and we also know there are three cultivars of wine in the dataset. Let’s redo k-means with three centroids.\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#run kmeans\nkmeans_res &lt;- df_wine %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  kmeans(centers = 3, nstart = 25)\n\n#project cluster centers from kmeans into the pca space\ncenters_pca &lt;- predict(pca_wine, newdata = kmeans_res$centers) %&gt;% as.data.frame()\n# Label clusters\ncenters_pca$cluster &lt;- as.factor(1:nrow(centers_pca))\ncenters_pca\n\n          PC1        PC2          PC3         PC4         PC5         PC6\n1  2.71238444  1.1224849 -0.238420685 -0.06228125  0.07346875 -0.09964414\n2 -2.26979079  0.9294322  0.001523733  0.13511700 -0.13453261  0.21766922\n3  0.03685265 -1.7672542  0.185615130 -0.08001400  0.07067870 -0.12944063\n           PC7          PC8         PC9        PC10         PC11         PC12\n1 -0.060213318  0.007367207 -0.01997059 -0.06129547  0.008093155 -0.003445464\n2  0.051963343 -0.024894027  0.05014407  0.07446923 -0.021230820  0.007417378\n3 -0.002320739  0.017964647 -0.03216049 -0.02293882  0.013900922 -0.004371673\n          PC13 cluster\n1 -0.050408713       1\n2  0.050476861       2\n3 -0.008595707       3\n\n\n\n#add updated cluster info to the dataframe\ndf_wine$Cluster &lt;- factor(kmeans_res$cluster)\n\nautoplot(pca_wine, data = df_wine, color = 'Cluster',\n         loadings = TRUE, loadings.colour = \"grey30\", \n         loadings.label.colour = \"black\",\n         loadings.label = TRUE, loadings.label.size = 3.5,\n         scale = 0) +\n  # Cluster centers\n  geom_point(data = centers_pca, aes(x = PC1, y = PC2, color = cluster),\n             shape = 8, size = 6, stroke = 2)\n\n\n\n\n\n\n\n\nIndeed this looks better!\nThat concludes our foray into modelling for now and it’s time for the exercise.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/s4_objects.html",
    "href": "presentations/s4_objects.html",
    "title": "R Objects: S4 Objects",
    "section": "",
    "text": "Bioconductor packages often use S4 objects to store their data. Some examples:\n\n(Ranged)SummarizedExperiment is an object that holds rectangular matrices of high-throughput omics data (RNA-Seq, ChIP-Seq, ATAC-Seq)\npyholoseq is an objects that stores phylogenetic data such as OTU tables, taxonomy ect for e.g. microbiome and general metagenomics\nDESeqDataSet is an object that stores counts, transformations and metadata for RNAseq analysis. It is subclass of (Ranged)SummarizedExperiment\n\nUnlike the S3 objects (named lists with a class) we looked at before, S4 objects have clearly defined elements called ‘slots’.\nA slot must have:\n\na name\na defined data type\nit may have validation rules\n\nThey are usually accessed by specialized functions. Let’s have a look at a SummarizedExperiment objects.\n\n\n\nlibrary(SummarizedExperiment)\n\nIndlæser krævet pakke: MatrixGenerics\n\n\nIndlæser krævet pakke: matrixStats\n\n\n\nVedhæfter pakke: 'MatrixGenerics'\n\n\nDe følgende objekter er maskerede fra 'package:matrixStats':\n\n    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n    colWeightedMeans, colWeightedMedians, colWeightedSds,\n    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n    rowWeightedSds, rowWeightedVars\n\n\nIndlæser krævet pakke: GenomicRanges\n\n\nIndlæser krævet pakke: stats4\n\n\nIndlæser krævet pakke: BiocGenerics\n\n\n\nVedhæfter pakke: 'BiocGenerics'\n\n\nDe følgende objekter er maskerede fra 'package:stats':\n\n    IQR, mad, sd, var, xtabs\n\n\nDe følgende objekter er maskerede fra 'package:base':\n\n    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n    Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort,\n    table, tapply, union, unique, unsplit, which.max, which.min\n\n\nIndlæser krævet pakke: S4Vectors\n\n\n\nVedhæfter pakke: 'S4Vectors'\n\n\nDe følgende objekter er maskerede fra 'package:base':\n\n    expand.grid, I, unname\n\n\nIndlæser krævet pakke: IRanges\n\n\n\nVedhæfter pakke: 'IRanges'\n\n\nDet følgende objekt er maskeret fra 'package:grDevices':\n\n    windows\n\n\nIndlæser krævet pakke: GenomeInfoDb\n\n\nIndlæser krævet pakke: Biobase\n\n\nWelcome to Bioconductor\n\n    Vignettes contain introductory material; view with\n    'browseVignettes()'. To cite Bioconductor, see\n    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n\n\n\nVedhæfter pakke: 'Biobase'\n\n\nDet følgende objekt er maskeret fra 'package:MatrixGenerics':\n\n    rowMedians\n\n\nDe følgende objekter er maskerede fra 'package:matrixStats':\n\n    anyMissing, rowMedians\n\nlibrary(airway)\nlibrary(tidyverse)\n\nWarning: pakke 'ggplot2' blev bygget under R version 4.2.3\n\n\nWarning: pakke 'tibble' blev bygget under R version 4.2.3\n\n\nWarning: pakke 'dplyr' blev bygget under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ lubridate::%within%() masks IRanges::%within%()\n✖ dplyr::collapse()     masks IRanges::collapse()\n✖ dplyr::combine()      masks Biobase::combine(), BiocGenerics::combine()\n✖ dplyr::count()        masks matrixStats::count()\n✖ dplyr::desc()         masks IRanges::desc()\n✖ tidyr::expand()       masks S4Vectors::expand()\n✖ dplyr::filter()       masks stats::filter()\n✖ dplyr::first()        masks S4Vectors::first()\n✖ dplyr::lag()          masks stats::lag()\n✖ ggplot2::Position()   masks BiocGenerics::Position(), base::Position()\n✖ purrr::reduce()       masks GenomicRanges::reduce(), IRanges::reduce()\n✖ dplyr::rename()       masks S4Vectors::rename()\n✖ lubridate::second()   masks S4Vectors::second()\n✖ lubridate::second&lt;-() masks S4Vectors::second&lt;-()\n✖ dplyr::slice()        masks IRanges::slice()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n#load the airway dataset\ndata(airway, package = 'airway')\n#You can read about the dataset by doing:\n#?airway\n\n\ntypeof(airway)\n\n[1] \"S4\"\n\nclass(airway)\n\n[1] \"RangedSummarizedExperiment\"\nattr(,\"package\")\n[1] \"SummarizedExperiment\"\n\n\nairway is a RangedSummarizedExperiment object. We can get a good overview of the content of Bioconductor S4 objects by just accessing them:\n\nairway\n\nclass: RangedSummarizedExperiment \ndim: 64102 8 \nmetadata(1): ''\nassays(1): counts\nrownames(64102): ENSG00000000003 ENSG00000000005 ... LRG_98 LRG_99\nrowData names(0):\ncolnames(8): SRR1039508 SRR1039509 ... SRR1039520 SRR1039521\ncolData names(9): SampleName cell ... Sample BioSample\n\n\nThere is only one assay and it is count data. We might have several assays in the same RangedSummarizedExperiment object, i.e. one for raw counts and one for normalized counts or rlog transformed counts.\nOur rows are genes with Ensembl Gene Identifiers (ENSG00000000003, ect) and our columns are samples. There have been 64102 genes measured (look at the dimensions).\n\n\n\nWe generally access slots by functions that have the same name as the slot. The (raw) counts for example are in the assay slot:\n\ncount_matrix &lt;- assay(airway, 'counts')\nhead(count_matrix)\n\n                SRR1039508 SRR1039509 SRR1039512 SRR1039513 SRR1039516\nENSG00000000003        679        448        873        408       1138\nENSG00000000005          0          0          0          0          0\nENSG00000000419        467        515        621        365        587\nENSG00000000457        260        211        263        164        245\nENSG00000000460         60         55         40         35         78\nENSG00000000938          0          0          2          0          1\n                SRR1039517 SRR1039520 SRR1039521\nENSG00000000003       1047        770        572\nENSG00000000005          0          0          0\nENSG00000000419        799        417        508\nENSG00000000457        331        233        229\nENSG00000000460         63         76         60\nENSG00000000938          0          0          0\n\nclass(count_matrix)\n\n[1] \"matrix\" \"array\" \n\n\nThe count data is in an array/matrix where each row is a gene and each column is a sample and the gene names are in the row names. They don’t have their own column because unlike dataframes matrices can only have numeric values.\nWe haven’t explicitly worked with this data type before, but many functions in R can be applied to different types of objects so let’s try getting the row sums:\n\nrowSums(count_matrix) %&gt;% head()\n\nENSG00000000003 ENSG00000000005 ENSG00000000419 ENSG00000000457 ENSG00000000460 \n           5935               0            4279            1936             467 \nENSG00000000938 \n              3 \n\n\nWe can see that gene ENSG00000000005 does not have counts in any of our sample (the row sum is 0). How many of such genes are there?\n\nsum(rowSums(count_matrix) == 0)\n\n[1] 30633\n\n\nAbout half of the genes in the catalog have not been seen.\nRemember these are raw counts so we’re not going to do too much with them. If we are going to compare counts across samples or genes we will have to normalize them first. This is a topic for the RNAseq course! (insert shameless self promotion).\n\n\n\nThe metadata slot contains the experimental data underlying the counts:\n\nmetadata(airway)\n\n[[1]]\nExperiment data\n  Experimenter name: Himes BE \n  Laboratory: NA \n  Contact information:  \n  Title: RNA-Seq transcriptome profiling identifies CRISPLD2 as a glucocorticoid responsive gene that modulates cytokine function in airway smooth muscle cells. \n  URL: http://www.ncbi.nlm.nih.gov/pubmed/24926665 \n  PMIDs: 24926665 \n\n  Abstract: A 226 word abstract is available. Use 'abstract' method.\n\n\nWhat we would traditionally describe as metadata in for example an RNAseq experiment is in the colData slot instead:\n\ncolData(airway)\n\nDataFrame with 8 rows and 9 columns\n           SampleName     cell      dex    albut        Run avgLength\n             &lt;factor&gt; &lt;factor&gt; &lt;factor&gt; &lt;factor&gt;   &lt;factor&gt; &lt;integer&gt;\nSRR1039508 GSM1275862  N61311     untrt    untrt SRR1039508       126\nSRR1039509 GSM1275863  N61311     trt      untrt SRR1039509       126\nSRR1039512 GSM1275866  N052611    untrt    untrt SRR1039512       126\nSRR1039513 GSM1275867  N052611    trt      untrt SRR1039513        87\nSRR1039516 GSM1275870  N080611    untrt    untrt SRR1039516       120\nSRR1039517 GSM1275871  N080611    trt      untrt SRR1039517       126\nSRR1039520 GSM1275874  N061011    untrt    untrt SRR1039520       101\nSRR1039521 GSM1275875  N061011    trt      untrt SRR1039521        98\n           Experiment    Sample    BioSample\n             &lt;factor&gt;  &lt;factor&gt;     &lt;factor&gt;\nSRR1039508  SRX384345 SRS508568 SAMN02422669\nSRR1039509  SRX384346 SRS508567 SAMN02422675\nSRR1039512  SRX384349 SRS508571 SAMN02422678\nSRR1039513  SRX384350 SRS508572 SAMN02422670\nSRR1039516  SRX384353 SRS508575 SAMN02422682\nSRR1039517  SRX384354 SRS508576 SAMN02422673\nSRR1039520  SRX384357 SRS508579 SAMN02422683\nSRR1039521  SRX384358 SRS508580 SAMN02422677\n\n\nThis dataframe tells us for each sample whether it was treated with dexamethasone (dex) or albuterol (albut), as well the Run ID, Experiment II and some other identifiers.\nA cool thing about (Ranged)SummarizedExperiment objects is that the $ syntax directly indexes the colData. For example we can get a vector of sample names or whether the samples were treated with dexamethasone like so:\n\n#the $ syntax directly indexes the metadata, i.e.\nairway$SampleName\n\n[1] GSM1275862 GSM1275863 GSM1275866 GSM1275867 GSM1275870 GSM1275871 GSM1275874\n[8] GSM1275875\n8 Levels: GSM1275862 GSM1275863 GSM1275866 GSM1275867 ... GSM1275875\n\nairway$dex\n\n[1] untrt trt   untrt trt   untrt trt   untrt trt  \nLevels: trt untrt\n\n\n\n\n\nAnother neat thing about (Ranged)SummarizedExperiment objects is that they can be subset like matrices.\nLet’s have brief example of a matrix:\n\nmat &lt;- matrix(1:12, nrow = 3, ncol = 4)\n\n# Assign row and column names\nrownames(mat) &lt;- c(\"Gene1\", \"Gene2\", \"Gene3\")\ncolnames(mat) &lt;- c(\"Sample1\", \"Sample2\", \"Sample3\", \"Sample4\")\n\nmat\n\n      Sample1 Sample2 Sample3 Sample4\nGene1       1       4       7      10\nGene2       2       5       8      11\nGene3       3       6       9      12\n\n\nMatrices are subset with this syntax:\n\nmat[rows,columns]\n\nLets say we only want to look at Genes 1 and 2 we can indicate that by:\n\nrownames\nrowindices\na boolean vector\n\n\n#rownames\nmat[c(\"Gene1\", \"Gene2\"), ]\n\n      Sample1 Sample2 Sample3 Sample4\nGene1       1       4       7      10\nGene2       2       5       8      11\n\n#rowindices\nmat[c(1,3),]\n\n      Sample1 Sample2 Sample3 Sample4\nGene1       1       4       7      10\nGene3       3       6       9      12\n\n#boolean vector\nkeep &lt;- c(T,F,T)\nmat[keep,]\n\n      Sample1 Sample2 Sample3 Sample4\nGene1       1       4       7      10\nGene3       3       6       9      12\n\n\nAnd similarly for columns in the second field:\n\n# Select Sample1 & Sample3 (all rows)\nmat[, c(\"Sample1\", \"Sample3\")]  \n\n      Sample1 Sample3\nGene1       1       7\nGene2       2       8\nGene3       3       9\n\n\nWe can use that syntax to subset the entire (Ranged)SummarizedExperiment object (not just the count matrix in the assay slot)!\nFor example we can make a new (Ranged)SummarizedExperiment object with only the samples treated with dexamethasone.\n\n#create a boolean vector of which samples to select\nairway$dex\n\n[1] untrt trt   untrt trt   untrt trt   untrt trt  \nLevels: trt untrt\n\nkeep &lt;- airway$dex == 'trt'\nkeep\n\n[1] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n\n\n\n#use the vector to subset the object as if were a matrix!\ndex_treated_samples &lt;- airway[, airway$dex == \"trt\"]\nclass(dex_treated_samples)\n\n[1] \"RangedSummarizedExperiment\"\nattr(,\"package\")\n[1] \"SummarizedExperiment\"\n\ndex_treated_samples\n\nclass: RangedSummarizedExperiment \ndim: 64102 4 \nmetadata(1): ''\nassays(1): counts\nrownames(64102): ENSG00000000003 ENSG00000000005 ... LRG_98 LRG_99\nrowData names(0):\ncolnames(4): SRR1039509 SRR1039513 SRR1039517 SRR1039521\ncolData names(9): SampleName cell ... Sample BioSample\n\n\nThat’s all for now!"
  },
  {
    "objectID": "presentations/s4_objects.html#s4-objects",
    "href": "presentations/s4_objects.html#s4-objects",
    "title": "R Objects: S4 Objects",
    "section": "",
    "text": "Bioconductor packages often use S4 objects to store their data. Some examples:\n\n(Ranged)SummarizedExperiment is an object that holds rectangular matrices of high-throughput omics data (RNA-Seq, ChIP-Seq, ATAC-Seq)\npyholoseq is an objects that stores phylogenetic data such as OTU tables, taxonomy ect for e.g. microbiome and general metagenomics\nDESeqDataSet is an object that stores counts, transformations and metadata for RNAseq analysis. It is subclass of (Ranged)SummarizedExperiment\n\nUnlike the S3 objects (named lists with a class) we looked at before, S4 objects have clearly defined elements called ‘slots’.\nA slot must have:\n\na name\na defined data type\nit may have validation rules\n\nThey are usually accessed by specialized functions. Let’s have a look at a SummarizedExperiment objects.\n\n\n\nlibrary(SummarizedExperiment)\n\nIndlæser krævet pakke: MatrixGenerics\n\n\nIndlæser krævet pakke: matrixStats\n\n\n\nVedhæfter pakke: 'MatrixGenerics'\n\n\nDe følgende objekter er maskerede fra 'package:matrixStats':\n\n    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n    colWeightedMeans, colWeightedMedians, colWeightedSds,\n    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n    rowWeightedSds, rowWeightedVars\n\n\nIndlæser krævet pakke: GenomicRanges\n\n\nIndlæser krævet pakke: stats4\n\n\nIndlæser krævet pakke: BiocGenerics\n\n\n\nVedhæfter pakke: 'BiocGenerics'\n\n\nDe følgende objekter er maskerede fra 'package:stats':\n\n    IQR, mad, sd, var, xtabs\n\n\nDe følgende objekter er maskerede fra 'package:base':\n\n    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n    Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort,\n    table, tapply, union, unique, unsplit, which.max, which.min\n\n\nIndlæser krævet pakke: S4Vectors\n\n\n\nVedhæfter pakke: 'S4Vectors'\n\n\nDe følgende objekter er maskerede fra 'package:base':\n\n    expand.grid, I, unname\n\n\nIndlæser krævet pakke: IRanges\n\n\n\nVedhæfter pakke: 'IRanges'\n\n\nDet følgende objekt er maskeret fra 'package:grDevices':\n\n    windows\n\n\nIndlæser krævet pakke: GenomeInfoDb\n\n\nIndlæser krævet pakke: Biobase\n\n\nWelcome to Bioconductor\n\n    Vignettes contain introductory material; view with\n    'browseVignettes()'. To cite Bioconductor, see\n    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n\n\n\nVedhæfter pakke: 'Biobase'\n\n\nDet følgende objekt er maskeret fra 'package:MatrixGenerics':\n\n    rowMedians\n\n\nDe følgende objekter er maskerede fra 'package:matrixStats':\n\n    anyMissing, rowMedians\n\nlibrary(airway)\nlibrary(tidyverse)\n\nWarning: pakke 'ggplot2' blev bygget under R version 4.2.3\n\n\nWarning: pakke 'tibble' blev bygget under R version 4.2.3\n\n\nWarning: pakke 'dplyr' blev bygget under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ lubridate::%within%() masks IRanges::%within%()\n✖ dplyr::collapse()     masks IRanges::collapse()\n✖ dplyr::combine()      masks Biobase::combine(), BiocGenerics::combine()\n✖ dplyr::count()        masks matrixStats::count()\n✖ dplyr::desc()         masks IRanges::desc()\n✖ tidyr::expand()       masks S4Vectors::expand()\n✖ dplyr::filter()       masks stats::filter()\n✖ dplyr::first()        masks S4Vectors::first()\n✖ dplyr::lag()          masks stats::lag()\n✖ ggplot2::Position()   masks BiocGenerics::Position(), base::Position()\n✖ purrr::reduce()       masks GenomicRanges::reduce(), IRanges::reduce()\n✖ dplyr::rename()       masks S4Vectors::rename()\n✖ lubridate::second()   masks S4Vectors::second()\n✖ lubridate::second&lt;-() masks S4Vectors::second&lt;-()\n✖ dplyr::slice()        masks IRanges::slice()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n#load the airway dataset\ndata(airway, package = 'airway')\n#You can read about the dataset by doing:\n#?airway\n\n\ntypeof(airway)\n\n[1] \"S4\"\n\nclass(airway)\n\n[1] \"RangedSummarizedExperiment\"\nattr(,\"package\")\n[1] \"SummarizedExperiment\"\n\n\nairway is a RangedSummarizedExperiment object. We can get a good overview of the content of Bioconductor S4 objects by just accessing them:\n\nairway\n\nclass: RangedSummarizedExperiment \ndim: 64102 8 \nmetadata(1): ''\nassays(1): counts\nrownames(64102): ENSG00000000003 ENSG00000000005 ... LRG_98 LRG_99\nrowData names(0):\ncolnames(8): SRR1039508 SRR1039509 ... SRR1039520 SRR1039521\ncolData names(9): SampleName cell ... Sample BioSample\n\n\nThere is only one assay and it is count data. We might have several assays in the same RangedSummarizedExperiment object, i.e. one for raw counts and one for normalized counts or rlog transformed counts.\nOur rows are genes with Ensembl Gene Identifiers (ENSG00000000003, ect) and our columns are samples. There have been 64102 genes measured (look at the dimensions).\n\n\n\nWe generally access slots by functions that have the same name as the slot. The (raw) counts for example are in the assay slot:\n\ncount_matrix &lt;- assay(airway, 'counts')\nhead(count_matrix)\n\n                SRR1039508 SRR1039509 SRR1039512 SRR1039513 SRR1039516\nENSG00000000003        679        448        873        408       1138\nENSG00000000005          0          0          0          0          0\nENSG00000000419        467        515        621        365        587\nENSG00000000457        260        211        263        164        245\nENSG00000000460         60         55         40         35         78\nENSG00000000938          0          0          2          0          1\n                SRR1039517 SRR1039520 SRR1039521\nENSG00000000003       1047        770        572\nENSG00000000005          0          0          0\nENSG00000000419        799        417        508\nENSG00000000457        331        233        229\nENSG00000000460         63         76         60\nENSG00000000938          0          0          0\n\nclass(count_matrix)\n\n[1] \"matrix\" \"array\" \n\n\nThe count data is in an array/matrix where each row is a gene and each column is a sample and the gene names are in the row names. They don’t have their own column because unlike dataframes matrices can only have numeric values.\nWe haven’t explicitly worked with this data type before, but many functions in R can be applied to different types of objects so let’s try getting the row sums:\n\nrowSums(count_matrix) %&gt;% head()\n\nENSG00000000003 ENSG00000000005 ENSG00000000419 ENSG00000000457 ENSG00000000460 \n           5935               0            4279            1936             467 \nENSG00000000938 \n              3 \n\n\nWe can see that gene ENSG00000000005 does not have counts in any of our sample (the row sum is 0). How many of such genes are there?\n\nsum(rowSums(count_matrix) == 0)\n\n[1] 30633\n\n\nAbout half of the genes in the catalog have not been seen.\nRemember these are raw counts so we’re not going to do too much with them. If we are going to compare counts across samples or genes we will have to normalize them first. This is a topic for the RNAseq course! (insert shameless self promotion).\n\n\n\nThe metadata slot contains the experimental data underlying the counts:\n\nmetadata(airway)\n\n[[1]]\nExperiment data\n  Experimenter name: Himes BE \n  Laboratory: NA \n  Contact information:  \n  Title: RNA-Seq transcriptome profiling identifies CRISPLD2 as a glucocorticoid responsive gene that modulates cytokine function in airway smooth muscle cells. \n  URL: http://www.ncbi.nlm.nih.gov/pubmed/24926665 \n  PMIDs: 24926665 \n\n  Abstract: A 226 word abstract is available. Use 'abstract' method.\n\n\nWhat we would traditionally describe as metadata in for example an RNAseq experiment is in the colData slot instead:\n\ncolData(airway)\n\nDataFrame with 8 rows and 9 columns\n           SampleName     cell      dex    albut        Run avgLength\n             &lt;factor&gt; &lt;factor&gt; &lt;factor&gt; &lt;factor&gt;   &lt;factor&gt; &lt;integer&gt;\nSRR1039508 GSM1275862  N61311     untrt    untrt SRR1039508       126\nSRR1039509 GSM1275863  N61311     trt      untrt SRR1039509       126\nSRR1039512 GSM1275866  N052611    untrt    untrt SRR1039512       126\nSRR1039513 GSM1275867  N052611    trt      untrt SRR1039513        87\nSRR1039516 GSM1275870  N080611    untrt    untrt SRR1039516       120\nSRR1039517 GSM1275871  N080611    trt      untrt SRR1039517       126\nSRR1039520 GSM1275874  N061011    untrt    untrt SRR1039520       101\nSRR1039521 GSM1275875  N061011    trt      untrt SRR1039521        98\n           Experiment    Sample    BioSample\n             &lt;factor&gt;  &lt;factor&gt;     &lt;factor&gt;\nSRR1039508  SRX384345 SRS508568 SAMN02422669\nSRR1039509  SRX384346 SRS508567 SAMN02422675\nSRR1039512  SRX384349 SRS508571 SAMN02422678\nSRR1039513  SRX384350 SRS508572 SAMN02422670\nSRR1039516  SRX384353 SRS508575 SAMN02422682\nSRR1039517  SRX384354 SRS508576 SAMN02422673\nSRR1039520  SRX384357 SRS508579 SAMN02422683\nSRR1039521  SRX384358 SRS508580 SAMN02422677\n\n\nThis dataframe tells us for each sample whether it was treated with dexamethasone (dex) or albuterol (albut), as well the Run ID, Experiment II and some other identifiers.\nA cool thing about (Ranged)SummarizedExperiment objects is that the $ syntax directly indexes the colData. For example we can get a vector of sample names or whether the samples were treated with dexamethasone like so:\n\n#the $ syntax directly indexes the metadata, i.e.\nairway$SampleName\n\n[1] GSM1275862 GSM1275863 GSM1275866 GSM1275867 GSM1275870 GSM1275871 GSM1275874\n[8] GSM1275875\n8 Levels: GSM1275862 GSM1275863 GSM1275866 GSM1275867 ... GSM1275875\n\nairway$dex\n\n[1] untrt trt   untrt trt   untrt trt   untrt trt  \nLevels: trt untrt\n\n\n\n\n\nAnother neat thing about (Ranged)SummarizedExperiment objects is that they can be subset like matrices.\nLet’s have brief example of a matrix:\n\nmat &lt;- matrix(1:12, nrow = 3, ncol = 4)\n\n# Assign row and column names\nrownames(mat) &lt;- c(\"Gene1\", \"Gene2\", \"Gene3\")\ncolnames(mat) &lt;- c(\"Sample1\", \"Sample2\", \"Sample3\", \"Sample4\")\n\nmat\n\n      Sample1 Sample2 Sample3 Sample4\nGene1       1       4       7      10\nGene2       2       5       8      11\nGene3       3       6       9      12\n\n\nMatrices are subset with this syntax:\n\nmat[rows,columns]\n\nLets say we only want to look at Genes 1 and 2 we can indicate that by:\n\nrownames\nrowindices\na boolean vector\n\n\n#rownames\nmat[c(\"Gene1\", \"Gene2\"), ]\n\n      Sample1 Sample2 Sample3 Sample4\nGene1       1       4       7      10\nGene2       2       5       8      11\n\n#rowindices\nmat[c(1,3),]\n\n      Sample1 Sample2 Sample3 Sample4\nGene1       1       4       7      10\nGene3       3       6       9      12\n\n#boolean vector\nkeep &lt;- c(T,F,T)\nmat[keep,]\n\n      Sample1 Sample2 Sample3 Sample4\nGene1       1       4       7      10\nGene3       3       6       9      12\n\n\nAnd similarly for columns in the second field:\n\n# Select Sample1 & Sample3 (all rows)\nmat[, c(\"Sample1\", \"Sample3\")]  \n\n      Sample1 Sample3\nGene1       1       7\nGene2       2       8\nGene3       3       9\n\n\nWe can use that syntax to subset the entire (Ranged)SummarizedExperiment object (not just the count matrix in the assay slot)!\nFor example we can make a new (Ranged)SummarizedExperiment object with only the samples treated with dexamethasone.\n\n#create a boolean vector of which samples to select\nairway$dex\n\n[1] untrt trt   untrt trt   untrt trt   untrt trt  \nLevels: trt untrt\n\nkeep &lt;- airway$dex == 'trt'\nkeep\n\n[1] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n\n\n\n#use the vector to subset the object as if were a matrix!\ndex_treated_samples &lt;- airway[, airway$dex == \"trt\"]\nclass(dex_treated_samples)\n\n[1] \"RangedSummarizedExperiment\"\nattr(,\"package\")\n[1] \"SummarizedExperiment\"\n\ndex_treated_samples\n\nclass: RangedSummarizedExperiment \ndim: 64102 4 \nmetadata(1): ''\nassays(1): counts\nrownames(64102): ENSG00000000003 ENSG00000000005 ... LRG_98 LRG_99\nrowData names(0):\ncolnames(4): SRR1039509 SRR1039513 SRR1039517 SRR1039521\ncolData names(9): SampleName cell ... Sample BioSample\n\n\nThat’s all for now!"
  },
  {
    "objectID": "solutions/solution1.html",
    "href": "solutions/solution1.html",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n\nLoad in the diabetes_clinical_toy_messy.xlsx data set.\n\n\ndiabetes_clinical &lt;- read_excel('../data/diabetes_clinical_toy_messy.xlsx')\nhead(diabetes_clinical)\n\n# A tibble: 6 × 9\n     ID Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n1  9046 Male      34            84  24.7               93 Unknown        0\n2 51676 Male      25            74  22.5              102 Unknown        0\n3 31112 Male      30             0  32.3               75 Former         1\n4 60182 Male      50            80  34.5               98 Unknown        1\n5  1665 Female    27            60  26.3               82 Never          0\n6 56669 Male      35            84  35                 58 Smoker         1\n# ℹ 1 more variable: Serum_ca2 &lt;dbl&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#getting-started",
    "href": "solutions/solution1.html#getting-started",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n\nLoad in the diabetes_clinical_toy_messy.xlsx data set.\n\n\ndiabetes_clinical &lt;- read_excel('../data/diabetes_clinical_toy_messy.xlsx')\nhead(diabetes_clinical)\n\n# A tibble: 6 × 9\n     ID Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n1  9046 Male      34            84  24.7               93 Unknown        0\n2 51676 Male      25            74  22.5              102 Unknown        0\n3 31112 Male      30             0  32.3               75 Former         1\n4 60182 Male      50            80  34.5               98 Unknown        1\n5  1665 Female    27            60  26.3               82 Never          0\n6 56669 Male      35            84  35                 58 Smoker         1\n# ℹ 1 more variable: Serum_ca2 &lt;dbl&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#explore-the-data",
    "href": "solutions/solution1.html#explore-the-data",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "Explore the data",
    "text": "Explore the data\nUse can you either base R or/and tidyverse to solve the exercises.\n\nHow many missing values (NA’s) are there in each column.\n\n\ncolSums(is.na(diabetes_clinical))\n\n              ID              Sex              Age    BloodPressure \n               0                0                3                0 \n             BMI PhysicalActivity           Smoker         Diabetes \n               3                0                0                0 \n       Serum_ca2 \n               0 \n\n\n\nCheck the ranges and distribution of each of the variables. Consider that the variables are of different classes. Do any values strike you as odd?\n\nFor the categorical variables we can use table:\nThe Sex values are not consistent.\n\ntable(diabetes_clinical$Sex)\n\n\nFemale FEMALE   male   Male \n   291      2      2    237 \n\ntable(diabetes_clinical$Smoker)\n\n\n Former   Never  Smoker Unknown \n    132     159     162      79 \n\ntable(diabetes_clinical$Diabetes)\n\n\n  0   1 \n267 265 \n\n\nFor the numerical variables we’ll plot and check the range:\n\nrange(diabetes_clinical$Age, na.rm = TRUE)\n\n[1] 21 81\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = Age, x = 1)) + \n  geom_violin()\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n\n\n\n\n\n\n\nOdd: Some BloodPressure values are 0.\n\nrange(diabetes_clinical$BloodPressure, na.rm = TRUE)\n\n[1]   0 114\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = BloodPressure, x = 1)) + \n  geom_violin() \n\n\n\n\n\n\n\n\nOdd: Some BMI values are 0.\n\nrange(diabetes_clinical$BMI, na.rm = TRUE)\n\n[1]  0.0 57.1\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = BMI, x = 1)) + \n  geom_violin()\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n\n\n\n\n\n\n\n\nrange(diabetes_clinical$PhysicalActivity, na.rm = TRUE)\n\n[1]  19 177\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = PhysicalActivity, x = 1)) + \n  geom_violin()\n\n\n\n\n\n\n\n\n\nrange(diabetes_clinical$Serum_ca2, na.rm = TRUE)\n\n[1]  8.7 10.2\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = Serum_ca2, x = 1)) + \n  geom_violin()",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#clean-up-the-data",
    "href": "solutions/solution1.html#clean-up-the-data",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "Clean up the data",
    "text": "Clean up the data\nNow that we have had a look at the data, it is time to correct fixable mistakes and remove observations that cannot be corrected.\nConsider the following:\n\nWhat should we do with the rows that contain NA’s? Do we remove them or keep them?\nWhich odd things in the data can we correct with confidence and which cannot?\nAre there zeros in the data? Are they true zeros or errors?\nDo you want to change any of the classes of the variables?\n\n\nClean the data according to your considerations.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nHave a look at ID, BloodPressure, BMI, Sex, and Diabetes.\n\n\n\nMy considerations:\n\nWhen modelling, rows with NA’s in the variables we want to model should be removed as we cannot model on NAs. Since there are only NA’s in Age and BMI, the rows can be left until we need to do a model with these columns.\nThe different spellings in Sex should be regularized so that there is only one spelling for each category. Since most rows have the first letter as capital letter and the remaining letter as lowercase we will use that.\nThere are zeros in BMI and BloodPressure. These are considered false zeros as is does not make sense that these variables have a value of 0.\nDiabetes and ID are changed to factor.\n\nCheck number of rows before cleaning.\n\nnrow(diabetes_clinical)\n\n[1] 532\n\n\nCleaning data according to considerations.\n\ndiabetes_clinical_clean &lt;- diabetes_clinical %&gt;% \n  mutate(Sex = str_to_title(Sex),\n         ID = factor(ID),\n         Diabetes = factor(Diabetes)) %&gt;% \n  filter(BMI != 0, BloodPressure != 0) \n\nCheck the unique sexes now.\n\ndiabetes_clinical_clean$Sex %&gt;% unique()\n\n[1] \"Male\"   \"Female\"\n\n\nCheck number of rows after cleaning.\n\nnrow(diabetes_clinical_clean)\n\n[1] 490",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#meta-data",
    "href": "solutions/solution1.html#meta-data",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "Meta Data",
    "text": "Meta Data\nThere is some metadata to accompany the dataset you have just cleaned in diabetes_meta_toy_messy.csv. This is a csv file, not an excel sheet, so you need to use the read_delim function to load it. Load in the dataset and inspect it.\n6.2. Load the meta data set.\n\ndiabetes_meta &lt;- read_delim('../data/diabetes_meta_toy_messy.csv')\nhead(diabetes_meta)\n\n# A tibble: 6 × 3\n     ID Married Work         \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        \n1 33879 Yes     Self-employed\n2 52800 Yes     Private      \n3 16817 Yes     Private      \n4 70676 Yes     Self-employed\n5  6319 No      Public       \n6 71379 No      Public       \n\n\n6.3. How many missing values (NA’s) are there in each column.\n\ncolSums(is.na(diabetes_meta))\n\n     ID Married    Work \n      0       0       0 \n\n\n6.4. Check the distribution of each of the variables. Consider that the variables are of different classes. Do any of the distributions seam odd to you?\nFor the categorical variables:\n\ntable(diabetes_meta$Married)\n\n\n  No  No   Yes Yes  \n 183    3  345    1 \n\ntable(diabetes_meta$Work)\n\n\n      Private        Public       Retired Self-employed \n          283           154             6            89 \n\n\nBy investigating the unique values of the Married variable we see that some of the values have whitespace.\n\nunique(diabetes_meta$Married)\n\n[1] \"Yes\"  \"No\"   \"Yes \" \"No \" \n\n\n\n\nClean the data according to your considerations.\n\n\nMy considerations:\n\nThe Married variable has whitespace in the some of the values. The values “Yes” and “Yes” will be interpreted as different values. We can confidently remove all the whitespaces in this variable.\nID is changed to factor to match the diabetes_clean dataset.\n\nCheck number of rows before cleaning.\n\nnrow(diabetes_meta)\n\n[1] 532\n\n\n\ndiabetes_meta_clean &lt;- diabetes_meta %&gt;% \n  mutate(Married = str_trim(Married),\n         ID = factor(ID))\n\nCheck the unique marital status now.\n\nunique(diabetes_meta_clean$Married)\n\n[1] \"Yes\" \"No\" \n\n\nCheck number of rows after cleaning.\n\nnrow(diabetes_meta_clean)\n\n[1] 532",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#join-the-datasets",
    "href": "solutions/solution1.html#join-the-datasets",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "Join the datasets",
    "text": "Join the datasets\n\nConsider what variable the datasets should be joined on.\n\nThe joining variable must be the same type in both datasets.\n\nJoin the datasets by the variable you selected above.\n\n\ndiabetes_join &lt;- diabetes_clinical_clean %&gt;% \n  left_join(diabetes_meta_clean, by = 'ID')\n\n\nHow many rows does the joined dataset have? Explain why.\n\nBecause we used left_join, only the IDs that are in diabetes_clinical_clean are kept.\n\nnrow(diabetes_join)\n\n[1] 490\n\n\n\nExport the joined dataset. Think about which directory you want to save the file in.\n\n\nwritexl::write_xlsx(diabetes_join, '../out/diabetes_join.xlsx')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3A.html",
    "href": "solutions/solution3A.html",
    "title": "Exercise 3 A - Solutions",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\n\n\nLoad data from the .rds file you created in Exercise 2. Have a guess at what the function is called.\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\nhead(diabetes_glucose)\n\n# A tibble: 6 × 12\n  ID    Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n  &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n1 9046  Male      34            84  24.7               93 Unknown 0       \n2 51676 Male      25            74  22.5              102 Unknown 0       \n3 60182 Male      50            80  34.5               98 Unknown 1       \n4 1665  Female    27            60  26.3               82 Never   0       \n5 56669 Male      35            84  35                 58 Smoker  1       \n6 53882 Female    31            78  43.3               59 Smoker  1       \n# ℹ 4 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 A - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3A.html#getting-started",
    "href": "solutions/solution3A.html#getting-started",
    "title": "Exercise 3 A - Solutions",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\n\n\nLoad data from the .rds file you created in Exercise 2. Have a guess at what the function is called.\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\nhead(diabetes_glucose)\n\n# A tibble: 6 × 12\n  ID    Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n  &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n1 9046  Male      34            84  24.7               93 Unknown 0       \n2 51676 Male      25            74  22.5              102 Unknown 0       \n3 60182 Male      50            80  34.5               98 Unknown 1       \n4 1665  Female    27            60  26.3               82 Never   0       \n5 56669 Male      35            84  35                 58 Smoker  1       \n6 53882 Female    31            78  43.3               59 Smoker  1       \n# ℹ 4 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 A - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3A.html#plotting---part-1",
    "href": "solutions/solution3A.html#plotting---part-1",
    "title": "Exercise 3 A - Solutions",
    "section": "Plotting - Part 1",
    "text": "Plotting - Part 1\nYou will first do some basic plots to get started with ggplot again.\nIf it has been a while since you worked with ggplot, have a look at the ggplot material from the FromExceltoR course.\n\nCreate a scatter plot of Age and Blood Pressure. Do you notice a trend?\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(x = BloodPressure, \n             y = Age)) + \n  geom_point() \n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nCreate a scatter plot of PhysicalActivity and BMI. Do you notice a trend?\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(x = PhysicalActivity, \n             y = BMI)) + \n  geom_point() \n\n\n\n\n\n\n\n\n\nNow, create the same two plots as before, but this time stratify them by Diabetes. Do you notice any trends?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can stratify a plot by a categorical variable in several ways, depending on the type of plot. The purpose of stratification is to distinguish samples based on their categorical values, making patterns or differences easier to identify. This can be done using aesthetics like color, fill, shape.\n\n\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(x = BloodPressure, \n             y = Age, \n             color = Diabetes)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(x = PhysicalActivity, \n             y = BMI, \n             color = Diabetes)) + \n  geom_point() \n\n\n\n\n\n\n\n\n\nCreate a boxplot of BMI stratified by Diabetes. Give the plot a meaningful title.\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(y = BMI, \n             x = Diabetes, \n             color = Diabetes)) + \n  geom_boxplot() + \n  labs(title = 'Distribution of BMI Stratified by Diabetes')\n\n\n\n\n\n\n\n\n\nCreate a boxplot of PhysicalActivity stratified by Smoker. Give the plot a meaningful title.\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(y = PhysicalActivity, \n             x = Smoker, \n             fill = Smoker)) + \n  geom_boxplot() + \n  labs(title = 'Distribution of Physical Activity Stratified by Smoker Status')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 A - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3A.html#plotting---part-2",
    "href": "solutions/solution3A.html#plotting---part-2",
    "title": "Exercise 3 A - Solutions",
    "section": "Plotting - Part 2",
    "text": "Plotting - Part 2\nIn order to plot the data inside the nested variable, the data needs to be unnested.\n\nCreate a boxplot of the glucose measurements at time 0 stratified by Diabetes. Give the plot a meaningful title.\n\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  filter(Measurement == 0) %&gt;% \n  ggplot(aes(y = `Glucose (mmol/L)`, \n             x = Diabetes, \n             color = Diabetes)) +\n  geom_boxplot() + \n  labs(title = 'Glucose Measurement for Time Point 0 (fasted)')\n\n\n\n\n\n\n\n\n\nCreate these boxplots for each time point (0, 60, 120) by using faceting by Measurement. Give the plot a meaningful title.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFaceting allows you to create multiple plots based on the values of a categorical variable, making it easier to compare patterns across groups. In ggplot2, you can use facet_wrap for a single variable or facet_grid for multiple variables.\n\n\n\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  ggplot(aes(y = `Glucose (mmol/L)`, \n             x = Diabetes, \n             color = Diabetes)) +\n  geom_boxplot() + \n  facet_wrap(vars(Measurement)) + \n  labs(title = 'Glucose Measurements for Time Point 0, 60, and 120')\n\n\n\n\n\n\n\n\n\nCalculate the mean glucose levels for each time point.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use unnest(), group_by(), and summerise().\n\n\n\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  group_by(Measurement) %&gt;% \n  summarise(`Glucose (mmol/L)` = mean(`Glucose (mmol/L)`))\n\n# A tibble: 3 × 2\n  Measurement `Glucose (mmol/L)`\n  &lt;fct&gt;                    &lt;dbl&gt;\n1 0                         8.06\n2 60                        9.73\n3 120                      11.1 \n\n\n\nMake the same calculation as above, but additionally group the results by Diabetes. Save the data frame in a variable. Compare your results to the boxplots you made above.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nGroup by several variables: group_by(var1, var2).\n\n\n\n\nglucose_mean &lt;- diabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  group_by(Measurement, Diabetes) %&gt;%\n  summarize(`Glucose (mmol/L)` = mean(`Glucose (mmol/L)`)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'Measurement'. You can override using the\n`.groups` argument.\n\nglucose_mean\n\n# A tibble: 6 × 3\n  Measurement Diabetes `Glucose (mmol/L)`\n  &lt;fct&gt;       &lt;chr&gt;                 &lt;dbl&gt;\n1 0           0                      5.50\n2 0           1                     10.6 \n3 60          0                      6.83\n4 60          1                     12.6 \n5 120         0                      7.89\n6 120         1                     14.2 \n\n\n\nCreate a plot that visualizes glucose measurements across time points, with one line for each patient ID. Then color the lines by their diabetes status. In summary, each patient’s glucose measurements should be connected with a line, grouped by their ID, and color-coded by Diabetes. Give the plot a meaningful title.\n\nIf your time points are strangely ordered have a look at the levels of your Measurement variable (the one that specifies which time point the measurement was taken at) and if necessary fix their order.\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  ggplot(aes(x = Measurement,\n             y = `Glucose (mmol/L)`)) +\n  geom_point(aes(color = Diabetes)) + \n  geom_line(aes(group = ID, color = Diabetes)) + \n  labs(title = 'Glucose Measurements Across Time Points by Diabetes Status')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 A - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3A.html#extra",
    "href": "solutions/solution3A.html#extra",
    "title": "Exercise 3 A - Solutions",
    "section": "Extra",
    "text": "Extra\ne1. Recreate the plot you made in Exercise 12 and include the mean value for each glucose measurement for the two diabetes statuses (0 and 1) you calculated in Exercise 11. This plot should look like this:\n\n\n\n\n\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  ggplot(aes(x = Measurement,\n             y = `Glucose (mmol/L)`)) +\n  geom_point(aes(color = Diabetes)) + \n  geom_line(aes(group = ID, color = Diabetes)) + \n  geom_point(data = glucose_mean, aes(x = Measurement, y = `Glucose (mmol/L)`)) +\n  geom_line(data = glucose_mean, aes(x = Measurement, y = `Glucose (mmol/L)`, \n                                     group = Diabetes, linetype = Diabetes)) +\n  labs(title = \"Glucose Measurements with Mean by Diabetes Status\")\n\n\n\n\n\n\n\nggsave('../out/figure3_13.png')\n\nSaving 7 x 5 in image",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 A - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html",
    "href": "solutions/solution4.html",
    "title": "Exercise 4 - Solutions",
    "section": "",
    "text": "In this exercise you will practice your scripting.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#getting-started",
    "href": "solutions/solution4.html#getting-started",
    "title": "Exercise 4 - Solutions",
    "section": "Getting started",
    "text": "Getting started\nLoad libaries and data\n\nlibrary(tidyverse)\nlibrary(glue)\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\ndiabetes_glucose\n\n# A tibble: 490 × 12\n   ID    Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n   &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n 1 9046  Male      34            84  24.7               93 Unknown 0       \n 2 51676 Male      25            74  22.5              102 Unknown 0       \n 3 60182 Male      50            80  34.5               98 Unknown 1       \n 4 1665  Female    27            60  26.3               82 Never   0       \n 5 56669 Male      35            84  35                 58 Smoker  1       \n 6 53882 Female    31            78  43.3               59 Smoker  1       \n 7 10434 Male      52            86  33.3               58 Never   1       \n 8 27419 Female    54            78  35.2               74 Former  1       \n 9 60491 Female    41            90  39.8               67 Smoker  1       \n10 12109 Female    36            82  30.8               81 Smoker  1       \n# ℹ 480 more rows\n# ℹ 4 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#if-else-statements",
    "href": "solutions/solution4.html#if-else-statements",
    "title": "Exercise 4 - Solutions",
    "section": "If-else statements",
    "text": "If-else statements\nIn these exercises we don’t use the dataframe yet, that comes later when we have loops. For this part, just declare variables to test your statements, e.g. bp &lt;- 120.\n\nWrite an if-else statement that prints whether a person has high (more than 100), low (lower than 50) or normal blood pressure (between 50 and 100).\n\n\nbp &lt;- 80\n\nif (bp &gt; 100){\n  print('High blood pressure')\n} else if (bp &lt; 50) {\n  print('Low blood pressure')\n} else {\n  print('Normal blood pressure')\n} \n\n[1] \"Normal blood pressure\"\n\n\n\nWrite an if-else statement that assigns people high, moderate or low health risk based on their smoking habits (variable smoker) and BMI:\n\n\nSmoker and BMI greater than 35 -&gt; high risk\nSmoker or BMI greater than 35 -&gt; moderate risk\notherwise low risk\n\nAnd smoker should be one of “Smoker”, “Former”, “Never”, “Unknown”.\nVerify that your statement works for different combinations of risk score and BMI\n\nSmoker &lt;- 'Smoker'\nBMI &lt;- 40\n\nif (Smoker == 'Smoker' & BMI &gt; 35){\n  print('High risk')\n} else if (Smoker == 'Smoker' | BMI &gt; 35) {\n  print('Moderate risk')\n} else {\n  print('Low risk')\n}\n\n[1] \"High risk\"",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#loops",
    "href": "solutions/solution4.html#loops",
    "title": "Exercise 4 - Solutions",
    "section": "Loops",
    "text": "Loops\n\nCreate a vector with at least 5 elements and loop over it.\n\n\nmy_v &lt;- c(1, 78, 5, 'hello', 7)\n\nfor (el in my_v) {\n  print(el)\n}\n\n[1] \"1\"\n[1] \"78\"\n[1] \"5\"\n[1] \"hello\"\n[1] \"7\"\n\n\n\nLoop over all column names of diabetes_glucose.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncolnames(df) creates a vector of column names.\n\n\n\n\nfor (col in colnames(diabetes_glucose)) {\n  print(col)\n}\n\n[1] \"ID\"\n[1] \"Sex\"\n[1] \"Age\"\n[1] \"BloodPressure\"\n[1] \"BMI\"\n[1] \"PhysicalActivity\"\n[1] \"Smoker\"\n[1] \"Diabetes\"\n[1] \"Serum_ca2\"\n[1] \"Married\"\n[1] \"Work\"\n[1] \"OGTT\"\n\n\n\nLoop over all rows of diabetes_glucose and determine whether the person’s blood pressure is high, low or normal with the same conditions as in 1.\n\n\n#We'll only show the first 10 rows here for brevity\n#for (i in 1:nrow(diabetes_glucose)) {\n\nfor (i in 1:10) {\n  bp &lt;- diabetes_glucose$BloodPressure[i]\n\n  if (bp &gt; 100){\n    print('High blood pressure')\n  } else if (bp &lt; 50) {\n    print('Low blood pressure')\n  } else {\n    print('Normal blood pressure')\n  } \n}\n\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n\n\n\nLoop over all rows of diabetes_glucose and determine the risk based on genetic risk score and BMI, with the same conditions as in 2. Print the genetic risk score and BMI as well as the risk level to make it easier to see whether your code works correctly.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAn easy way to printing several variables is to pass a vector into print: print(c(this,and_that,and_this_too))\n\n\n\n\n#We'll only show the first 10 rows here for brevity\n#for (i in 1:nrow(diabetes_glucose)) {\n\nfor (i in 1:10) {\n  Smoker &lt;- diabetes_glucose$Smoker[i]\n  BMI &lt;- diabetes_glucose$BMI[i]\n  \n  #skip rows where either of the values is NA\n  if (is.na(Smoker) | is.na(BMI)){\n    next\n  }\n    \n  if (Smoker == 'Smoker' & BMI &gt; 35){\n    print(c(Smoker, BMI, 'High risk'))\n  } else if (Smoker == 'Smoker' | BMI &gt; 35) {\n    print(c(Smoker, BMI,'Moderate risk'))\n  } else {\n    print(c(Smoker, BMI,'Low risk'))\n  }\n}\n\n[1] \"Unknown\"  \"24.7\"     \"Low risk\"\n[1] \"Unknown\"  \"22.5\"     \"Low risk\"\n[1] \"Unknown\"  \"34.5\"     \"Low risk\"\n[1] \"Never\"    \"26.3\"     \"Low risk\"\n[1] \"Smoker\"        \"35\"            \"Moderate risk\"\n[1] \"Smoker\"    \"43.3\"      \"High risk\"\n[1] \"Never\"    \"33.3\"     \"Low risk\"\n[1] \"Former\"        \"35.2\"          \"Moderate risk\"\n[1] \"Smoker\"    \"39.8\"      \"High risk\"\n[1] \"Smoker\"        \"30.8\"          \"Moderate risk\"",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#user-defined-functions",
    "href": "solutions/solution4.html#user-defined-functions",
    "title": "Exercise 4 - Solutions",
    "section": "User defined Functions",
    "text": "User defined Functions\nIn this part we will write some functions that create plots.\nSince we want to be able to pass the name of the column to plot as a variable we will need to use the syntax for aliased column names. We showed how to do that in the end of presentation 3 if you need a refresher.\n\nCreate a variable plot_column and assign “Age” to it. Now make a boxplot of that column. Switch plot_column to a different column in diabetes_glucose. Does it work?\n\n\n#the column we want to plot\nplot_column &lt;- 'Age'\n\n#make the plot\nggplot(diabetes_glucose, aes(y = .data[[plot_column]])) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nWrap your code for the boxplot into a function. The function should take two arguments: the dataframe to use and the name of the column to plot. Test your function. Add some customization to the plot like a theme or colors.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFunctions are good at returning objects so make your plot into an object and return that.\n\n\n\n\nmake_boxplot &lt;- function(df, plot_column){\n  \n  p &lt;- ggplot(df, aes(y = .data[[plot_column]])) +\n    geom_boxplot(fill = \"#03579A\") +\n    labs(title = paste(\"Boxplot of\", plot_column)) + \n    theme_bw()\n  \n  return(p)\n  \n}\n\nmake_boxplot(diabetes_glucose, 'Age')\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nAdd a check to your function whether the supplied column is numeric. Note here that you need to test the data type of the column you want to plot, not the data type of it’s name. Confirm that your check works.\n\n\nmake_boxplot &lt;- function(df, plot_column){\n  \n  if (!is.numeric(df[[plot_column]])){\n    stop('The column to plot must be numcerial.')\n  }\n  \n  p &lt;- ggplot(df, aes(y = .data[[plot_column]])) +\n    geom_boxplot(fill = \"#03579A\") +\n    labs(title = paste(\"Boxplot of\", plot_column)) + \n    theme_bw()\n  \n  return(p)\n  \n}\n\nmake_boxplot(diabetes_glucose, 'Sex')\n\nError in make_boxplot(diabetes_glucose, \"Sex\"): The column to plot must be numcerial.\n\n\n\nWrite code to apply your boxplot function to each numerical column in the dataframe. There are different ways to achieve this.\n\n\n# Our Idea: Find names of all numeric columns and plug them into a for loop\n\nnum_cols &lt;- diabetes_glucose %&gt;%\n  select(where(is.numeric)) %&gt;%\n  colnames()\n\n#check if correct columns found\nnum_cols\n\n[1] \"Age\"              \"BloodPressure\"    \"BMI\"              \"PhysicalActivity\"\n[5] \"Serum_ca2\"       \n\n#iterate over numeric columns and display plots\nfor(col in num_cols){\n  my_plot &lt;- make_boxplot(diabetes_glucose, col)\n  print(my_plot)\n  #alternative: if you want to extport the plots to files use something like:\n  #ggsave(paste0('../figures/boxplot_diabetes_',col,'.png'), width = 7, height = 5)\n}\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate an R script file to contain your functions. Copy your functions there and remove them from your global environment with rm(list=\"name_of_your_function\"). Now source the function R script in your quarto document and test that the functions work.\n\n\n#remove function from global environment so we can test if it loads properly from the script\nrm(list = \"make_boxplot\")\n\n\nsource('solution4_functions.R')\n\n\nmake_boxplot(diabetes_glucose, 'Age')\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#extra-exercises",
    "href": "solutions/solution4.html#extra-exercises",
    "title": "Exercise 4 - Solutions",
    "section": "Extra exercises",
    "text": "Extra exercises\nFirst, unnest diabetes_glucose so you get back the Measurement and Glucose columns.\n\ndiabetes_glucose_unnest &lt;- diabetes_glucose %&gt;%\n  unnest(OGTT)\n\ne1. Calculate the mean Glucose (mmol/L) for each measuring time point (i.e. one value for 0, 60 and 120). Now stratify this mean by a second variable, Sex. You should have 6 mean values since there are 6 groups (0_female, 0_male, 60_female, ect). Now, create a variable category to which you pass the name of the column to stratify by (e.g. category &lt;- 'Sex') and use category in your code instead of the literal variable name.\n\ncategory &lt;- 'Sex'\n\nglucose_group_mean &lt;- diabetes_glucose_unnest %&gt;%\n  group_by(Measurement, .data[[category]]) %&gt;%\n  summarize(glucose_mean = mean(`Glucose (mmol/L)`), .groups = \"drop\")\n\nglucose_group_mean\n\n# A tibble: 6 × 3\n  Measurement Sex    glucose_mean\n  &lt;fct&gt;       &lt;chr&gt;         &lt;dbl&gt;\n1 0           Female         8.10\n2 0           Male           8.02\n3 60          Female         9.71\n4 60          Male           9.74\n5 120         Female        11.0 \n6 120         Male          11.2 \n\n\ne2. We would like to make a plot that shows the means you calculated above. Again, use your category variable instead of the literal column name.\n\nglucose_group_mean %&gt;%\n    ggplot(aes(x = Measurement,\n               y = glucose_mean, \n               color = .data[[category]],\n               group = .data[[category]])) +\n    geom_point() +\n    geom_line()\n\n\n\n\n\n\n\n\ne3. Wrap the code from e1 and e2 into a function show_mean_by_catergory so that you can call: show_mean_by_catergory(diabetes_glucose_unnest, 'Sex') and it will make you the plot. Test with different columns.\n\nshow_mean_by_catergory &lt;- function(df,category){\n  \n  glucose_group_mean &lt;- df %&gt;%\n    group_by(Measurement, .data[[category]]) %&gt;%\n    summarize(glucose_mean = mean(`Glucose (mmol/L)`), .groups = \"drop\")\n  \n  p &lt;-glucose_group_mean %&gt;%\n    ggplot(aes(x = Measurement,\n               y = glucose_mean, \n               color = .data[[category]],\n               group = .data[[category]])) +\n    geom_point() +\n    geom_line()\n  \n  return(p)\n}\n\n\nshow_mean_by_catergory(diabetes_glucose_unnest, 'Smoker')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution5.html",
    "href": "solutions/solution5.html",
    "title": "Exercise 5 - Solutions",
    "section": "",
    "text": "Load packages\nlibrary(tidyverse)\nlibrary(ModelMetrics)\nlibrary(readxl)\nlibrary(caTools)\nlibrary(car)\nlibrary(ggfortify)",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 5 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution5.html#part-1-linear-regression",
    "href": "solutions/solution5.html#part-1-linear-regression",
    "title": "Exercise 5 - Solutions",
    "section": "Part 1: Linear regression",
    "text": "Part 1: Linear regression\n\nLoad the data boston.csv\n\n\ndf &lt;- as_tibble(read.delim('../data/boston.csv', sep = ','))\nhead(df)\n\n# A tibble: 6 × 6\n     crim indus   nox    rm  medv neighborhood\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       \n1 0.00632  2.31 0.538  6.58  24   Suburban    \n2 0.0273   7.07 0.469  6.42  21.6 Urban       \n3 0.0273   7.07 0.469  7.18  34.7 Rural       \n4 0.0324   2.18 0.458  7.00  33.4 Urban       \n5 0.0690   2.18 0.458  7.15  36.2 Suburban    \n6 0.0298   2.18 0.458  6.43  28.7 Suburban    \n\n\n\nNeighborhood is a categorical variable. We could make it a factor but it will also work as a character column (in the case of using lm).\nSplit the dataset into test and training data.\n\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#add an ID column to keep track of observations\ndf$ID &lt;- 1:nrow(df)\n\ntrain &lt;- df %&gt;% sample_frac(.75)\ntest  &lt;- anti_join(df, train, by = 'ID') \n\n\nFit the model\n\n\nmodel &lt;- lm(medv ~ rm + crim + neighborhood, data = train)\n\n\nsummary(model)\n\n\nCall:\nlm(formula = medv ~ rm + crim + neighborhood, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.920  -3.167  -0.468   2.746  35.052 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -25.52560    3.08810  -8.266 2.43e-15 ***\nrm                     7.63165    0.49122  15.536  &lt; 2e-16 ***\ncrim                  -0.22845    0.03525  -6.482 2.86e-10 ***\nneighborhoodSuburban   0.07995    0.75050   0.107    0.915    \nneighborhoodUrban      3.66323    0.84058   4.358 1.70e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.183 on 375 degrees of freedom\nMultiple R-squared:  0.5573,    Adjusted R-squared:  0.5525 \nF-statistic:   118 on 4 and 375 DF,  p-value: &lt; 2.2e-16\n\n\n\nrm and crim have a significant influence on the house price. An increase in the number of rooms increases the price since the coefficient is positive, whereas an increase in crime rate reduces the price. There is a significant difference in price between Rural and Urban zones, but not between Rural and Suburban. Rural is the reference level. Lastly, houses with 0 rooms cost -25k dollar. Perhaps the predictors should be centered before fitting the model around 0 so rm == 0 is the average number of rooms for better interpretability.\nScale the numeric predictor columns and redo the modelling. What has changed?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThere is a scale function, see ?scale().\n\n\n\n\ndf &lt;- df %&gt;%\n  mutate(across(where(is.numeric), scale, .names = \"standardized_{.col}\"))\n\nhead(df)\n\n# A tibble: 6 × 13\n     crim indus   nox    rm  medv neighborhood    ID standardized_crim[,1]\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;int&gt;                 &lt;dbl&gt;\n1 0.00632  2.31 0.538  6.58  24   Suburban         1                -0.419\n2 0.0273   7.07 0.469  6.42  21.6 Urban            2                -0.417\n3 0.0273   7.07 0.469  7.18  34.7 Rural            3                -0.417\n4 0.0324   2.18 0.458  7.00  33.4 Urban            4                -0.416\n5 0.0690   2.18 0.458  7.15  36.2 Suburban         5                -0.412\n6 0.0298   2.18 0.458  6.43  28.7 Suburban         6                -0.417\n# ℹ 5 more variables: standardized_indus &lt;dbl[,1]&gt;, standardized_nox &lt;dbl[,1]&gt;,\n#   standardized_rm &lt;dbl[,1]&gt;, standardized_medv &lt;dbl[,1]&gt;,\n#   standardized_ID &lt;dbl[,1]&gt;\n\n\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\ntrain &lt;- df %&gt;% sample_frac(.75)\ntest  &lt;- anti_join(df, train, by = 'ID') \n\n\nmodel_std &lt;- lm(medv ~ standardized_rm + standardized_crim + neighborhood, data = train)\nsummary(model_std)\n\n\nCall:\nlm(formula = medv ~ standardized_rm + standardized_crim + neighborhood, \n    data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.920  -3.167  -0.468   2.746  35.052 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          21.61103    0.52360  41.274  &lt; 2e-16 ***\nstandardized_rm       5.36213    0.34514  15.536  &lt; 2e-16 ***\nstandardized_crim    -1.96504    0.30317  -6.482 2.86e-10 ***\nneighborhoodSuburban  0.07995    0.75050   0.107    0.915    \nneighborhoodUrban     3.66323    0.84058   4.358 1.70e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.183 on 375 degrees of freedom\nMultiple R-squared:  0.5573,    Adjusted R-squared:  0.5525 \nF-statistic:   118 on 4 and 375 DF,  p-value: &lt; 2.2e-16\n\n\nAll significance observations stay the same since scaling can never affect that. The size of the coefficients will usually change since the range of the predictor (that they are multiplied with in the formula) has changed, but their direction stays the same. Now a house with the average number of rooms (rm == 0) costs 21k.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 5 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution5.html#part-2-logistic-regression",
    "href": "solutions/solution5.html#part-2-logistic-regression",
    "title": "Exercise 5 - Solutions",
    "section": "Part 2: Logistic regression",
    "text": "Part 2: Logistic regression\nFor this part we will use the joined diabetes data since it has a categorical outcome (Diabetes yes or no). We will not use the oral Glucose measurements as predictors since this is literally how you define diabetes, so we’re loading the joined dataset we created in exercise 1, e.g. ‘diabetes_join.xlsx’ or what you have named it.\n\ndiabetes_df &lt;- read_excel('../out/diabetes_join.xlsx')\nhead(diabetes_df)\n\n# A tibble: 6 × 11\n  ID    Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n1 9046  Male      34            84  24.7               93 Unknown 0       \n2 51676 Male      25            74  22.5              102 Unknown 0       \n3 60182 Male      50            80  34.5               98 Unknown 1       \n4 1665  Female    27            60  26.3               82 Never   0       \n5 56669 Male      35            84  35                 58 Smoker  1       \n6 53882 Female    31            78  43.3               59 Smoker  1       \n# ℹ 3 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;\n\n\nWe choose to make a regression model of Diabetes as predicted by serum calcium levels (Serum_ca2), BMI and smoking habits (Smoker).\n\nWe cannot have NA values in our predictors so remove all rows with NAs and save the result into a new dataframe diabetes_nona.\n\n\ndiabetes_nona &lt;- drop_na(diabetes_df)\nnrow(diabetes_nona)\n\n[1] 488\n\nnrow(diabetes_df)\n\n[1] 490\n\n\n\nMake the outcome variable into a factor if it is not already.\n\n\nclass(diabetes_nona$Diabetes)\n\n[1] \"character\"\n\ndiabetes_nona$Diabetes &lt;- factor(diabetes_nona$Diabetes)\nclass(diabetes_nona$Diabetes)\n\n[1] \"factor\"\n\n\n\nScale all numeric predictors. Check your result.\n\n\ndiabetes_nona &lt;- diabetes_nona %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale))\n\nhead(diabetes_nona)\n\n# A tibble: 6 × 11\n  ID    Sex    Age[,1] BloodPressure[,1] BMI[,1] PhysicalActivity[,1] Smoker \n  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;             &lt;dbl&gt;   &lt;dbl&gt;                &lt;dbl&gt; &lt;chr&gt;  \n1 9046  Male    0.0166             0.881  -0.820               0.351  Unknown\n2 51676 Male   -0.775              0.104  -1.15                0.708  Unknown\n3 60182 Male    1.42               0.570   0.646               0.550  Unknown\n4 1665  Female -0.599             -0.985  -0.581              -0.0855 Never  \n5 56669 Male    0.105              0.881   0.720              -1.04   Smoker \n6 53882 Female -0.247              0.415   1.96               -0.998  Smoker \n# ℹ 4 more variables: Diabetes &lt;fct&gt;, Serum_ca2 &lt;dbl[,1]&gt;, Married &lt;chr&gt;,\n#   Work &lt;chr&gt;\n\n\n\nSplit your data into training and test data. Take care that the two classes of the outcome variable are in the same ratio in both training and test data.\n\n\n# Set seed to ensure reproducibility\nset.seed(123)\n\nsplit &lt;- sample.split(diabetes_nona$Diabetes, SplitRatio = 0.75)\n\ntrain &lt;- diabetes_nona[split,]\ntest &lt;- diabetes_nona[!split,] #! negates the vector, so true becomes false and vice verse\n\ncount(train,Diabetes)\n\n# A tibble: 2 × 2\n  Diabetes     n\n  &lt;fct&gt;    &lt;int&gt;\n1 0          182\n2 1          184\n\ncount(test, Diabetes)\n\n# A tibble: 2 × 2\n  Diabetes     n\n  &lt;fct&gt;    &lt;int&gt;\n1 0           61\n2 1           61\n\n\n\nFit a regression model with Serum_ca2, BMI and Smoker as predictors. Check the model summary.\n\n\nmod1 &lt;- glm(Diabetes ~ Serum_ca2 + BMI + Smoker, data = train, family = binomial)\nsummary(mod1)\n\n\nCall:\nglm(formula = Diabetes ~ Serum_ca2 + BMI + Smoker, family = binomial, \n    data = train)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.9170  -0.1187   0.0004   0.2087   1.9340  \n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -0.1099     0.4541  -0.242   0.8088    \nSerum_ca2      -0.1028     0.2100  -0.490   0.6244    \nBMI             5.2882     0.6628   7.979 1.48e-15 ***\nSmokerNever    -1.3338     0.6335  -2.105   0.0353 *  \nSmokerSmoker    1.2924     0.6277   2.059   0.0395 *  \nSmokerUnknown  -0.1880     0.6831  -0.275   0.7832    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 507.37  on 365  degrees of freedom\nResidual deviance: 132.68  on 360  degrees of freedom\nAIC: 144.68\n\nNumber of Fisher Scoring iterations: 7\n\n\n\nCreate a second model with only BMI and Smoker as predictors. Compare the fit of your second model to the first one (including Serum_ca2). Is there a significant gain, i.e. better fit when including the serum calcium levels as predictor? Which model do you think is better?\n\n\nmod2 &lt;- glm(Diabetes ~ BMI + Smoker, data = train, family = binomial)\nsummary(mod2)\n\n\nCall:\nglm(formula = Diabetes ~ BMI + Smoker, family = binomial, data = train)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.9122  -0.1224   0.0004   0.1977   1.8537  \n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -0.1177     0.4532  -0.260   0.7951    \nBMI             5.2616     0.6557   8.025 1.02e-15 ***\nSmokerNever    -1.3237     0.6309  -2.098   0.0359 *  \nSmokerSmoker    1.3356     0.6233   2.143   0.0321 *  \nSmokerUnknown  -0.1545     0.6781  -0.228   0.8197    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 507.37  on 365  degrees of freedom\nResidual deviance: 132.92  on 361  degrees of freedom\nAIC: 142.92\n\nNumber of Fisher Scoring iterations: 7\n\n\n\nanova(mod1, mod2, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: Diabetes ~ Serum_ca2 + BMI + Smoker\nModel 2: Diabetes ~ BMI + Smoker\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       360     132.68                     \n2       361     132.92 -1 -0.23882   0.6251\n\n\nThe likelihood ratio test between the two models has an insignificant p-value. This means there is no evidence that including Serum_ca2 improves the fit of the model. The second model mod2 is therefore preferable.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 5 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution5.html#part-3-clustering",
    "href": "solutions/solution5.html#part-3-clustering",
    "title": "Exercise 5 - Solutions",
    "section": "Part 3: Clustering",
    "text": "Part 3: Clustering\nIn this part we will run clustering on the joined diabetes dataset from exercise 1. Load it here if you don’t have it already from Part 2.\n\n#in case\ndiabetes_df &lt;- read_excel('../out/diabetes_join.xlsx')\nhead(diabetes_df)\n\n# A tibble: 6 × 11\n  ID    Sex      Age BloodPressure   BMI PhysicalActivity Smoker  Diabetes\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n1 9046  Male      34            84  24.7               93 Unknown 0       \n2 51676 Male      25            74  22.5              102 Unknown 0       \n3 60182 Male      50            80  34.5               98 Unknown 1       \n4 1665  Female    27            60  26.3               82 Never   0       \n5 56669 Male      35            84  35                 58 Smoker  1       \n6 53882 Female    31            78  43.3               59 Smoker  1       \n# ℹ 3 more variables: Serum_ca2 &lt;dbl&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;\n\n\n\nRun the k-means clustering algorithm with 4 centers on the data. Consider which columns you can use and if you have to manipulate them before. If you get an error, check whether you have values that might not be admissible, such as NA.\n\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#run kmeans\nkmeans_res &lt;- diabetes_df %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #drop missing values\n  drop_na() %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  kmeans(centers = 4, nstart = 25)\n\nkmeans_res\n\nK-means clustering with 4 clusters of sizes 121, 105, 121, 141\n\nCluster means:\n         Age BloodPressure        BMI PhysicalActivity    Serum_ca2\n1 -0.5286070    -0.3058681 -0.6167955        0.3163233  1.009157782\n2 -0.5664483    -0.3764116 -0.8001807        0.9728678 -0.787111758\n3  1.3679241     0.8087592  0.3267171       -0.3222905 -0.009092463\n4 -0.2984418    -0.1512525  0.8448118       -0.7193553 -0.272065028\n\nClustering vector:\n  [1] 1 1 3 2 4 4 3 3 3 3 2 1 1 1 1 4 1 3 2 3 2 3 1 4 4 4 2 4 1 2 1 2 1 3 1 1 3\n [38] 1 4 2 4 4 1 1 4 1 4 4 2 4 1 4 1 2 2 3 4 2 3 1 4 3 4 2 4 1 2 1 1 1 1 2 2 3\n [75] 2 1 2 4 4 1 1 4 1 1 2 1 1 3 4 2 2 3 2 2 4 4 3 1 4 4 1 4 1 2 1 4 3 3 1 4 3\n[112] 4 3 2 2 2 2 2 1 3 3 2 2 4 3 2 4 1 3 3 1 2 1 3 4 1 2 3 2 1 3 3 2 1 2 3 1 2\n[149] 4 3 1 2 4 4 3 4 4 4 4 1 3 4 4 4 1 1 3 2 1 2 1 1 4 1 4 2 2 1 3 2 4 4 3 2 2\n[186] 3 1 4 3 1 1 2 1 3 2 3 3 4 1 2 3 2 3 4 4 3 1 3 3 4 4 4 3 2 2 1 1 4 3 3 4 3\n[223] 2 4 2 3 4 2 3 4 3 1 4 3 3 2 4 3 2 1 3 3 3 2 2 4 1 1 2 4 3 3 4 4 2 4 4 1 4\n[260] 1 2 1 4 4 4 1 2 3 3 1 4 1 3 1 1 4 2 4 3 3 4 3 3 4 1 3 4 3 4 3 1 4 4 3 2 3\n[297] 3 2 3 4 4 2 1 4 4 2 3 1 4 1 2 2 1 2 2 3 4 1 4 3 1 4 4 3 4 4 3 4 1 4 2 2 2\n[334] 1 3 2 1 3 1 3 4 4 4 1 1 1 2 4 4 4 2 2 4 4 4 1 3 4 3 4 1 3 1 3 1 1 4 2 2 3\n[371] 4 1 2 4 4 2 4 2 4 3 3 4 3 1 2 3 4 4 1 2 4 1 2 2 3 1 1 2 2 2 3 4 3 1 3 4 4\n[408] 3 2 3 4 4 1 1 4 4 3 3 4 3 2 4 4 4 1 4 2 1 3 4 1 4 2 3 4 1 1 4 1 1 2 3 2 3\n[445] 4 1 3 3 3 2 2 3 3 2 4 4 1 3 3 3 4 1 3 1 3 1 1 3 1 2 1 4 1 1 3 4 4 2 2 4 2\n[482] 2 3 3 4 1 4 3\n\nWithin cluster sum of squares by cluster:\n[1] 317.4167 315.8628 396.1259 367.9939\n (between_SS / total_SS =  42.6 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\nCheck whether the data you have run k-means on has the same number of rows as the dataframe with meta information, e.g. whether the person had diabetes. If they are not aligned, create a dataframe with Diabetes info that matches the dataframe you ran clustering on.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ndrop_na() takes an argument that tells which columns to look at for NA values.\n\n\n\nThe full data:\n\nnrow(diabetes_df)\n\n[1] 490\n\n\nHow many rows did we run clustering on?\n\ndiabetes_df %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #drop missing values\n  drop_na() %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  nrow()\n\n[1] 488\n\n\nWe could also have checked the length of kmeans_res$cluster:\n\nlength(kmeans_res$cluster)\n\n[1] 488\n\n\nSo we have omitted some rows. We need to omit the same rows from the original dataframe so our k-means clustering results are aligned with it.\n\ndiabetes_df &lt;- diabetes_df %&gt;%\n  drop_na(where(is.numeric))\nnrow(diabetes_df)\n\n[1] 488\n\n\n\nVisualize the results of your clustering.\n\nWe first need to calculate a PCA. This is basically the same we have done in exercise 3B.\n\npca_res &lt;- diabetes_df %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #drop missing values\n  drop_na() %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  prcomp()\n\nNow we project the k-means centroids in the PCA space\n\n#project cluster centers from kmeans into the pca space\ncenters_pca &lt;- predict(pca_res, newdata = kmeans_res$centers) %&gt;% as.data.frame()\n# Label clusters\ncenters_pca$cluster &lt;- as.factor(1:nrow(centers_pca))  \ncenters_pca\n\n         PC1         PC2        PC3         PC4         PC5 cluster\n1  0.9517476 -0.08349116 -0.9526042 -0.09077825  0.20829660       1\n2  1.3335463  0.41329140  0.8435674 -0.05601768 -0.07039558       2\n3 -1.3718134  0.80239970 -0.1598088  0.41230331 -0.12147179       3\n4 -0.6325844 -0.92470588  0.3264354 -0.23420338 -0.02208699       4\n\n\nAnd add cluster assignments to the diabetes_df:\n\ndiabetes_df$Cluster &lt;- factor(kmeans_res$cluster)\n\nFinally we can plot:\n\nautoplot(pca_res, data = diabetes_df, color = 'Cluster',\n         loadings = TRUE, loadings.colour = \"grey30\", \n         loadings.label.colour = \"black\",\n         loadings.label = TRUE, loadings.label.size = 3.5,\n         scale = 0) + \n  theme_minimal() +\n  labs(title = \"PCA of Diabetes Dataset\") +\n  # Cluster centers\n  geom_point(data = centers_pca, aes(x = PC1, y = PC2, color = cluster),\n             shape = 8, size = 6, stroke = 2)  \n\n\n\n\n\n\n\n\nWell the separation was not that good in exercise 3B so perhaps we should not expect very clean clusters.\n\nInvestigate the best number of clusters.\n\n\nlibrary(factoextra)\n\nWarning: pakke 'factoextra' blev bygget under R version 4.2.3\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\ndiabetes_df %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #drop missing values\n  drop_na() %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  fviz_nbclust(kmeans, method = \"wss\")\n\n\n\n\n\n\n\n\n\ndiabetes_df %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #drop missing values\n  drop_na() %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  fviz_nbclust(kmeans, method = \"silhouette\")\n\n\n\n\n\n\n\n\n\ndiabetes_df %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #drop missing values\n  drop_na() %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  fviz_nbclust(kmeans, method = \"gap_stat\")\n\n\n\n\n\n\n\n\nThe elbow is not very clear but the silhouette and gap statistic favor 2 clusters - which kind of makes sense since we have two outcomes, diabetic and non-diabetic.\n\nRe-do the clustering (plus visualization) with that number.\n\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#run kmeans\nkmeans_res &lt;- diabetes_df %&gt;%\n  select(where(is.numeric)) %&gt;%\n  #drop missing values\n  drop_na() %&gt;%\n  #scale all numeric cols\n  mutate(across(where(is.numeric), scale)) %&gt;%\n  kmeans(centers = 2, nstart = 25)\n\nkmeans_res\n\nK-means clustering with 2 clusters of sizes 257, 231\n\nCluster means:\n         Age BloodPressure        BMI PhysicalActivity  Serum_ca2\n1  0.4697155     0.3538870  0.6621866       -0.5424263 -0.1002325\n2 -0.5225839    -0.3937184 -0.7367184        0.6034786  0.1115140\n\nClustering vector:\n  [1] 2 2 1 2 1 1 1 1 1 1 2 2 2 2 2 1 2 1 2 1 2 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1\n [38] 1 2 2 1 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 2 1 2 1 1 1 2 1 2 2 2 2 2 2 2 2 1\n [75] 2 2 2 1 1 2 2 2 2 2 2 1 2 1 1 2 2 1 2 2 1 1 1 2 1 1 2 1 2 2 2 1 1 1 2 1 1\n[112] 2 1 2 2 2 2 2 2 2 1 2 2 1 1 2 1 2 1 1 2 2 2 1 1 2 2 1 2 2 1 1 2 2 2 1 2 1\n[149] 1 1 2 2 2 1 1 1 1 1 1 2 1 2 2 1 1 2 1 2 2 2 1 2 1 2 1 2 2 2 1 2 1 1 1 2 2\n[186] 2 2 1 1 2 1 2 2 1 2 1 1 1 2 2 1 2 1 1 1 1 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 1\n[223] 2 1 2 1 1 2 1 1 1 2 1 1 1 2 2 1 2 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 2 1 1 2 1\n[260] 2 2 2 1 1 1 2 2 1 1 2 1 2 1 2 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1\n[297] 1 2 1 1 1 2 2 1 1 2 1 2 1 2 2 1 2 2 2 1 1 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 2\n[334] 2 1 2 2 1 2 1 1 1 1 2 2 2 2 1 1 1 2 2 1 1 1 2 1 1 1 1 2 1 2 1 2 2 1 2 2 1\n[371] 1 2 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2 2 1 1 1 2 1 1 2\n[408] 1 2 1 1 1 2 2 2 1 1 1 1 2 2 2 1 1 2 1 2 2 1 1 2 1 2 2 1 1 1 2 2 2 2 1 2 1\n[445] 1 2 1 1 1 2 2 1 1 2 1 1 1 2 2 1 1 2 1 2 1 2 2 1 2 2 2 1 2 2 1 1 1 2 2 1 2\n[482] 2 1 1 1 2 1 1\n\nWithin cluster sum of squares by cluster:\n[1] 959.9630 883.9897\n (between_SS / total_SS =  24.3 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\n#project cluster centers from kmeans into the pca space\ncenters_pca &lt;- predict(pca_res, newdata = kmeans_res$centers) %&gt;% as.data.frame()\n# Label clusters\ncenters_pca$cluster &lt;- as.factor(1:nrow(centers_pca))  \ncenters_pca\n\n        PC1        PC2         PC3          PC4         PC5 cluster\n1 -1.032372 -0.1214937  0.05219972  0.003763692 -0.07308096       1\n2  1.148570  0.1351683 -0.05807502 -0.004187311  0.08130652       2\n\n\n\ndiabetes_df$Cluster &lt;- factor(kmeans_res$cluster)\n\n\nautoplot(pca_res, data = diabetes_df, color = 'Cluster',\n         loadings = TRUE, loadings.colour = \"grey30\", \n         loadings.label.colour = \"black\",\n         loadings.label = TRUE, loadings.label.size = 3.5,\n         scale = 0) + \n  theme_minimal() +\n  labs(title = \"PCA of Diabetes Dataset\") +\n  # Cluster centers\n  geom_point(data = centers_pca, aes(x = PC1, y = PC2, color = cluster),\n             shape = 8, size = 6, stroke = 2)",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 5 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution5.html#extra-exercises",
    "href": "solutions/solution5.html#extra-exercises",
    "title": "Exercise 5 - Solutions",
    "section": "Extra exercises",
    "text": "Extra exercises\ne1. Find the best single predictor in the Diabetes dataset. This is done by comparing the null model (no predictors) to all possible models with one predictor, i.e. outcome ~ predictor, outcome ~ predictor2, ect. The null model can be formulated like so: outcome ~ 1 (only the intercept). Fit all possible one predictor models and compare their fit to the null model with a likelihood ratio test. Find the predictor with the lowest p-value in the likelihood ratio test. This can be done in a loop in order to avoid writing out all models.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo use a formula with a variable you will need to combine the literal part and the variable with paste, e.g. paste(\"Outcome ~\", my_pred).\n\n\n\n\n# Define the null model (intercept-only model)\nnull_model &lt;- glm(Diabetes ~ 1, data = train, family = binomial)\n\n# Get predictor names (excluding the outcome variable)\npredictors &lt;- setdiff(names(diabetes_nona), c(\"Diabetes\", \"ID\"))\n\n# Initialize an empty data frame to store results\nresults &lt;- data.frame(Predictor = character(), ChiSq = numeric(), P_Value = numeric(), stringsAsFactors = FALSE)\n\n# Loop through each predictor and fit a logistic regression model\nfor (pred in predictors) {\n  \n  # Fit model with single predictor\n  model_pred &lt;- glm(paste(\"Diabetes ~\", pred), data = train, family = binomial)\n  \n  # Perform Likelihood Ratio Test\n  test_result &lt;- anova(null_model, model_pred, test = \"Chisq\")\n  \n  # Extract Chi-square statistic and p-value\n  chi_sq &lt;- test_result$Deviance[2]  # The second row corresponds to the predictor model\n  p_value &lt;- test_result$`Pr(&gt;Chi)`[2]\n  \n  # Store results\n  results &lt;- rbind(results, data.frame(Predictor = pred, ChiSq = chi_sq, P_Value = p_value))\n}\n\n# Print the results sorted by p-value\nresults &lt;- results %&gt;% arrange(P_Value)\nprint(results)\n\n         Predictor       ChiSq      P_Value\n1              BMI 353.0033684 9.399861e-79\n2 PhysicalActivity 174.3147338 8.449925e-40\n3           Smoker  69.2823192 6.080298e-15\n4              Age  30.2674741 3.763850e-08\n5    BloodPressure  13.6648488 2.185065e-04\n6             Work   6.6505603 8.391019e-02\n7          Married   2.6869823 1.011713e-01\n8              Sex   1.8470863 1.741227e-01\n9        Serum_ca2   0.7986775 3.714891e-01\n\n\ne2. Write a function that handles visualization of k-means clustering results. Think about which information you need to pass and what it should return.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 5 - Solution"
    ]
  },
  {
    "objectID": "exercises/exercise6.html",
    "href": "exercises/exercise6.html",
    "title": "Exercise 6: Understanding and improving an R script",
    "section": "",
    "text": "In this exercise you got through the script analysis.R together with your neighbors, find out what the data is that is being worked and which analysis is done and how. There are also some things that could be an issue, so have an eye out and try to think how you could improve the script.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 6: Understanding and improving an R script"
    ]
  }
]
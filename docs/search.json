[
  {
    "objectID": "solutions/solution_not_up.html",
    "href": "solutions/solution_not_up.html",
    "title": "Solution not up yet!",
    "section": "",
    "text": "Solutions will be available only after you’ve had a chance to work through the exercises on your own. If you’re unsure how to proceed, check the slides, cheat sheets, ask a peer, or reach out to a TA.\n\nEnjoy!"
  },
  {
    "objectID": "solutions/solution4_functions.html",
    "href": "solutions/solution4_functions.html",
    "title": "Exercise 4, Functions- Solutions",
    "section": "",
    "text": "Here is the solution4_functions.R showed:\n\n\n\nmake_boxplot &lt;- function(df, plot_column){\n  \n  if (!is.numeric(df[[plot_column]])){\n    stop('The column to plot must be numcerial.')\n  }\n  \n  p &lt;- ggplot(df, aes(y = .data[[plot_column]])) +\n    geom_boxplot(fill = \"#03579A\") +\n    labs(title = paste(\"Boxplot of\", plot_column)) + \n    theme_bw()\n  \n  return(p)\n  \n}\n\n# 2. Function that take dataframe and a numerical value and returns a boxplot. \n# Required packages: ggplot2\nboxplot &lt;- function(df, var_num){\n  \n  p &lt;- df %&gt;% \n    ggplot(aes_string(y = var_num)) + \n    geom_boxplot(fill = \"#03579A\") +\n    labs(title = paste(\"Boxplot of\", var_num)) + \n    theme_bw() + \n    theme(text = element_text(family=\"Avenir\"))\n  \n  return(p)\n  \n}\n\n# 8. Function that take dataframe and a numerical value and returns a density plot. \n# Required packages: ggplot2\nbar_plot &lt;- function(df, var_cat){\n  \n  p &lt;- df %&gt;% \n    ggplot(aes_string(x = var_cat)) + \n    geom_bar(fill = \"#03579A\") + \n    labs(title = paste(\"Barplot of\", var_cat)) + \n    theme_bw() + \n    theme(text = element_text(family=\"Avenir\"))\n  \n  return(p)\n  \n}\n\n# 11. Like #2 boxplot, with error handling.\n# Required packages: ggplot2\nboxplot_2 &lt;- function(df, var_num){\n  \n  # Check if the numerical variable is numerical \n  if (!is.numeric(df[[var_num]])){\n    stop('The numerical variable (var_num) must be numcerial.')\n  }\n  \n  p &lt;- df %&gt;% \n    ggplot(aes_string(y = var_num)) + \n    geom_boxplot(fill = \"#03579A\") +\n    labs(title = paste(\"Boxplot of\", var_num)) + \n    theme_bw() + \n    theme(text = element_text(family=\"Avenir\"))\n  \n  return(p)\n  \n}\n\n# 14. Like #8 density_plot, with error handling.\n# Required packages: ggplot2\nbar_plot_2 &lt;- function(df, var_cat){\n\n  # Check if the categorical variable is either character or factor\n  if (!(is.character(df[[var_cat]]) | is.factor(df[[var_cat]]))){\n    stop('The categorical variable (var_cat) must be a character or factor.')\n  } \n  \n  p &lt;- df %&gt;% \n    ggplot(aes_string(x = var_cat)) + \n    geom_bar(fill = \"#03579A\") + \n    labs(title = paste(\"Barplot of\", var_cat)) + \n    theme_bw() + \n    theme(text = element_text(family=\"Avenir\"))\n  \n  return(p)\n  \n}\n\n# 17. Function that takes an ID and outputs a graph of the glucose measurement over time.\n# Required packages: dplyr, ggplot2\nglucose_measurement_id_plot &lt;- function(df, id){\n  \n  # Check if id is character\n  if (!is.character(id)){\n    stop('The ID must be a character.')\n  } \n  \n  p &lt;- df %&gt;% \n    filter(ID == id) %&gt;% \n    ggplot(aes_string(x = \"Measurement\", \n                      y = \"`Glucose (mmol/L)`\")) +\n    geom_point(color = \"#03579A\") + \n    geom_line(color = \"#03579A\") + \n    labs(title = paste(\"Oral Glucose Tolerance Test of ID:\", id)) + \n    theme_bw() +\n    theme(text = element_text(family=\"Avenir\")) \n  \n  return(p)\n  \n}\n\n# 19. This function takes a categorical variable and a dataframe as input, calculates the mean glucose content for each category and measurement time, and outputs a line graph showing the glucose measurements over time.\n# Required packages: dplyr, ggplot2\nglucose_measurement_mean_plot &lt;- function(df, var_cat){\n\n  # Check if the categorical variable is either character or factor\n  if (!(is.character(df[[var_cat]]) | is.factor(df[[var_cat]]))){\n    stop('The categorical variable (var_cat) must be a character or factor.')\n  } \n  \n  # Calculate the mean glucose values for each category and measurement time\n  glucose_group_mean &lt;- df %&gt;% \n    group_by(Measurement, .data[[var_cat]]) %&gt;%\n    summarize(glucose_mean = mean(`Glucose (mmol/L)`), .groups = \"drop\") %&gt;%\n    ungroup()\n  \n  # Dynamically select colors based on the number of unique categories\n  colors &lt;- c(\"#03579A\", \"#3986C7\", \"#F9DA8C\", \"#404857\", \"#A41E23\")\n  n_colors &lt;- df[[var_cat]] %&gt;% unique() %&gt;% length()\n  colors &lt;- colors[1:n_colors]\n  \n  # Create a ggplot object to visualize the mean glucose measurements\n  p &lt;- glucose_group_mean %&gt;%\n    ggplot(aes_string(x = \"Measurement\",\n                      y = \"glucose_mean\", \n                      color = var_cat)) +\n    geom_point() +\n    geom_line() +\n    scale_color_manual(values = colors) +\n    labs(title = paste(\"Mean Oral Glucose Tolerance Test Across\", var_cat), \n         y = \"Mean Glucose (mmol/L)\") +\n    theme_bw() +\n    theme(text = element_text(family=\"Avenir\"))\n\n  return(p)\n  \n}",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4, Function - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3.html",
    "href": "solutions/solution3.html",
    "title": "Exercise 3 - Solutions: Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\n\n\nLoad data from the .rds file you created in Exercise 2. Have a guess at what the function is called.\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\nhead(diabetes_glucose)\n\n# A tibble: 6 × 12\n  ID    Sex      Age BloodPressure GeneticRisk   BMI PhysicalActivity Smoker \n  &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  \n1 9046  Male      34            84       0.619  24.7               93 Unknown\n2 51676 Male      25            74       0.591  22.5              102 Unknown\n3 60182 Male      50            80       0.178  34.5               98 Unknown\n4 1665  Female    27            60       0.206  26.3               82 Never  \n5 56669 Male      35            84       0.286  35                 58 Smoker \n6 53882 Female    31            78       1.22   43.3               59 Smoker \n# ℹ 4 more variables: Diabetes &lt;chr&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3.html#getting-started",
    "href": "solutions/solution3.html#getting-started",
    "title": "Exercise 3 - Solutions: Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\n\n\nLoad data from the .rds file you created in Exercise 2. Have a guess at what the function is called.\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\nhead(diabetes_glucose)\n\n# A tibble: 6 × 12\n  ID    Sex      Age BloodPressure GeneticRisk   BMI PhysicalActivity Smoker \n  &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  \n1 9046  Male      34            84       0.619  24.7               93 Unknown\n2 51676 Male      25            74       0.591  22.5              102 Unknown\n3 60182 Male      50            80       0.178  34.5               98 Unknown\n4 1665  Female    27            60       0.206  26.3               82 Never  \n5 56669 Male      35            84       0.286  35                 58 Smoker \n6 53882 Female    31            78       1.22   43.3               59 Smoker \n# ℹ 4 more variables: Diabetes &lt;chr&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3.html#plotting---part-1",
    "href": "solutions/solution3.html#plotting---part-1",
    "title": "Exercise 3 - Solutions: Exploratory Data Analysis (EDA)",
    "section": "Plotting - Part 1",
    "text": "Plotting - Part 1\nYou will first do some basic plots to get started with ggplot again.\nIf it has been a while since you worked with ggplot, have a look at the ggplot material from the FromExceltoR course.\n\nCreate a scatter plot of Age and Blood Pressure. Do you notice a trend?\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(x = BloodPressure, \n             y = Age)) + \n  geom_point() \n\n\n\n\n\n\n\n\n\nCreate a scatter plot of PhysicalActivity and BMI. Do you notice a trend?\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(x = PhysicalActivity, \n             y = BMI)) + \n  geom_point() \n\n\n\n\n\n\n\n\n\nNow, create the same two plots as before, but this time stratify them by Diabetes. Do you notice any trends?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can stratify a plot by a categorical variable in several ways, depending on the type of plot. The purpose of stratification is to distinguish samples based on their categorical values, making patterns or differences easier to identify. This can be done using aesthetics like color, fill, shape.\n\n\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(x = BloodPressure, \n             y = Age, \n             color = Diabetes)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(x = PhysicalActivity, \n             y = BMI, \n             color = Diabetes)) + \n  geom_point() \n\n\n\n\n\n\n\n\n\nCreate a boxplot of BMI stratified by Diabetes. Give the plot a meaningful title.\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(y = BMI, \n             x = Diabetes, \n             color = Diabetes)) + \n  geom_boxplot() + \n  labs(title = 'Distribution of BMI Stratified by Diabetes')\n\n\n\n\n\n\n\n\n\nCreate a boxplot of PhysicalActivity stratified by Smoker. Give the plot a meaningful title.\n\n\ndiabetes_glucose %&gt;% \n  ggplot(aes(y = PhysicalActivity, \n             x = Smoker, \n             fill = Smoker)) + \n  geom_boxplot() + \n  labs(title = 'Distribution of Physical Activity Stratified by Smoker Status')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3.html#plotting---part-2",
    "href": "solutions/solution3.html#plotting---part-2",
    "title": "Exercise 3 - Solutions: Exploratory Data Analysis (EDA)",
    "section": "Plotting - Part 2",
    "text": "Plotting - Part 2\nIn order to plot the data inside the nested variable, the data needs to be unnested.\n\nCreate a boxplot of the glucose measurements at time 0 stratified by Diabetes. Give the plot a meaningful title.\n\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  filter(Measurement == 0) %&gt;% \n  ggplot(aes(y = `Glucose (mmol/L)`, \n             x = Diabetes, \n             color = Diabetes)) +\n  geom_boxplot() + \n  labs(title = 'Glucose Measurement for Time Point 0 (fasted)')\n\n\n\n\n\n\n\n\n\nCreate these boxplots for each time point (0, 60, 120) by using faceting by Measurement. Give the plot a meaningful title.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFaceting allows you to create multiple plots based on the values of a categorical variable, making it easier to compare patterns across groups. In ggplot2, you can use facet_wrap for a single variable or facet_grid for multiple variables.\n\n\n\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  ggplot(aes(y = `Glucose (mmol/L)`, \n             x = Diabetes, \n             color = Diabetes)) +\n  geom_boxplot() + \n  facet_wrap(vars(Measurement)) + \n  labs(title = 'Glucose Measurements for Time Point 0, 60, and 120')\n\n\n\n\n\n\n\n\n\nCalculate the mean glucose levels for each time point.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use unnest(), group_by(), and summerise().\n\n\n\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  group_by(Measurement) %&gt;% \n  summarise(`Glucose (mmol/L)` = mean(`Glucose (mmol/L)`))\n\n# A tibble: 3 × 2\n  Measurement `Glucose (mmol/L)`\n  &lt;fct&gt;                    &lt;dbl&gt;\n1 0                         8.06\n2 60                        9.74\n3 120                      11.1 \n\n\n\nMake the same calculation as above, but additionally group the results by Diabetes. Save the data frame in a variable. Compare your results to the boxplots you made above.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nGroup by several variables: group_by(var1, var2).\n\n\n\n\nglucose_mean &lt;- diabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  group_by(Measurement, Diabetes) %&gt;%\n  summarize(`Glucose (mmol/L)` = mean(`Glucose (mmol/L)`)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'Measurement'. You can override using the\n`.groups` argument.\n\nglucose_mean\n\n# A tibble: 6 × 3\n  Measurement Diabetes `Glucose (mmol/L)`\n  &lt;fct&gt;       &lt;chr&gt;                 &lt;dbl&gt;\n1 0           0                      5.51\n2 0           1                     10.6 \n3 60          0                      6.83\n4 60          1                     12.6 \n5 120         0                      7.89\n6 120         1                     14.2 \n\n\n\nCreate a plot that visualizes glucose measurements across time points, with one line for each patient ID. Then color the lines by their diabetes status. In summary, each patient’s glucose measurements should be connected with a line, grouped by their ID, and color-coded by Diabetes. Give the plot a meaningful title.\n\nIf your time points are strangely ordered have a look at the levels of your Measurement variable (the one that specifies which time point the measurement was taken at) and if necessary fix their order.\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  ggplot(aes(x = Measurement,\n             y = `Glucose (mmol/L)`)) +\n  geom_point(aes(color = Diabetes)) + \n  geom_line(aes(group = ID, color = Diabetes)) + \n  labs(title = 'Glucose Measurements Across Time Points by Diabetes Status')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3.html#plotting---part-3-pca",
    "href": "solutions/solution3.html#plotting---part-3-pca",
    "title": "Exercise 3 - Solutions: Exploratory Data Analysis (EDA)",
    "section": "Plotting - Part 3: PCA",
    "text": "Plotting - Part 3: PCA\nFor this part we will use this tutorial to make a principal component analysis (PCA). First, we perform some preprocessing to get our data into the right format.\n\nLet’s start by unnesting the OGTT data and using pivot wider so that each Glucose measurement time point gets its own column (again).\n\n\ndiabetes_glucose_unnest &lt;-  diabetes_glucose %&gt;% \n  unnest(OGTT) %&gt;% \n  pivot_wider(names_from = Measurement, \n              values_from = `Glucose (mmol/L)`, \n              names_prefix = \"Glucose_\")\n\ndiabetes_glucose_unnest\n\n# A tibble: 493 × 14\n   ID    Sex      Age BloodPressure GeneticRisk   BMI PhysicalActivity Smoker \n   &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  \n 1 9046  Male      34            84       0.619  24.7               93 Unknown\n 2 51676 Male      25            74       0.591  22.5              102 Unknown\n 3 60182 Male      50            80       0.178  34.5               98 Unknown\n 4 1665  Female    27            60       0.206  26.3               82 Never  \n 5 56669 Male      35            84       0.286  35                 58 Smoker \n 6 53882 Female    31            78       1.22   43.3               59 Smoker \n 7 10434 Male      52            86       1.15   33.3               58 Never  \n 8 27419 Female    54            78       0.692  35.2               74 Former \n 9 60491 Female    41            90       0.451  39.8               67 Smoker \n10 12109 Female    36            82       0.18   30.8               81 Smoker \n# ℹ 483 more rows\n# ℹ 6 more variables: Diabetes &lt;chr&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;,\n#   Glucose_0 &lt;dbl&gt;, Glucose_60 &lt;dbl&gt;, Glucose_120 &lt;dbl&gt;\n\n\n\nHave a look at your unnested diabetes data set. Can you use all the variables to perform PCA? Subset the dataset to only include the relevant variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nPCA can only be performed on numerical values. Extract these (except ID!) from the dataset. Numerical columns can easily be selected with the where(is.numeric) helper.\n\n\n\nExtract the numerical columns, including the OGTT measurements.\n\ndiabetes_glucose_numerical &lt;- diabetes_glucose_unnest %&gt;%\n  select(where(is.numeric))\n\ndiabetes_glucose_numerical\n\n# A tibble: 493 × 8\n     Age BloodPressure GeneticRisk   BMI PhysicalActivity Glucose_0 Glucose_60\n   &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1    34            84       0.619  24.7               93      6.65       8.04\n 2    25            74       0.591  22.5              102      4.49       5.40\n 3    50            80       0.178  34.5               98     12.9       14.3 \n 4    27            60       0.206  26.3               82      5.76       6.52\n 5    35            84       0.286  35                 58     10.8       16.2 \n 6    31            78       1.22   43.3               59     11.1       12.8 \n 7    52            86       1.15   33.3               58     10.4       14.7 \n 8    54            78       0.692  35.2               74      6.79      10.1 \n 9    41            90       0.451  39.8               67      7.39      10.3 \n10    36            82       0.18   30.8               81     11.6       13.0 \n# ℹ 483 more rows\n# ℹ 1 more variable: Glucose_120 &lt;dbl&gt;\n\n\n\nPCA cannot handle NA’s in the dataset. Remove all rows with NA in any column in your numerical subset. Then, go back to the original unnested data diabetes_glucose_unnest (or what you have called it) and also here drop rows that have NAs in the numerical columns (so the same rows you dropped from the numeric subset).This is important because we want to use (categorical) columns present in the original data to later color the resulting PCA, so the two dataframes (original and only numeric columns) need to be aligned and contain the same rows.\n\n\ndiabetes_glucose_numerical &lt;- drop_na(diabetes_glucose_numerical)\nnrow(diabetes_glucose_numerical)\n\n[1] 488\n\n\nAlign original data.\n\ndiabetes_glucose_unnest &lt;- diabetes_glucose_unnest %&gt;%\n  drop_na(colnames(diabetes_glucose_numerical))\nnrow(diabetes_glucose_unnest)\n\n[1] 488\n\n\nNow our data is ready to make a PCA.\n\nCalculate the PCA by running prcomp on our prepared data (see the tutorial). Then, create a plot of the resulting PCA (also shown in tutorial).\n\n\nlibrary(ggfortify)\n\nWarning: pakke 'ggfortify' blev bygget under R version 4.2.3\n\npca_res &lt;- prcomp(diabetes_glucose_numerical, scale. = TRUE)\n\nautoplot(pca_res)\n\n\n\n\n\n\n\n\n\nColor your PCA plot and add loadings. Think about which variable you want to color by. Remember to refer to the dataset that has this variable (probably not your numeric subset!)\n\n\nautoplot(pca_res, data = diabetes_glucose_unnest, colour = 'Diabetes',\n         loadings = TRUE, loadings.colour = 'black',\n         loadings.label = TRUE, loadings.label.size = 3)\n\n\n\n\n\n\n\n\n\nAdd a ggplot theme and title to your plot and save it.\n\n\nautoplot(pca_res, data = diabetes_glucose_unnest, colour = \"Diabetes\",\n         loadings = TRUE, loadings.colour = \"grey30\", loadings.label.colour = \"black\",\n         loadings.label = TRUE, loadings.label.size = 3.5) + \n  theme_minimal() + \n  labs(title = \"PCA of Diabetes Dataset\")\n\n\n\n\n\n\n\nggsave('../figures/PCA_diabetes.png', width = 7, height = 5)\n\n\nCalculate the variance explained by each of the PC’s using the following formula:\n\n\\[\n\\text{Variance Explained} = \\frac{\\text{sdev}^2}{\\sum \\text{sdev}^2} \\times 100\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can access the standard deviation from the PCA object like this: pca_res$sdev.\n\n\n\n\nvariance_explained &lt;- ((pca_res$sdev^2) / sum(pca_res$sdev^2)) * 100\nvariance_explained\n\n[1] 47.76548305 15.46894055 11.55448017  8.45259213  7.50812423  5.13863785\n[7]  4.02205644  0.08968558\n\n\n\nCreate a two column data-frame with the names of the PC’s (PC1, PC2, ect) in one column and the variance explained by that PC in the other column.\n\n\ndf_variance_explained &lt;- tibble(PC = c(paste0('PC', 1:length(variance_explained))),\n                                variance_explained = variance_explained)\n\ndf_variance_explained\n\n# A tibble: 8 × 2\n  PC    variance_explained\n  &lt;chr&gt;              &lt;dbl&gt;\n1 PC1              47.8   \n2 PC2              15.5   \n3 PC3              11.6   \n4 PC4               8.45  \n5 PC5               7.51  \n6 PC6               5.14  \n7 PC7               4.02  \n8 PC8               0.0897\n\n\n\nNow create a bar plot (using geom_col), showing for each PC the amount of explained variance. This type of plot is called a scree plot.\n\n\ndf_variance_explained %&gt;% \n  ggplot(aes(x = PC, \n             y = variance_explained))+ \n  geom_col() + \n  labs(title = \"Varinace explained for each PC\", \n       y = \"Variance Explained\")\n\n\n\n\n\n\n\n\n\nLastly, render you quarto document and review the resulting html file.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution3.html#extra",
    "href": "solutions/solution3.html#extra",
    "title": "Exercise 3 - Solutions: Exploratory Data Analysis (EDA)",
    "section": "Extra",
    "text": "Extra\ne1. Recreate the plot you made in Exercise 12 and include the mean value for each glucose measurement for the two diabetes statuses (0 and 1) you calculated in Exercise 11. This plot should look like this:\n\n\n\n\n\n\ndiabetes_glucose %&gt;%\n  unnest(OGTT) %&gt;% \n  ggplot(aes(x = Measurement,\n             y = `Glucose (mmol/L)`)) +\n  geom_point(aes(color = Diabetes)) + \n  geom_line(aes(group = ID, color = Diabetes)) + \n  geom_point(data = glucose_mean, aes(x = Measurement, y = `Glucose (mmol/L)`)) +\n  geom_line(data = glucose_mean, aes(x = Measurement, y = `Glucose (mmol/L)`, \n                                     group = Diabetes, linetype = Diabetes)) +\n  labs(title = \"Glucose Measurements with Mean by Diabetes Status\")\n\n\n\n\n\n\n\nggsave('../out/figure3_13.png')\n\nSaving 7 x 5 in image",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 3 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html",
    "href": "solutions/solution1.html",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n\nLoad in the diabetes_clinical_toy_messy.xlsx data set.\n\n\ndiabetes_clinical &lt;- read_excel('../data/diabetes_clinical_toy_messy.xlsx')\nhead(diabetes_clinical)\n\n# A tibble: 6 × 9\n     ID Sex      Age BloodPressure GeneticRisk   BMI PhysicalActivity Smoker \n  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  \n1  9046 Male      34            84       0.619  24.7               93 Unknown\n2 51676 Male      25            74       0.591  22.5              102 Unknown\n3 31112 Male      30             0       0.839  32.3               75 Former \n4 60182 Male      50            80       0.178  34.5               98 Unknown\n5  1665 Female    27            60       0.206  26.3               82 Never  \n6 56669 Male      35            84       0.286  35                 58 Smoker \n# ℹ 1 more variable: Diabetes &lt;dbl&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#getting-started",
    "href": "solutions/solution1.html#getting-started",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "",
    "text": "Load packages.\n\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n\nLoad in the diabetes_clinical_toy_messy.xlsx data set.\n\n\ndiabetes_clinical &lt;- read_excel('../data/diabetes_clinical_toy_messy.xlsx')\nhead(diabetes_clinical)\n\n# A tibble: 6 × 9\n     ID Sex      Age BloodPressure GeneticRisk   BMI PhysicalActivity Smoker \n  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  \n1  9046 Male      34            84       0.619  24.7               93 Unknown\n2 51676 Male      25            74       0.591  22.5              102 Unknown\n3 31112 Male      30             0       0.839  32.3               75 Former \n4 60182 Male      50            80       0.178  34.5               98 Unknown\n5  1665 Female    27            60       0.206  26.3               82 Never  \n6 56669 Male      35            84       0.286  35                 58 Smoker \n# ℹ 1 more variable: Diabetes &lt;dbl&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#explore-the-data",
    "href": "solutions/solution1.html#explore-the-data",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "Explore the data",
    "text": "Explore the data\nUse can you either base R or/and tidyverse to solve the exercises.\n\nHow many missing values (NA’s) are there in each column.\n\n\ncolSums(is.na(diabetes_clinical))\n\n              ID              Sex              Age    BloodPressure \n               0                0                0                0 \n     GeneticRisk              BMI PhysicalActivity           Smoker \n               5                0                0                0 \n        Diabetes \n               0 \n\n\n\nCheck the distribution of each of the variables. Consider that the variables are of different classes. Do any of the distributions seem odd to you?\n\nFor the categorical variables:\nThe Sex values are not consistent.\n\ntable(diabetes_clinical$Sex)\n\n\nFemale FEMALE   male   Male \n   291      2      2    237 \n\ntable(diabetes_clinical$Smoker)\n\n\n Former   Never  Smoker Unknown \n    132     159     162      79 \n\ntable(diabetes_clinical$Diabetes)\n\n\n  0   1 \n267 265 \n\n\nFor the numerical variables:\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = Age)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nOdd: Some BloodPressure values are 0.\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = BloodPressure)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = GeneticRisk)) + \n  geom_boxplot()\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nOdd: Some BMI values are 0.\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = BMI)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\ndiabetes_clinical %&gt;% \n  ggplot(aes(y = PhysicalActivity)) + \n  geom_boxplot()",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#clean-up-the-data",
    "href": "solutions/solution1.html#clean-up-the-data",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "Clean up the data",
    "text": "Clean up the data\nNow that we have had a look at the data, it is time to correct fixable mistakes and remove observations that cannot be corrected.\nConsider the following:\n\nWhat should we do with the rows that contain NA’s? Do we remove them or keep them?\nWhich odd things in the data can we correct with confidence and which cannot?\nAre there zeros in the data? Are they true zeros or errors?\nDo you want to change any of the classes of the variables?\n\n\nClean the data according to your considerations.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nHave a look at BloodPressure, BMI, Sex, and Diabetes.\n\n\n\nMy considerations:\n\nWhen modelling, rows with NA’s in the variables we want to model should be removed as we cannot model on NAs. Since there are only NA’s in GeneticRisk, the rows can be left until we need to do a model with GeneticRisk.\nThe uppercase/lowercase mistakes in Sex does not influence the interpretability of the variables, so they are simply changes such that the first letter is a capital letter and the remaining letter are lowercase.\nThere are zeros in BMI and BloodPressure. These are considered false zeros as is does not make sense that these variables have a value of 0.\nDiabetes is changed to factor.\n\nAccess number of rows before cleaning.\n\nnrow(diabetes_clinical)\n\n[1] 532\n\n\nCleaning data according to considerations.\n\ndiabetes_clinical_clean &lt;- diabetes_clinical %&gt;% \n  mutate(Sex = str_to_title(Sex),\n         Diabetes = Diabetes %&gt;% factor()) %&gt;% \n  filter(BMI != 0, BloodPressure != 0) \n\nCheck the unique sexes now.\n\ndiabetes_clinical_clean$Sex %&gt;% unique()\n\n[1] \"Male\"   \"Female\"\n\n\nAccess number of rows after cleaning.\n\nnrow(diabetes_clinical_clean)\n\n[1] 493",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#meta-data",
    "href": "solutions/solution1.html#meta-data",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "Meta Data",
    "text": "Meta Data\nThere is some metadata to accompany the dataset you have just cleaned in diabetes_meta_toy_messy.csv. This is a csv file, not an excel sheet, so you need to use the read_delim function to load it. Load in the dataset and inspect it.\n6.2. Load the meta data set.\n\ndiabetes_meta &lt;- read_delim('../data/diabetes_meta_toy_messy.csv')\nhead(diabetes_meta)\n\n# A tibble: 6 × 3\n     ID Married Work         \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        \n1 33879 Yes     Self-employed\n2 52800 Yes     Private      \n3 16817 Yes     Private      \n4 70676 Yes     Self-employed\n5  6319 No      Public       \n6 71379 No      Public       \n\n\n6.3. How many missing values (NA’s) are there in each column.\n\ncolSums(is.na(diabetes_meta))\n\n     ID Married    Work \n      0       0       0 \n\n\n6.4. Check the distribution of each of the variables. Consider that the variables are of different classes. Do any of the distributions seam odd to you?\nFor the categorical variables:\n\ntable(diabetes_meta$Married)\n\n\n  No  No   Yes Yes  \n 183    3  345    1 \n\ntable(diabetes_meta$Work)\n\n\n      Private        Public       Retired Self-employed \n          283           154             6            89 \n\n\nBy investigating the unique values of the Married variable we see that some of the values have whitespace.\n\nunique(diabetes_meta$Married)\n\n[1] \"Yes\"  \"No\"   \"Yes \" \"No \" \n\n\n\n\nClean the data according to your considerations.\n\n\nMy considerations:\n\nThe Married variable has whitespace in the some of the values. The values “Yes” and “Yes” will be interpreted as different values. We can confidently remove all the whitespaces in this variable.\nID is changed to numerical to match the diabetes_clean dataset.\n\nAccess number of rows before cleaning.\n\nnrow(diabetes_meta)\n\n[1] 532\n\n\n\ndiabetes_meta_clean &lt;- diabetes_meta %&gt;% \n  mutate(Married = str_trim(Married),\n         ID = as.numeric(ID))\n\nCheck the unique marital status now.\n\nunique(diabetes_meta_clean$Married)\n\n[1] \"Yes\" \"No\" \n\n\nAccess number of rows after cleaning.\n\nnrow(diabetes_meta_clean)\n\n[1] 532",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution1.html#join-the-datasets",
    "href": "solutions/solution1.html#join-the-datasets",
    "title": "Exercise 1 - Solutions: Data Cleanup (Base R and Tidyverse)",
    "section": "Join the datasets",
    "text": "Join the datasets\n\nConsider what variable the datasets should be joined on.\n\nThe joining variable must be the same type in both datasets.\n\nJoin the datasets by the variable you selected above.\n\n\ndiabetes_join &lt;- diabetes_clinical_clean %&gt;% \n  left_join(diabetes_meta_clean, by = 'ID')\n\n\nHow many rows does the joined dataset have? Explain why.\n\nBecause we used left_join, only the IDs that are in diabetes_clinical_clean are kept.\n\nnrow(diabetes_join)\n\n[1] 493\n\n\n\nExport the joined dataset. Think about which directory you want to save the file in.\n\n\nwritexl::write_xlsx(diabetes_join, '../out/diabetes_join.xlsx')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 1 - Solution"
    ]
  },
  {
    "objectID": "presentations/presentation6.html",
    "href": "presentations/presentation6.html",
    "title": "Presentation 6: ???",
    "section": "",
    "text": "print('Hello World')\n\n[1] \"Hello World\""
  },
  {
    "objectID": "presentations/presentation4_main_script.html",
    "href": "presentations/presentation4_main_script.html",
    "title": "Presentation 4: Scripting in R",
    "section": "",
    "text": "In this section we will learn more about flow control and how to make more complex code constructs in R.\nlibrary(tidyverse)\n\nWarning: pakke 'ggplot2' blev bygget under R version 4.2.3\n\n\nWarning: pakke 'tibble' blev bygget under R version 4.2.3\n\n\nWarning: pakke 'dplyr' blev bygget under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#if-else-statments",
    "href": "presentations/presentation4_main_script.html#if-else-statments",
    "title": "Presentation 4: Scripting in R",
    "section": "If-else statments",
    "text": "If-else statments\nIf-else statements are essential if you want your program to do different things depending on a condition. Here we see how to code them in R.\nFirst define some variables.\n\nnum1 &lt;- 8\nnum2 &lt;- 5\n\nNow that we have variables, we can test logical statement between them: Is num1 larger than num2? The result of a logical statement is always one of either TRUE or FALSE:\n\nnum1 &gt; num2\n\n[1] TRUE\n\n\nIs num1 smaller than num2?\n\nnum1 &lt; num2\n\n[1] FALSE\n\n\nWe use logical statements inside an if statement to define a condition.\n\nif (num1 &gt; num2){\n  statement &lt;- paste(num1, 'is larger than', num2)\n}\n\nprint(statement)\n\n[1] \"8 is larger than 5\"\n\n\nWe can add an else if to test multiple conditions. else is what applies when all previous checks where FALSE.\nNow we have three possible outcomes:\n\n#try with different values for num2\nnum2 &lt;- 10\n\nif (num1 &gt; num2){\n  statement &lt;- paste(num1, 'is larger than', num2)\n} else if (num1 &lt; num2) {\n  statement &lt;- paste(num1, 'is smaller than', num2)\n} else {\n  statement &lt;- paste(num1, 'is equal to', num2)\n} \n\nprint(statement)\n\n[1] \"8 is smaller than 10\"",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#for-loops",
    "href": "presentations/presentation4_main_script.html#for-loops",
    "title": "Presentation 4: Scripting in R",
    "section": "For-loops",
    "text": "For-loops\n\nDefining a for loop\nMany functions in R are already vectorized, i.e. \n\ndf &lt;- tibble(num1 = 1:10)\ndf\n\n# A tibble: 10 × 1\n    num1\n   &lt;int&gt;\n 1     1\n 2     2\n 3     3\n 4     4\n 5     5\n 6     6\n 7     7\n 8     8\n 9     9\n10    10\n\ndf$num2 &lt;- df$num1 * 10\ndf\n\n# A tibble: 10 × 2\n    num1  num2\n   &lt;int&gt; &lt;dbl&gt;\n 1     1    10\n 2     2    20\n 3     3    30\n 4     4    40\n 5     5    50\n 6     6    60\n 7     7    70\n 8     8    80\n 9     9    90\n10    10   100\n\n\nThe above code applies * 10 to each element of column num1 without us having to invoke a loop.\nBut sometimes we want to iterate over the elements manually because the situation requires it. For that case we can use a for loop.\nWe first define a list containing both numeric and character elements.\n\nlist1 &lt;- list(1, 2, 6, 3, 2, 'hello', 'world', 'yes', 7, 8, 12, 15)\n\nTo loop through list1, we define a loop variable (here called element), which takes the value of each item in the vector, one at a time.\n\nfor (element in list1) {\n  print(element)\n}\n\n[1] 1\n[1] 2\n[1] 6\n[1] 3\n[1] 2\n[1] \"hello\"\n[1] \"world\"\n[1] \"yes\"\n[1] 7\n[1] 8\n[1] 12\n[1] 15\n\n\nThe loop variable name is arbitrary - you can call it anything. For example, we can use THIS_VARIABLE and get the same result. Point is, it does not matter what you call the variable, just avoid overwriting an important variable of your script.\n\nfor (THIS_VARIABLE in list1) {\n  print(THIS_VARIABLE)\n}\n\n[1] 1\n[1] 2\n[1] 6\n[1] 3\n[1] 2\n[1] \"hello\"\n[1] \"world\"\n[1] \"yes\"\n[1] 7\n[1] 8\n[1] 12\n[1] 15\n\n\nAfter you loop through a vector or a list, the value of the loop variable is always the last element of your vector. The variable is hence a global variable.\n\nTHIS_VARIABLE\n\n[1] 15\n\n\n\n\nLoop control\nThere are two loop control statements we can use to\n\njump to the next iteration: next\nend the loop before finishing: break\n\n\n#example for next\n\nfor (element in list1) {\n  if(element == 'hello'){\n    next\n  }\n  \n  print(element)\n}\n\n[1] 1\n[1] 2\n[1] 6\n[1] 3\n[1] 2\n[1] \"world\"\n[1] \"yes\"\n[1] 7\n[1] 8\n[1] 12\n[1] 15\n\n\n\n#example for break\nfor (element in list1) {\n  if(element == 'hello'){\n    break\n  }\n  \n  print(element)\n}\n\n[1] 1\n[1] 2\n[1] 6\n[1] 3\n[1] 2\n\n\n\n\nWhich data constructs are iterable in R?\nVectors:\n\nmy_vector &lt;- c(1, 2, 3, 4, 5)\nfor (elem in my_vector) {\n  print(elem)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nLists:\n\nmy_list &lt;- list(a = 1, b = \"Hello\", c = TRUE)\nfor (elem in my_list) {\n  print(elem)\n}\n\n[1] 1\n[1] \"Hello\"\n[1] TRUE\n\n\nDataframes and tibbles:\n\nmy_df &lt;- data.frame(A = 1:3, B = c(\"X\", \"Y\", \"Z\"))\nmy_df\n\n  A B\n1 1 X\n2 2 Y\n3 3 Z\n\n#column-wise\n\nfor (col in my_df) {\n  print(col)\n}\n\n[1] 1 2 3\n[1] \"X\" \"Y\" \"Z\"\n\n\nFor row-wise iteration you can for example use the row index:\n\nfor (i in 1:nrow(my_df)) {\n  print(i)\n  #print row i\n  print(my_df[i,])\n}\n\n[1] 1\n  A B\n1 1 X\n[1] 2\n  A B\n2 2 Y\n[1] 3\n  A B\n3 3 Z\n\n\n\n\nIf-else in loops\nWe can now use what we have learned to loop through our list1 and multiply all numeric values with 10:\n\n#to remember contents:\nlist1\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 3\n\n[[5]]\n[1] 2\n\n[[6]]\n[1] \"hello\"\n\n[[7]]\n[1] \"world\"\n\n[[8]]\n[1] \"yes\"\n\n[[9]]\n[1] 7\n\n[[10]]\n[1] 8\n\n[[11]]\n[1] 12\n\n[[12]]\n[1] 15\n\n\n\nfor (element in list1) {\n  if (is.numeric(element)){\n    statement &lt;- paste(element, 'times 10 is', element*10)\n  } else {\n    statement &lt;- paste(element, 'is not a number!')\n  }\n  print(statement)\n}\n\n[1] \"1 times 10 is 10\"\n[1] \"2 times 10 is 20\"\n[1] \"6 times 10 is 60\"\n[1] \"3 times 10 is 30\"\n[1] \"2 times 10 is 20\"\n[1] \"hello is not a number!\"\n[1] \"world is not a number!\"\n[1] \"yes is not a number!\"\n[1] \"7 times 10 is 70\"\n[1] \"8 times 10 is 80\"\n[1] \"12 times 10 is 120\"\n[1] \"15 times 10 is 150\"\n\n\nNote: that this does not work with a vector, i.e. vec &lt;- c(1,2,'hello') because vectors can only contain one data type so all elements of vec are characters.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#user-defined-functions",
    "href": "presentations/presentation4_main_script.html#user-defined-functions",
    "title": "Presentation 4: Scripting in R",
    "section": "User defined Functions",
    "text": "User defined Functions\nUser defined functions help us to re-use and structure our code.\nWe will use BMI calculation as an example for this part.\n\n#measurements of one individual\n\nweight_kg &lt;- 70\nheight_m &lt;- 1.80\n\nWe calculate BMI with this formula:\n\nbmi &lt;- weight_kg/height_m^2\nbmi\n\n[1] 21.60494\n\n\nIf we plan to calculate BMI for multiple individuals it is convenient to write the calculation into a function.\n\nFunction name: calculate_bmi.\nFunction parameters: weight_kg and height_m.\nThe return value: bmi.\n\nThe return statement specifies the value that the function will return when called.\n\ncalculate_bmi &lt;- function(weight_kg, height_m){\n  \n  bmi &lt;- weight_kg/height_m^2\n  \n  return(bmi)\n  \n}\n\nWe can now call the function on our previously defined variables.\n\ncalculate_bmi(weight_kg = weight_kg, \n              height_m = height_m)\n\n[1] 21.60494\n\n\nWe can also pass numbers directly to the function.\n\ncalculate_bmi(weight_kg = 100, \n              height_m = 1.90)\n\n[1] 27.70083\n\n\nArgument Order in Function Calls\nIf we specify the parameter names, the order can be changed.\n\ncalculate_bmi(height_m = 1.90, \n              weight_kg = 100)\n\n[1] 27.70083\n\n\nIf we do not specify the parameter names, the arguments will be matched according to the position - so be careful with this.\n\ncalculate_bmi(1.90, \n              100)\n\n[1] 0.00019",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#combining-function-call-with-if-statement",
    "href": "presentations/presentation4_main_script.html#combining-function-call-with-if-statement",
    "title": "Presentation 4: Scripting in R",
    "section": "Combining function call with if-statement",
    "text": "Combining function call with if-statement\nWe can combine user-defined functions with if-else statements, so that the if-else will decide whether we execute the function or not.\n\n#measurements of one individual\nage &lt;- 45\nweight_kg &lt;- 85\nheight_m &lt;- 1.75\n\nFpr some BMI should only be calculated for individuals over the age of 18.\n\nif (age &gt;= 18){\n  calculate_bmi(weight_kg, height_m)\n}\n\n[1] 27.7551",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#combining-function-call-with-for-loops",
    "href": "presentations/presentation4_main_script.html#combining-function-call-with-for-loops",
    "title": "Presentation 4: Scripting in R",
    "section": "Combining function call with for-loops",
    "text": "Combining function call with for-loops\nOr we can choose to execute our function once for every element of an iterable, e.g. every row in a dataframe:\n\ndf &lt;- data.frame(row.names = 1:5, \n                 age = c(45, 16, 31, 56, 19), \n                 weight_kg = c(85, 65, 100, 45, 76), \n                 height_m = c(1.75, 1.45, 1.95, 1.51, 1.89))\n\ndf\n\n  age weight_kg height_m\n1  45        85     1.75\n2  16        65     1.45\n3  31       100     1.95\n4  56        45     1.51\n5  19        76     1.89\n\n\nPrint ID, weight, and height of all individuals.\n\nfor (id in rownames(df)){\n  \n  weight &lt;- df[id, 'weight_kg']\n  \n  height &lt;- df[id, 'height_m']\n  \n  print(c(id, weight, height))\n  \n}\n\n[1] \"1\"    \"85\"   \"1.75\"\n[1] \"2\"    \"65\"   \"1.45\"\n[1] \"3\"    \"100\"  \"1.95\"\n[1] \"4\"    \"45\"   \"1.51\"\n[1] \"5\"    \"76\"   \"1.89\"\n\n\nCall function to calculate BMI for all individuals.\n\nfor (id in rownames(df)) {\n  \n  weight &lt;- df[id, 'weight_kg']\n  \n  height &lt;- df[id, 'height_m']\n  \n  bmi &lt;- calculate_bmi(weight, height)\n  \n  print(c(id, bmi))\n  \n}\n\n[1] \"1\"                \"27.7551020408163\"\n[1] \"2\"                \"30.9155766944114\"\n[1] \"3\"                \"26.2984878369494\"\n[1] \"4\"                \"19.7359764922591\"\n[1] \"5\"                \"21.2760001119789\"\n\n\n\nCombination of function call, if-statement and for-loops.\nPrint BMI for individuals that are 18 years old or older.\n\nfor (id in rownames(df)) {\n  \n  if (df[id, 'age'] &gt;= 18) {\n    \n    weight &lt;- df[id, 'weight_kg']\n  \n    height &lt;- df[id, 'height_m']\n    \n    bmi &lt;- calculate_bmi(weight, height)\n    \n    print(c(id, bmi))\n\n  } else {\n    \n    print(paste(id, 'is under 18.'))\n    \n  }\n  \n}\n\n[1] \"1\"                \"27.7551020408163\"\n[1] \"2 is under 18.\"\n[1] \"3\"                \"26.2984878369494\"\n[1] \"4\"                \"19.7359764922591\"\n[1] \"5\"                \"21.2760001119789\"\n\n\nAdd BMI to the data frame.\n\nfor (id in rownames(df)){\n  \n  if (df[id, 'age'] &gt;= 18) {\n    \n    weight &lt;- df[id, 'weight_kg']\n  \n    height &lt;- df[id, 'height_m']\n    \n    bmi &lt;- calculate_bmi(weight, height)\n\n  } else {\n    \n    bmi &lt;- NA\n    \n  }\n  \n  df[id, 'bmi'] &lt;- bmi\n  \n}\n\nHave a look at the data frame.\n\ndf\n\n  age weight_kg height_m      bmi\n1  45        85     1.75 27.75510\n2  16        65     1.45       NA\n3  31       100     1.95 26.29849\n4  56        45     1.51 19.73598\n5  19        76     1.89 21.27600",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#error-handling-in-user-defined-functions",
    "href": "presentations/presentation4_main_script.html#error-handling-in-user-defined-functions",
    "title": "Presentation 4: Scripting in R",
    "section": "Error handling in user-defined functions",
    "text": "Error handling in user-defined functions\nCurrently our BMI function accepts all kinds of inputs. However, what happens if we give a negative weight?\n\ncalculate_bmi(weight_kg = -50, height_m = 1.80)\n\n[1] -15.4321\n\n\nWe should require that both weight and height need to be positive values:\n\ncalculate_bmi_2 &lt;- function(weight_kg, height_m) {\n  \n  # Check if weight and height are numeric\n  if (!is.numeric(weight_kg) | !is.numeric(height_m)) {\n    stop(\"Both weight_kg and height_m must be numeric values.\")\n  }\n  \n  # Check if weight and height are positive\n  if (weight_kg &lt;= 0) {\n    stop(\"Weight must be a positive value.\")\n  }\n  if (height_m &lt;= 0) {\n    stop(\"Height must be a positive value.\")\n  }\n  \n  # Calculate BMI\n  bmi &lt;- weight_kg / height_m^2\n  \n  # Check if BMI is within a reasonable range\n  if (bmi &lt; 10 | bmi &gt; 60) {\n    warning(\"The calculated BMI is outside the normal range. Please check your input values.\")\n  }\n  \n  return(bmi)\n  \n}\n\nWhen we try to run calculate_bmi_2 with a negative weight we now receive an error:\n\ncalculate_bmi_2(weight_kg = -50, height_m = 1.80)\n\nWe also added a check whether the calculated BMI is within the normal range:\n\ncalculate_bmi_2(weight_kg = 25, height_m = 1.80)\n\nWarning in calculate_bmi_2(weight_kg = 25, height_m = 1.8): The calculated BMI\nis outside the normal range. Please check your input values.\n\n\n[1] 7.716049\n\n\nRunning calculate_bmi_2 with appropriate inputs:\n\ncalculate_bmi_2(weight_kg = 75, height_m = 1.80)\n\n[1] 23.14815",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation4_main_script.html#out-sourcing-functions-to-an-rscript-you-source",
    "href": "presentations/presentation4_main_script.html#out-sourcing-functions-to-an-rscript-you-source",
    "title": "Presentation 4: Scripting in R",
    "section": "Out-sourcing functions to an Rscript you source",
    "text": "Out-sourcing functions to an Rscript you source\nIt is cleaner to collect all your functions in one place, and perhaps that place should not be your analysis script. You can instead save your functions in a separate R script and source it inside your analysis script to have access to all your functions without them cluttering your workflow.\nWe have create a file named presentation4_functions.R and copied our two function definitions for calculate_bmi and calculate_bmi_2 into it.\nNow we remove our function definitions from the global environment to demonstrate how to source them from an external file.\n\nrm(list = \"calculate_bmi\", \"calculate_bmi_2\")\n\nBy sourcing a script, all global variables (including functions) in that script will be loaded and appear in the Global environment in the top left corner. Here we source the functions.R script. Check the environment to confirm that the two functions appeared.\n\nsource('./presentation4_functions.R')\n\nAfter we sourced the functions script the calculate_bmi function can be used just like if it was defined in the main script. If you work on a larger project and write multiple functions, it is best practice to have a function script and source it in your main script.\n\ncalculate_bmi_2(weight_kg = 67, \n              height_m = 1.70)\n\n[1] 23.18339\n\n\nYou can also use mapply as an alternative to calling the function in a for-loop:\n\nmapply(FUN = calculate_bmi_2, \n       weight_kg = df$weight_kg, \n       height_m = df$height_m)\n\n[1] 27.75510 30.91558 26.29849 19.73598 21.27600",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation3.html",
    "href": "presentations/presentation3.html",
    "title": "Presentation 3 - Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "In this section we will learn some extra ggplot tricks!",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "presentations/presentation3.html#load-packages",
    "href": "presentations/presentation3.html#load-packages",
    "title": "Presentation 3 - Exploratory Data Analysis (EDA)",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(readxl)\nlibrary(tidyverse)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "presentations/presentation3.html#load-data",
    "href": "presentations/presentation3.html#load-data",
    "title": "Presentation 3 - Exploratory Data Analysis (EDA)",
    "section": "Load data",
    "text": "Load data\n\ndf_sales &lt;- read_excel('../out/sales_data_2.xlsx')\ndf_sales\n\n# A tibble: 10 × 12\n      ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n 1     1 Alice      25 Female        100        110        120        100 happy\n 2     2 Bob        30 Male          200        210        220        230 happy\n 3     3 Charlie    22 Male          150        160        170        200 happy\n 4     4 Sophie     35 Female        300        320        340        250 happy\n 5     5 Eve        28 Female        250        240        250        270 happy\n 6     6 Frank      NA Male           NA        260        270        280 happy\n 7     7 Grace      40 Female        400        420        430        450 happy\n 8     8 Hannah     29 Female        500        510         NA        500 happy\n 9     9 Ian        21 Male          450        460        470        480 happy\n10    10 Jack       33 Male          300        310        320        290 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "presentations/presentation3.html#ggplot-recap",
    "href": "presentations/presentation3.html#ggplot-recap",
    "title": "Presentation 3 - Exploratory Data Analysis (EDA)",
    "section": "ggplot recap",
    "text": "ggplot recap\nWe will not go into much detail here since this section mostly serves as a recap of the ggplot material covered in the previous course, From Excel to R.\nThe creed of ggplot is summarized is that every information that should be put into the plot must be in a column. There is one column that describes the x-axis and one for the y-axis, and one for each additional aesthetic like color, size, shape, ect.\n\nggplot(df_sales, aes(x = Name, y = sales_2022, color = Sex)) +\n  geom_point()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nThe long format is ggplot’s best friend\nIt follows that if I need to plot all sales data, I will need to change the dataframe’s format such that all data points referring to sales are in the same column. As shown in pres 2 we do that with pivot_longer:\n\nsales_long &lt;- df_sales %&gt;%\n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"sales_year\",\n               values_to = \"sales_value\")\nsales_long\n\n# A tibble: 40 × 10\n      ID Name      Age Sex    mood  raise group     City  sales_year sales_value\n   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1     1 Alice      25 Female happy no    young_fe… Miami sales_2020         100\n 2     1 Alice      25 Female happy no    young_fe… Miami sales_2021         110\n 3     1 Alice      25 Female happy no    young_fe… Miami sales_2022         120\n 4     1 Alice      25 Female happy no    young_fe… Miami sales_2023         100\n 5     2 Bob        30 Male   happy yes   mature_m… Miami sales_2020         200\n 6     2 Bob        30 Male   happy yes   mature_m… Miami sales_2021         210\n 7     2 Bob        30 Male   happy yes   mature_m… Miami sales_2022         220\n 8     2 Bob        30 Male   happy yes   mature_m… Miami sales_2023         230\n 9     3 Charlie    22 Male   happy yes   young_ma… LA    sales_2020         150\n10     3 Charlie    22 Male   happy yes   young_ma… LA    sales_2021         160\n# ℹ 30 more rows\n\n\n\nggplot(sales_long, aes(x = Name, y = sales_value, color = Sex)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nYou can pipe into ggplot\nYou know what sucks? Having 10 million dataframes with very similar names in your environment. If you you don’t need to use your long format dataframe for anything else, instead of saving it and then plugging it into ggplot, you can pipe directly into ggplot:\n\ndf_sales %&gt;%\n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"sales_year\",\n               values_to = \"sales_value\") %&gt;%\n  #we omit the dataframe to plot because that is being piped into ggplot\n  #remember that different plot layers are still combined with '+'\n  ggplot(aes(x = Name, y = sales_value, color = Sex)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nPlotting several dataframes\nSometimes we would like to add more information to a plot. Consider the one we just made above. It shows 3 or 4 dots for each amployee, which the 3 or 4 different years we have information for. I can now calculate a mean across the 4 years per employee:\n\nsales_mean &lt;- sales_long %&gt;%\n  group_by(Name) %&gt;%\n  summarise(mean = mean(sales_value, na.rm = T))\n\nsales_mean\n\n# A tibble: 10 × 2\n   Name     mean\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 Alice    108.\n 2 Bob      215 \n 3 Charlie  170 \n 4 Eve      252.\n 5 Frank    270 \n 6 Grace    425 \n 7 Hannah   503.\n 8 Ian      465 \n 9 Jack     305 \n10 Sophie   302.\n\n\nAnd I would like to add it to the plot:\n\n#copy pasta code above\ndf_sales %&gt;%\n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"sales_year\",\n               values_to = \"sales_value\") %&gt;%\n  #we omit the dataframe to plot because that is being piped into ggplot\n  #remember that different plot layers are still combined with '+'\n  ggplot(aes(x = Name, y = sales_value, color = Sex)) +\n  geom_point() +\n  #add mean data by switching the dataframe!\n  #I need to specify a color aesthetic because there is no Sex column in sales_mean\n  geom_point(data = sales_mean, aes(x = Name, y = mean), color = 'black')\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nPlots are objects\nggplot plots are objects like any other R object and they can therefore be stored in a variable and displayed by invoking the variable’s name:\n\nawesome_plot &lt;- df_sales %&gt;%\n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"sales_year\",\n               values_to = \"sales_value\") %&gt;%\n  #we omit the dataframe to plot because that is being piped into ggplot\n  #remember that different plot layers are still combined with '+'\n  ggplot(aes(x = Name, y = sales_value, color = Sex)) +\n  geom_point() +\n  #add mean data by switching the dataframe!\n  #I need to specify a color aesthetic because there is no Sex column in sales_mean\n  geom_point(data = sales_mean, aes(x = Name, y = mean), color = 'black')\n\nawesome_plot\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIf R is every being pesky about showing you plots (e.g. if you want to display them in a loop) wrapping print() around the plot name usually helps:\n\nprint(awesome_plot)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nAliasing column names\nLastly, we’re going to show you how to alias a column name. Have you noticed that we always need to specify the literal name of the column we want to plot? What if we want to give the column name in a variable?\n\nplot_this &lt;- 'Name'\n\nggplot(df_sales, aes(x = plot_this, y = sales_2022, color = Sex)) +\n  geom_point()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nCertainly not the expected outcome! We can see that ggplot didn’t evaluate plot_this to the name of the actual column, Name. We’ll have to do it this way:\n\nplot_this &lt;- 'Name'\n\nggplot(df_sales, aes(x = .data[[plot_this]], y = sales_2022, color = Sex)) +\n  geom_point()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWe hear you say ‘But that is cumbersome!’. Unfortunately we’re neither the developers nor maintainers of ggplot so we all suffer together.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "presentations/presentation3.html#eda",
    "href": "presentations/presentation3.html#eda",
    "title": "Presentation 3 - Exploratory Data Analysis (EDA)",
    "section": "EDA",
    "text": "EDA\nInstead of having a long theoretical lecture we think you should just have a look at the data so let’s go straight to the exercise.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "presentations/presentation1.html",
    "href": "presentations/presentation1.html",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "",
    "text": "In this section we will look at some differences between base R and tidyverse and also learn how to prepare a clean dataset.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#load-packages",
    "href": "presentations/presentation1.html#load-packages",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Load Packages",
    "text": "Load Packages\n\nlibrary(tidyverse)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#load-dataset",
    "href": "presentations/presentation1.html#load-dataset",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Load Dataset",
    "text": "Load Dataset\nHere we load a dataframe that contains sales data for employees (in thousands DKK) from 2020 to 2023. We load the data as df_baseR which we will use to demonstrate base R commands. A copy of the same dataframe, df_tidyverse, is used to demonstrate tidyverse commands.\n\ndf_baseR &lt;- readxl::read_excel('../data/df_sales_1.xlsx') %&gt;% as.data.frame()\ndf_tidyverse &lt;- readxl::read_excel('../data/df_sales_1.xlsx') %&gt;% as_tibble()\n\nTable format in baseR is called data.frame. Have a look at the object in the terminal. It is very simple.\n\nclass(df_baseR)\n\n[1] \"data.frame\"\n\n\nTable format in tidyverse is called tibble. Have a look at the object in the terminal. The dimensions of the tibble is provided together with the classes of each column.\n\nclass(df_tidyverse)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#base-r-and-tidyverse",
    "href": "presentations/presentation1.html#base-r-and-tidyverse",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Base R and Tidyverse",
    "text": "Base R and Tidyverse\nMany operations in R can be done in several ways. We illustrate here the base R and tidyverse ways to achieve common operations.\nAccess the Age column:\n\n# Base R \ndf_baseR['Age']\n\n# Tidyverse \ndf_tidyverse %&gt;% select(Age)\n\nAccess the Age column as a vector:\n\n# Base R \ndf_baseR[['Age']]\ndf_tidyverse$Age\n\n# Tidyverse \ndf_tidyverse %&gt;% pull(Age)\n\nAdd a column containing the difference in sales in 2022 and 2022.\n\n# Base R \ndf_baseR$sales_diff &lt;- df_baseR$sales_2022 - df_baseR$sales_2020\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  mutate(sales_diff = sales_2022 - sales_2020)\n\nRemove the sales_diff column.\n\n# Base R \ndf_baseR$sales_diff &lt;- NULL\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  select(-sales_diff)\n\nSelect columns with sales numbers.\n\n# Base R \ndf_baseR[, startsWith(colnames(df_baseR), 'sales_')]\n\n# Tidyverse \ndf_tidyverse %&gt;% \n  select(starts_with('sales_'))\n\nFilter rows for people older than 25.\n\n# Base R \ndf_baseR[df_baseR$Age &gt; 25 ,]\n\n# Tidyverse \ndf_tidyverse %&gt;% \n  filter(Age &gt; 25)\n\nFilter row for people that are 30 years old or younger and have sales in 2022 over 200.\n\n# Base R \ndf_baseR[!is.na(df_baseR$Age) & !is.na(df_baseR$sales_2022) &\n         df_baseR$Age &lt;= 30 & df_baseR$sales_2022 &gt; 200 ,]\n\n# Tidyverse \ndf_tidyverse %&gt;% \n  filter(Age &lt;= 30, sales_2022 &gt; 200)\n\nAdd column.\n\n# Base R \ndf_baseR$mood &lt;- \"happy\"\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  mutate(mood = \"happy\")\n\nConditions using ifelse.\n\n# Base R \ndf_baseR$raise &lt;- ifelse(df_baseR$sales_2023 &gt; df_baseR$sales_2022, \"yes\", \"no\")\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  mutate(raise = ifelse(sales_2023 &gt; sales_2022, \"yes\", \"no\"))\n\nConditions using case_when.\n\n# Base R \ndf_baseR$group &lt;- ifelse(df_baseR$Age &lt; 30 & df_baseR$Sex == \"Female\", \"young_female\",\n                  ifelse(df_baseR$Age &lt; 30 & df_baseR$Sex == \"Male\", \"young_male\",\n                  ifelse(df_baseR$Age &gt;= 30 & df_baseR$Sex == \"Female\", \"mature_female\",\n                  ifelse(df_baseR$Age &gt;= 30 & df_baseR$Sex == \"Male\", \"mature_male\", NA))))\n\n# Tidyverse \ndf_tidyverse &lt;- df_tidyverse %&gt;% \n  mutate(group = case_when(Age &lt; 30 & Sex == \"Female\" ~ \"young_female\",\n                           Age &lt; 30 & Sex == \"Male\" ~ \"young_male\",\n                           Age &gt;= 30 & Sex == \"Female\" ~ \"mature_female\",\n                           Age &gt;= 30 & Sex == \"Male\" ~ \"mature_male\", \n                           .default = NA))\n\nCheck which columns have NAs.\n\n# Base R\ncolSums(is.na(df_baseR))\n\n# Tidyverse\ndf_tidyverse %&gt;% summarise(across(everything(), ~ sum(is.na(.))))\n\nRemove rows with any NAs.\n\n# Base R\ndf_baseR_no_na &lt;- df_baseR[complete.cases(df_baseR), ]\n\n# Tidyverse\ndf_tidyverse_no_na &lt;- df_tidyverse %&gt;% drop_na()\n\nSort data based on sales in 2022 in descending order.\n\n# Base R \ndf_baseR[order(-df_baseR$sales_2022) ,]\n\n# Tidyverse \ndf_tidyverse %&gt;% arrange(desc(sales_2022))\n\nDo the filtering in 4. and select the Name and Sex column. This far, do you prefer the base R or tidyverse way? Do you see pros and cons with both?\n\n# Base R, NAs not removed\ndf_baseR[!is.na(df_baseR$Age) & !is.na(df_baseR$sales_2022) &\n         df_baseR$Age &lt;= 30 & df_baseR$sales_2022 &gt; 200 , c('Age', 'Sex')]\n\n# Base R, NAs removed\ndf_baseR_no_na[df_baseR_no_na$Age &lt;= 30 & df_baseR_no_na$sales_2022 &gt; 200 , c('Age', 'Sex')]\n\n# Tidyverse \ndf_tidyverse %&gt;% \n  filter(Age &lt;= 30, sales_2022 &gt; 200) %&gt;% \n  select(Age, Sex)\n\nThe df_location data frame contains information about the cities of the sales people.\n\nset.seed(101)\n\ndf_location &lt;- data.frame(\n  ID = sample(10),\n  City = c(\"New York\", \"LA\", \"New York\", \"Chicago\", \"Miami\", \"Miami\", \"LA\", \"Chicago\", \"LA\", \"New York\")\n)\n\nhead(df_location)\n\nJoin df and df_location. For base R we use merge and for tidyverse we use left_join.\n\n# Base R \ndf_baseR_merged &lt;- merge(df_baseR, df_location, by = 'ID')\nhead(df_baseR_merged)\n\n# Tidyverse \ndf_tidyverse_join &lt;- df_tidyverse %&gt;% left_join(df_location, by = 'ID')\nhead(df_tidyverse_join)\n\nCount the number of people in each of the unique cities.\n\n# Base R\ntable(df_baseR_merged$City)\n\n# Tidyverse\ndf_tidyverse_join %&gt;% count(City)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#string-manipulation",
    "href": "presentations/presentation1.html#string-manipulation",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "String manipulation",
    "text": "String manipulation\nWe will do string manipulation the tidyverse way.\nThe paste function concatenates two strings to one.\n\npaste('Alice', 'Hansen')\n\n[1] \"Alice Hansen\"\n\n\nThe sep argument is a space by default, but can be changed to any character.\n\npaste('Alice', 'Hansen', sep = \"_\")\n\n[1] \"Alice_Hansen\"\n\n\nThe paste0 function concatenates two strings to one without adding any separator between them.\n\npaste0('Alice', 'Hansen')\n\n[1] \"AliceHansen\"\n\n\nLet’s give all the employees the last name Hansen.\n\ndf_tidyverse_join &lt;- df_tidyverse_join %&gt;% \n  mutate(Name = paste(Name, 'Hansen'))\n\nhead(df_tidyverse_join)\n\n# A tibble: 6 × 12\n     ID Name         Age Sex   sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice Han…    25 Fema…        100        110        120        100 happy\n2     2 Bob Hansen    30 Male         200        210        220        230 happy\n3     3 Charlie H…    22 Male         150        160        170        200 happy\n4     4 Sophie Ha…    35 Fema…        300        320        340        250 happy\n5     5 Eve Hansen    28 Fema…        250        240        250        270 happy\n6     6 Frank Han…    NA Male          NA        260        270        280 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\nWe use the str_split function to split a string into multiple parts in a list.\n\nstr_split('Alice Hansen', pattern = ' ')\n\n[[1]]\n[1] \"Alice\"  \"Hansen\"\n\n\n\nstr_split('Alice_Hansen_Jensen', pattern = '_')\n\n[[1]]\n[1] \"Alice\"  \"Hansen\" \"Jensen\"\n\n\nIndexing one of the strings in the list using the str_split_i function.\n\nstr_split_i('Alice_Hansen_Jensen', pattern = '_', i = 2)\n\n[1] \"Hansen\"\n\n\nLet’s remove the last name we just gave the employees.\n\ndf_tidyverse_join &lt;- df_tidyverse_join %&gt;% \n  mutate(Name = str_split_i(Name, pattern = ' ', i = 1))\n\nhead(df_tidyverse_join)\n\n# A tibble: 6 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female        100        110        120        100 happy\n2     2 Bob        30 Male          200        210        220        230 happy\n3     3 Charlie    22 Male          150        160        170        200 happy\n4     4 Sophie     35 Female        300        320        340        250 happy\n5     5 Eve        28 Female        250        240        250        270 happy\n6     6 Frank      NA Male           NA        260        270        280 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\nDetect substring in main string using str_detect.\n\nstr_detect('Alice', 'A')\n\n[1] TRUE\n\n\n\nstr_detect('Alice', 'B')\n\n[1] FALSE\n\n\nAdd column that check if “A” or “a” in Name and place it after the Name column.\n\ndf_tidyverse_join %&gt;% \n  mutate(A_in_name = str_detect(Name, 'A|a'),\n         .after = Name) %&gt;% \n  head()\n\n# A tibble: 6 × 13\n     ID Name   A_in_name   Age Sex   sales_2020 sales_2021 sales_2022 sales_2023\n  &lt;dbl&gt; &lt;chr&gt;  &lt;lgl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1     1 Alice  TRUE         25 Fema…        100        110        120        100\n2     2 Bob    FALSE        30 Male         200        210        220        230\n3     3 Charl… TRUE         22 Male         150        160        170        200\n4     4 Sophie FALSE        35 Fema…        300        320        340        250\n5     5 Eve    FALSE        28 Fema…        250        240        250        270\n6     6 Frank  TRUE         NA Male          NA        260        270        280\n# ℹ 4 more variables: mood &lt;chr&gt;, raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#whitespace",
    "href": "presentations/presentation1.html#whitespace",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Whitespace",
    "text": "Whitespace\nWhitespace includes spaces, newlines, and other blank characters in text. It can cause errors or inconsistencies in data, so removing unnecessary whitespace is an important step in cleaning data.\nLet’s have a look at a version of the sales data frame with whitespaces. In the tibble format it cannot be spotted.\n\ndf_sales_messy &lt;- read_delim('../data/df_sales_messy.csv')\nhead(df_sales_messy)\n\n# A tibble: 6 × 8\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1     1 Alice      25 Female        100        110        120        100\n2     2 Bob        30 Male          200        210        220        230\n3     3 Charlie    22 Male          150        160        170        200\n4     4 Sophie     35 Female        300        320        340        250\n5     5 Eve        28 Female        250        240        250        270\n6     6 Frank      NA Male           NA        260        270        280\n\n\nAccessing the unique sexes of the Sex column before cleaning.\n\ndf_sales_messy$Sex %&gt;% unique()\n\n[1] \"Female\"  \"Male\"    \"Female \" \"Male \"  \n\n\nUse the str_trim function to remove whitespace.\n\ndf_sales_messy$Sex %&gt;% str_trim() %&gt;% unique()\n\n[1] \"Female\" \"Male\"  \n\n\nLike other function, the str_trim function can also be used inside the mutate function to alter the data frame.\n\ndf_sales_clean &lt;- df_sales_messy %&gt;% \n  mutate(Sex = str_trim(Sex))\n\nAccessing the unique sexes of the Sex column after cleaning.\n\ndf_sales_clean$Sex %&gt;% unique()\n\n[1] \"Female\" \"Male\"",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "presentations/presentation1.html#export-dataset",
    "href": "presentations/presentation1.html#export-dataset",
    "title": "Presentation 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Export Dataset",
    "text": "Export Dataset\nExport tidyverse dataset\n\nwritexl::write_xlsx(df_tidyverse_join, '../out/sales_data_2.xlsx')",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise5.html",
    "href": "exercises/exercise5.html",
    "title": "Exercise 5 - Modelling",
    "section": "",
    "text": "In this exercise you will fit and interpret a linear regression model.\n\n\n\nLoad packages\nLoad the data boston.csv\n\nThis dataset describes conditions surrounding the Boston housing market in the 1970s. Each row describes a zone in the Boston area (so there is more than one house in each row).\nThe columns are:\ncrim - per capita crime rate\nindus - proportion of non-retail businesses\nnox - Nitrogen oxides concentration (air pollution)\nrm - average number of rooms\nneighborhood - the type of neighborhood the zone is in\nmedv - median value per house in 1000s\n\n\n\n\nDoes the datatype of each column fit to it what it describes? Do you need to change any data types?\n\n\n\n\n\nSplit the dataset into test and training data.\nFit a model of how well the number of rooms (rm), crime rate (crim) and neighborhood type (neighborhood) predict the value of the houses (medv).\nDescribe what information you get from the model summary.\nScale the numeric predictor columns and redo the modelling. What has changed?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThere is a scale function, see ?scale().",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 5: Linear Regression"
    ]
  },
  {
    "objectID": "exercises/exercise5.html#introduction",
    "href": "exercises/exercise5.html#introduction",
    "title": "Exercise 5 - Modelling",
    "section": "",
    "text": "In this exercise you will fit and interpret a linear regression model.\n\n\n\nLoad packages\nLoad the data boston.csv\n\nThis dataset describes conditions surrounding the Boston housing market in the 1970s. Each row describes a zone in the Boston area (so there is more than one house in each row).\nThe columns are:\ncrim - per capita crime rate\nindus - proportion of non-retail businesses\nnox - Nitrogen oxides concentration (air pollution)\nrm - average number of rooms\nneighborhood - the type of neighborhood the zone is in\nmedv - median value per house in 1000s\n\n\n\n\nDoes the datatype of each column fit to it what it describes? Do you need to change any data types?\n\n\n\n\n\nSplit the dataset into test and training data.\nFit a model of how well the number of rooms (rm), crime rate (crim) and neighborhood type (neighborhood) predict the value of the houses (medv).\nDescribe what information you get from the model summary.\nScale the numeric predictor columns and redo the modelling. What has changed?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThere is a scale function, see ?scale().",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 5: Linear Regression"
    ]
  },
  {
    "objectID": "exercises/exercise3.html",
    "href": "exercises/exercise3.html",
    "title": "Exercise 3: Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "In this exercise you will do a lot of plotting with ggplot. For a reminder on how ggplot works you can have a look the ggplot material covered in our previous course, From Excel to R.\nThe second part of the exercise deals with creating a principal component analysis (PCA) plot. For a quick introduction to the main idea behind PCA you can have a look at this video.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "exercises/exercise3.html#getting-started",
    "href": "exercises/exercise3.html#getting-started",
    "title": "Exercise 3: Exploratory Data Analysis (EDA)",
    "section": "Getting started",
    "text": "Getting started\n\nLoad packages.\n\n\nlibrary(tidyverse)\n\n\nLoad data from the .rds file you created in Exercise 2. Have a guess at what the function is called.\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "exercises/exercise3.html#plotting---part-1",
    "href": "exercises/exercise3.html#plotting---part-1",
    "title": "Exercise 3: Exploratory Data Analysis (EDA)",
    "section": "Plotting - Part 1",
    "text": "Plotting - Part 1\nYou will first do some basic plots to get started with ggplot again.\nIf it has been a while since you worked with ggplot, have a look at the ggplot material from the FromExceltoR course.\n\nCreate a scatter plot of Age and Blood Pressure. Do you notice a trend?\nCreate a scatter plot of PhysicalActivity and BMI. Do you notice a trend?\nNow, create the same two plots as before, but this time stratify them by Diabetes. Do you notice any trends?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can stratify a plot by a categorical variable in several ways, depending on the type of plot. The purpose of stratification is to distinguish samples based on their categorical values, making patterns or differences easier to identify. This can be done using aesthetics like color, fill, shape.\n\n\n\n\nCreate a boxplot of BMI stratified by Diabetes. Give the plot a meaningful title.\nCreate a boxplot of PhysicalActivity stratified by Smoker. Give the plot a meaningful title.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "exercises/exercise3.html#plotting---part-2",
    "href": "exercises/exercise3.html#plotting---part-2",
    "title": "Exercise 3: Exploratory Data Analysis (EDA)",
    "section": "Plotting - Part 2",
    "text": "Plotting - Part 2\nIn order to plot the data inside the nested variable, the data needs to be unnested.\n\nCreate a boxplot of the glucose measurements at time 0 stratified by Diabetes. Give the plot a meaningful title.\nCreate these boxplots for each time point (0, 60, 120) by using faceting by Measurement. Give the plot a meaningful title.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFaceting allows you to create multiple plots based on the values of a categorical variable, making it easier to compare patterns across groups. In ggplot2, you can use facet_wrap for a single variable or facet_grid for multiple variables.\n\n\n\n\nCalculate the mean glucose levels for each time point.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use unnest(), group_by(), and summerise().\n\n\n\n\nMake the same calculation as above, but additionally group the results by Diabetes. Save the data frame in a variable. Compare your results to the boxplots you made above.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nGroup by several variables: group_by(var1, var2).\n\n\n\n\nCreate a plot that visualizes glucose measurements across time points, with one line for each patient ID. Then color the lines by their diabetes status. In summary, each patient’s glucose measurements should be connected with a line, grouped by their ID, and color-coded by Diabetes. Give the plot a meaningful title.\n\nIf your time points are strangely ordered have a look at the levels of your Measurement variable (the one that specifies which time point the measurement was taken at) and if necessary fix their order.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "exercises/exercise3.html#plotting---part-3-pca",
    "href": "exercises/exercise3.html#plotting---part-3-pca",
    "title": "Exercise 3: Exploratory Data Analysis (EDA)",
    "section": "Plotting - Part 3: PCA",
    "text": "Plotting - Part 3: PCA\nFor this part we will use this tutorial to make a principal component analysis (PCA). First, we perform some preprocessing to get our data into the right format.\n\nLet’s start by unnesting the OGTT data and using pivot wider so that each Glucose measurement time point gets its own column (again).\nHave a look at your unnested diabetes data set. Can you use all the variables to perform PCA? Subset the dataset to only include the relevant variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nPCA can only be performed on numerical values. Extract these (except ID!) from the dataset. Numerical columns can easily be selected with the where(is.numeric) helper.\n\n\n\n\nPCA cannot handle NA’s in the dataset. Remove all rows with NA in any column in your numerical subset. Then, go back to the original unnested data diabetes_glucose_unnest (or what you have called it) and also here drop rows that have NAs in the numerical columns (so the same rows you dropped from the numeric subset).This is important because we want to use (categorical) columns present in the original data to later color the resulting PCA, so the two dataframes (original and only numeric columns) need to be aligned and contain the same rows.\n\nNow our data is ready to make a PCA.\n\nCalculate the PCA by running prcomp on our prepared data (see the tutorial). Then, create a plot of the resulting PCA (also shown in tutorial).\nColor your PCA plot and add loadings. Think about which variable you want to color by. Remember to refer to the dataset that has this variable (probably not your numeric subset!)\nAdd a ggplot theme and title to your plot and save it.\nCalculate the variance explained by each of the PC’s using the following formula:\n\n\\[\n\\text{Variance Explained} = \\frac{\\text{sdev}^2}{\\sum \\text{sdev}^2} \\times 100\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can access the standard deviation from the PCA object like this: pca_res$sdev.\n\n\n\n\nCreate a two column data-frame with the names of the PC’s (PC1, PC2, ect) in one column and the variance explained by that PC in the other column.\nNow create a bar plot (using geom_col), showing for each PC the amount of explained variance. This type of plot is called a scree plot.\nLastly, render you quarto document and review the resulting html file.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "exercises/exercise3.html#extra-exercises",
    "href": "exercises/exercise3.html#extra-exercises",
    "title": "Exercise 3: Exploratory Data Analysis (EDA)",
    "section": "Extra exercises",
    "text": "Extra exercises\nThis exercise might be a bit more challenging. It requires multiple operations and might involve some techniques that were not explicitly shown in the presentations.\ne1. Recreate the plot you made in Exercise 12 and include the mean value for each glucose measurement for the two diabetes statuses (0 and 1) you calculated in Exercise 11. This plot should look like this:\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThere are several ways to solve this task. Here is a workflow suggestion:\n\nYou want to show both the raw data and the means in the same plot. Data from another dataset can be added to a plot by pointing the geom to a specific dataset like so: + geom_point(data = different_data, aes(x = VAR1, y = VAR2, group = VAR3))\ngeom_line needs a variable to group by in order to know which dots should be connected. In exercise 10, this grouping variable was the patient ID. Which variable in glucose_mean tells which points are connected? Pass it as group aesthetic.\ngeom_line has a linetype aestethic to define the kind of line (dashed or solid).",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 3: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "exercises/exercise1.html",
    "href": "exercises/exercise1.html",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "",
    "text": "In this exercise you will practice your R skills by loading, inspecting and cleaning a dataset. You can use base R and/or tidyverse to solve the exercises, it is up to you.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#getting-started",
    "href": "exercises/exercise1.html#getting-started",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Getting started",
    "text": "Getting started\n\nLoad the packages you think you will need. There is no need to spend too much time on this part. If you later realize you need another package just add it here and re-run the chunk.\n\n\n#your packages here\n\n\nLoad in the data set diabetes_clinical_toy_messy.xlsx.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#explore-the-data",
    "href": "exercises/exercise1.html#explore-the-data",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Explore the data",
    "text": "Explore the data\n\nHow many missing values (NA’s) are there in each column?\nCheck the distribution of each of the variables. Consider that they are of different data types. Do any of the distributions seem odd to you?",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#clean-up-the-data",
    "href": "exercises/exercise1.html#clean-up-the-data",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Clean up the data",
    "text": "Clean up the data\nNow that we have had a look at the data, it is time to correct fixable mistakes and remove observations that cannot be corrected.\nConsider the following:\n\nWhat should we do with the rows that contain NAs? Do we remove them or keep them?\nWhich mistakes in the data can be corrected, and which cannot?\nAre there zeros in the data? Are they true zeros or errors?\nDo you want to change any of the data types of the variables?\n\n\nClean the data according to your considerations.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nHave a look at BloodPressure, BMI, Sex, and Diabetes.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#meta-data",
    "href": "exercises/exercise1.html#meta-data",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Meta Data",
    "text": "Meta Data\nThere is some metadata to accompany the dataset you have just cleaned in diabetes_meta_toy_messy.csv. This is a csv file, not an excel sheet, so you need to use the read_delim function to load it. Load in the dataset and inspect it.\n\nNow clean the metadata and do data exploration by repeating step 3-5 from above.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "exercises/exercise1.html#join-the-datasets",
    "href": "exercises/exercise1.html#join-the-datasets",
    "title": "Exercise 1: Data Cleanup (Base R and Tidyverse)",
    "section": "Join the datasets",
    "text": "Join the datasets\nWe will combine both datasets together into one tibble.\n\nConsider what variable the datasets should be joined on.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe joining variable must be the same type in both datasets.\n\n\n\n\nJoin the datasets by the variable you selected above.\nHow many rows does the joined dataset have? Explain why.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBecause we used left_join, only the IDs that are in diabetes_clinical_clean are kept.\n\n\n\n\nExport the joined dataset. Think about which directory you want to save the file in.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 1: Data Cleanup"
    ]
  },
  {
    "objectID": "data/data.html",
    "href": "data/data.html",
    "title": "Data",
    "section": "",
    "text": "DOWNLOAD DATA  \n\nAfter download, unzip the data folder and place it somewhere you can find it again.",
    "crumbs": [
      "Course Material",
      "Data️"
    ]
  },
  {
    "objectID": "data/data.html#download-data",
    "href": "data/data.html#download-data",
    "title": "Data",
    "section": "",
    "text": "DOWNLOAD DATA  \n\nAfter download, unzip the data folder and place it somewhere you can find it again.",
    "crumbs": [
      "Course Material",
      "Data️"
    ]
  },
  {
    "objectID": "data/data.html#download-presentations",
    "href": "data/data.html#download-presentations",
    "title": "Data",
    "section": "Download presentations",
    "text": "Download presentations\nIt can be nice to follow along the presentation scripts as we go through them.\n\n  DOWNLOAD PRESENTATIONS",
    "crumbs": [
      "Course Material",
      "Data️"
    ]
  },
  {
    "objectID": "about_heads.html",
    "href": "about_heads.html",
    "title": "About HeaDS",
    "section": "",
    "text": "In the Center for Health Data Science (HeaDS) we do both research and in the DataLab and Sandbox we develop and host course. Read more about all the cool stuff we do on our website.\n\n\nThe DataLab offers a range of services to support SUND employees in their data science analyses. Here’s an overview:\n\nCourses: We offer data science and bioinformatics courses for all SUND staff (researchers, administrative staff, technical staff, etc.). Our most popular courses include “From Excel to R,” “Python Tsunami,” and “Introduction to Bulk RNA-seq Analysis.”\nConsultations: We host drop-in sessions every Thursday from 13:00 to 15:00, where we assist with data science-related challenges and questions. Alternatively, you can reach out to arrange a one-on-one meeting on another day.\nCommissions: We conduct commissioned research, such as bioinformatics and data science analyses tailored to your needs. Additionally, we offer a commissioned supervision scheme if you would like to learn how to perform the analysis yourself.\nEvents: We host various data science events. Join us for our seminar series, “Talking HeaDS.” Our next session is in the spring (date and speeker TBA), and you can sign up here: https://eventsignup.ku.dk/talkingheadsspring2025."
  },
  {
    "objectID": "about_heads.html#center-for-health-data-science",
    "href": "about_heads.html#center-for-health-data-science",
    "title": "About HeaDS",
    "section": "",
    "text": "In the Center for Health Data Science (HeaDS) we do both research and in the DataLab and Sandbox we develop and host course. Read more about all the cool stuff we do on our website.\n\n\nThe DataLab offers a range of services to support SUND employees in their data science analyses. Here’s an overview:\n\nCourses: We offer data science and bioinformatics courses for all SUND staff (researchers, administrative staff, technical staff, etc.). Our most popular courses include “From Excel to R,” “Python Tsunami,” and “Introduction to Bulk RNA-seq Analysis.”\nConsultations: We host drop-in sessions every Thursday from 13:00 to 15:00, where we assist with data science-related challenges and questions. Alternatively, you can reach out to arrange a one-on-one meeting on another day.\nCommissions: We conduct commissioned research, such as bioinformatics and data science analyses tailored to your needs. Additionally, we offer a commissioned supervision scheme if you would like to learn how to perform the analysis yourself.\nEvents: We host various data science events. Join us for our seminar series, “Talking HeaDS.” Our next session is in the spring (date and speeker TBA), and you can sign up here: https://eventsignup.ku.dk/talkingheadsspring2025."
  },
  {
    "objectID": "exercises/exercise0.html",
    "href": "exercises/exercise0.html",
    "title": "Exercise 0: R script and Quarto",
    "section": "",
    "text": "Make a new directory for this course.\nGo to course website and to the Data tab. Press the Download Data button.\nMove the Data folder to your course directory.\nUnder your course directory, make a new folder for your scripts, one for our output, and another for the presentations you download.\n\nYour file tree should look something like this:",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#file-management-data-download",
    "href": "exercises/exercise0.html#file-management-data-download",
    "title": "Exercise 0: R script and Quarto",
    "section": "",
    "text": "Make a new directory for this course.\nGo to course website and to the Data tab. Press the Download Data button.\nMove the Data folder to your course directory.\nUnder your course directory, make a new folder for your scripts, one for our output, and another for the presentations you download.\n\nYour file tree should look something like this:",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#working-directories",
    "href": "exercises/exercise0.html#working-directories",
    "title": "Exercise 0: R script and Quarto",
    "section": "Working directories",
    "text": "Working directories\n\nOpen R studio.\nAccess your current working directory by writing getwd() in the console.\n\nThe working directory in R (or other programming environments) is the folder on your computer where R looks for files to read or write by default. When you load or save data, R will use the working directory unless you specify another path. A path can either be absolute or relative:\n\nAbsolute path: The path from the root of your file system to the input file.\nRelative path: The path from the working directory to the input file.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#r-script",
    "href": "exercises/exercise0.html#r-script",
    "title": "Exercise 0: R script and Quarto",
    "section": "R Script",
    "text": "R Script\n\nCreate an R script and save it in your work folder.\n\nAn R script is a plain text file containing a series of R commands and code used for data analysis. R scripts have a .R extension and can be executed line-by-line in an interactive R session or as a whole script. They are ideal for automating workflows and keeping your analyses reproducible and organized. R scripts can be submitted to a job on a supercomputer unlike Quarto documents.\n\nType getwd() in your R script and run the line. Compare the working directory with the one from the console.\nChange the working directory using setwd().\nRun getwd() again.\nType in a few lines of code and some comments and re-save the file.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#quarto",
    "href": "exercises/exercise0.html#quarto",
    "title": "Exercise 0: R script and Quarto",
    "section": "Quarto",
    "text": "Quarto\n\nCreate an Quarto document and save it in your work folder.\n\nQuarto is an open-source publishing system designed to help you create dynamic, reproducible documents, presentations, and websites. It extends the ideas of tools like R Markdown, combining simplicity with powerful customization options for modern scientific and technical communication.\n\nType getwd() in a code chunk in your Quarto document and run the line. Compare the working directory with the one from the console.\nChange the working directory in one chuck using setwd().\nRun getwd() in the same chunk as setwd() AND in another chunk. What do you observe?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nsetwd('')\ngetwd()\n\n\ngetwd()\n\n\n\n\n\nCreate some code chunks, write text and headers. Re-save the file.\nRender the Quarto document and have a look at the html file.\n\n\n\n\n\n\n\nResources for Quarto\n\n\n\n\n\n\nQuarto website\n\n“Get started with Quarto” tutorial for RStudio\n\n“Get started with Quarto” video for RStudio\nComprehensive guides to Quarto basics",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise0.html#r-project",
    "href": "exercises/exercise0.html#r-project",
    "title": "Exercise 0: R script and Quarto",
    "section": "R project",
    "text": "R project\nAn R project in RStudio creates a self-contained working environment tied to a specific folder, which becomes the default working directory for all scripts, data, and outputs. This structure helps organize files, ensures reproducibility, and simplifies path management. By default, a Quarto document’s working directory is its file location. While this can be changed chunk-wise, the working directory for R scripts can be set globally for all scripts in a folder by creating an R project. The R project is a small configuration file, usually placed in the root of the project folder, and requires no manual interaction—it quietly ensures your workflows remain well-organized.\n\n\n\n\n\n\nCreate an R project by clicking the Project (None) in the top right → New Project → Existing Directory and choose an appropriate location. Look at the top-right corner to check that you are in your R project.\nReopen the the R script and Quarto document you created in Exercise 7 and 13 respectively. Check each of their working directories. Are they as you expect? Explain.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe working directory of the R script is the same as the location of the .Rproj file.\nThe working directory of the Quarto document is always the same as the location of the document.\n\n\n\n\n\nIf you like the flow of the R project, keep it. If not, delete it. It is not necessary to have an R project. NB If you delete it, click the R project drop-down menu in the top-right corner → Close Project.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 0: R script and Quarto"
    ]
  },
  {
    "objectID": "exercises/exercise2.html",
    "href": "exercises/exercise2.html",
    "title": "Exercise 2: Advanced Wrangling",
    "section": "",
    "text": "In this exercise you will do some more advance tidyverse operations such as pivoting and nesting.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "exercises/exercise2.html#getting-started",
    "href": "exercises/exercise2.html#getting-started",
    "title": "Exercise 2: Advanced Wrangling",
    "section": "Getting started",
    "text": "Getting started\n\nLoad packages.\nLoad the joined diabetes data set you created in exercise 1 and the glucose dataset from the data folder.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "exercises/exercise2.html#wrangling",
    "href": "exercises/exercise2.html#wrangling",
    "title": "Exercise 2: Advanced Wrangling",
    "section": "Wrangling",
    "text": "Wrangling\n\nHave a look at the glucose dataset. It has three columns with measurements from a Oral Glucose Tolerance Test where blood glucose is measured at fasting (Glucose_0), 6 hours after glucose intake (Glucose_6), and 12 hours after (Glucose_12). The last columns is an ID column. Change the data type of the ID column to factor in both diabetes_join and df_glucose.\nRestructure the glucose dataset into a long format. Name the column that describes which measurement the row refers to, i.e. Glucose_0, Glucose_60 or Glucose_120, Measurement. How many rows are there per ID? Does that make sense?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember the flow:\n\npivot_longer(cols = LIST_WITH_COLUMNS_TO_PIVOT,\n             names_to = \"NEW_COLUMN_CONTAINING_COLUMN_NAMES\",\n             values_to = \"NEW_COLUMN_CONTAINING_COLUMN_VALUES\")\n\nHave a look at slide 16 for a visual overview.\n\n\n\n\nIn your long format dataframe you should have one column that described which measurement the row refers to, i.e. Glucose_0, Glucose_60 or Glucose_120. Transform this column so that you only have the numerical part, i.e. only 0, 60 or 120. Then change the data type of that column to factor. Check the order of the factor levels and if necessary change them to the proper order.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe stringr packages is a part of tidyverse and has many functions for manipulating strings. Find a function that can split the string so you can extract the numbers on the other side of the underscore.\nHave a look at the help for factors ?factors to see how to influence the levels.\n\n\n\n\nMerge the glucose dataset with the joined diabetes dataset.\nPull the glucose measurements from your favorite ID.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFirst filter for your favorite ID and then pull the columns.\n\n\n\n\nCalculate the mean glucose measure for each measurement timepoint.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use group_by(), and summerize().\n\n\n\n\nCalculate mean and standard deviation for all numeric columns.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use summarise() and across(), selecting numeric columns.\n\n\n\n\nNest the glucose measurements and values such that there is only one row per ID and call the nested column OGTT (Oral Glucose Tolerance Test). Display the resulting tibble to confirm that you have succeeded.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember the flow:\n\ngroup_by() %&gt;% \n  nest() %&gt;% \n  ungroup()\n\n\n\n\n\nExport the final dataset. Since the dataset is nested, you cannot export it as an excel file. Export the dataset as an .rds file. Have a guess at what the function is called.",
    "crumbs": [
      "Course Material",
      "Exercises",
      "Exercise 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "exercises/exercise4.html",
    "href": "exercises/exercise4.html",
    "title": "Exercise 4 - Scripting in R",
    "section": "",
    "text": "In this exercise you will practice your scripting."
  },
  {
    "objectID": "exercises/exercise4.html#getting-started",
    "href": "exercises/exercise4.html#getting-started",
    "title": "Exercise 4 - Scripting in R",
    "section": "Getting started",
    "text": "Getting started\nLoad libaries and data\n\nlibrary(tidyverse)\nlibrary(glue)\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\ndiabetes_glucose\n\n# A tibble: 493 × 12\n   ID    Sex      Age BloodPressure GeneticRisk   BMI PhysicalActivity Smoker \n   &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  \n 1 9046  Male      34            84       0.619  24.7               93 Unknown\n 2 51676 Male      25            74       0.591  22.5              102 Unknown\n 3 60182 Male      50            80       0.178  34.5               98 Unknown\n 4 1665  Female    27            60       0.206  26.3               82 Never  \n 5 56669 Male      35            84       0.286  35                 58 Smoker \n 6 53882 Female    31            78       1.22   43.3               59 Smoker \n 7 10434 Male      52            86       1.15   33.3               58 Never  \n 8 27419 Female    54            78       0.692  35.2               74 Former \n 9 60491 Female    41            90       0.451  39.8               67 Smoker \n10 12109 Female    36            82       0.18   30.8               81 Smoker \n# ℹ 483 more rows\n# ℹ 4 more variables: Diabetes &lt;chr&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;"
  },
  {
    "objectID": "exercises/exercise4.html#if-else-statements",
    "href": "exercises/exercise4.html#if-else-statements",
    "title": "Exercise 4 - Scripting in R",
    "section": "If-else statements",
    "text": "If-else statements\nIn these exercises we don’t use the dataframe yet, that comes later when we have loops. For this part, just declare variables to test your statements, e.g. bp &lt;- 120.\n\nWrite an if-else statement that prints whether a person has high (more than 100), low (lower than 50) or normal blood pressure (between 50 and 100).\nWrite an if-else statement that assigns people high, moderate or low diabetes risk based on their genetic risk score and BMI:\n\n\ngenetic Risk greater than 1 and BMI greater than 35 -&gt; high risk\ngenetic Risk greater than 1 or BMI greater than 35 -&gt; moderate risk\notherwise low risk\n\nVerify that your statement works for different combinations of risk score and BMI"
  },
  {
    "objectID": "exercises/exercise4.html#loops",
    "href": "exercises/exercise4.html#loops",
    "title": "Exercise 4 - Scripting in R",
    "section": "Loops",
    "text": "Loops\n\nCreate a vector with at least 5 elements and loop over it.\nLoop over all column names of diabetes_glucose.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncolnames(df) creates a vector of column names.\n\n\n\n\nLoop over all rows of diabetes_glucose and determine whether the person’s blood pressure is high, low or normal with the same conditions as in 1.\nLoop over all rows of diabetes_glucose and determine the risk based on genetic risk score and BMI, with the same conditions as in 2. Print the genetic risk score and BMI as well as the risk level to make it easier to see whether your code works correctly.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAn easy way to printing several variables is to pass a vector into print: print(c(this,and_that,and_this_too))"
  },
  {
    "objectID": "exercises/exercise4.html#user-defined-functions",
    "href": "exercises/exercise4.html#user-defined-functions",
    "title": "Exercise 4 - Scripting in R",
    "section": "User defined Functions",
    "text": "User defined Functions\nIn this part we will write some functions that create plots.\nSince we want to be able to pass the name of the column to plot as a variable we will need to use the syntax for aliased column names. We showed how to do that in the end of presentation 3 if you need a refresher.\n\nCreate a variable plot_column and assign “Age” to it. Now make a boxplot of that column. Switch plot_column to a different column in diabetes_glucose. Does it work?\nWrap your code for the boxplot into a function. The function should take two arguments: the dataframe to use and the name of the column to plot. Test your function. Add some customization to the plot like a theme of colors.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFunctions are good at returning objects so make your plot into an object and return that.\n\n\n\n\nAdd a check to your function whether the supplied column is numeric. Note here that you need to test the data type of the column you want to plot, not the data type of it’s name. Confirm that your check works.\nWrite code to apply your boxplot function to each numerical column in the dataframe. There are different ways to achieve this.\nCreate an R script file to contain your functions. Copy your functions there and remove them from your global environment with rm(list=\"name_of_your_function\"). Now source the function R script in your quarto document and test that the functions work."
  },
  {
    "objectID": "exercises/exercise4.html#extra-exercises",
    "href": "exercises/exercise4.html#extra-exercises",
    "title": "Exercise 4 - Scripting in R",
    "section": "Extra exercises",
    "text": "Extra exercises\nFirst, unnest diabetes_glucose so you get back the Measurement and Glucose columns.\n\ndiabetes_glucose_unnest &lt;- diabetes_glucose %&gt;%\n  unnest(OGTT)\n\ne1. Calculate the mean Glucose (mmol/L) for each measuring time point (i.e. one value for 0, 60 and 120). Now stratify this mean by a second variable, Sex. You should have 6 mean values since there are 6 groups (0_female, 0_male, 60_female, ect). Now, create a variable category to which you pass the name of the column to stratify by (e.g. category &lt;- 'Sex') and use category in your code instead of the literal variable name.\ne2. We would like to make a plot that shows the means you calculated above. Again, use your category variable instead of the literal column name.\ne3. Wrap the code from e1 and e2 into a function show_mean_by_catergory so that you can call: show_mean_by_catergory(diabetes_glucose_unnest, 'Sex') and it will make you the plot. Test with different columns."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Data Science",
    "section": "",
    "text": "This 3 day course is a continuation of our 2 day course FromExceltoR and the material of that course is a prerequisite to this course. If you have not used R since you took the course, please go through the course material again (link to course). R for Data Science is an advanced course in R-programming for researchers at the Faculty of Health and Medical Sciences (SUND), University of Copenhagen. The course is build on code-along presentations and exercises in Quarto documents.\n\nThe course goes through the following topics:\n\nScript formats\nAdvanced tidyverse using real world data (build on material from our introduction to R course, FromExceltoR)\nScripting in R using functions, for-loops, if-else statements.\nModelling in R.\n\nThe material in this repository is for teaching purposes only and not to be distributed commercially.\nFinally… Dear course participants, it would greatly help us if you could complete our UPDATE LINK feedback form."
  },
  {
    "objectID": "index.html#welcome-to-the-main-page-of-r-for-data-science",
    "href": "index.html#welcome-to-the-main-page-of-r-for-data-science",
    "title": "R for Data Science",
    "section": "",
    "text": "This 3 day course is a continuation of our 2 day course FromExceltoR and the material of that course is a prerequisite to this course. If you have not used R since you took the course, please go through the course material again (link to course). R for Data Science is an advanced course in R-programming for researchers at the Faculty of Health and Medical Sciences (SUND), University of Copenhagen. The course is build on code-along presentations and exercises in Quarto documents.\n\nThe course goes through the following topics:\n\nScript formats\nAdvanced tidyverse using real world data (build on material from our introduction to R course, FromExceltoR)\nScripting in R using functions, for-loops, if-else statements.\nModelling in R.\n\nThe material in this repository is for teaching purposes only and not to be distributed commercially.\nFinally… Dear course participants, it would greatly help us if you could complete our UPDATE LINK feedback form."
  },
  {
    "objectID": "index.html#program",
    "href": "index.html#program",
    "title": "R for Data Science",
    "section": "Program",
    "text": "Program"
  },
  {
    "objectID": "presentations/presentation2.html",
    "href": "presentations/presentation2.html",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "",
    "text": "In this section we will learn more about data manipulation in the tidyverse framework and how to get your data into the correct format for a task.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#load-packages",
    "href": "presentations/presentation2.html#load-packages",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(readxl)\nlibrary(tidyverse)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#load-data",
    "href": "presentations/presentation2.html#load-data",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Load data",
    "text": "Load data\n\ndf_sales &lt;- read_excel('../out/sales_data_2.xlsx')",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#formats-pivot-long-and-wider",
    "href": "presentations/presentation2.html#formats-pivot-long-and-wider",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Formats: Pivot long and wider",
    "text": "Formats: Pivot long and wider\nIn tidyverse we primarily use two different formats: long and wide. The wide format is how you are probably used to seeing data presented with one column for each measured variable. However, when we need to plot, analyse or model data, we will often need them to be in the long format instead. It is therefore important that we know how to switch between them.\n\nPivot into long format\nThe goal of this section is to make a plot like this where we visualize the sales for each year across each employee.\n\n\n\n\n\nThe data is now in wide format. Can we make the plot in the way the data is formatted now?\n\n Hint \n\nNo. To create the plot, we need a column for the years to use on the x-axis, a column for sales in thousands DKK, and a column for Names. While the Names column is already present, the sales data is spread across four separate columns, and there is no column for the year.\n\n\n\nhead(df_sales)\n\n# A tibble: 6 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female        100        110        120        100 happy\n2     2 Bob        30 Male          200        210        220        230 happy\n3     3 Charlie    22 Male          150        160        170        200 happy\n4     4 Sophie     35 Female        300        320        340        250 happy\n5     5 Eve        28 Female        250        240        250        270 happy\n6     6 Frank      NA Male           NA        260        270        280 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\nThe data set is in wide format. The data can be restructured to long format such that there is one line per year per person. For this we use the pivot_longer function.\n\ndf_sales_longer &lt;- df_sales %&gt;% \n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"year\",\n               values_to = \"sales\"\n               )\n\nhead(df_sales_longer)\n\n# A tibble: 6 × 10\n     ID Name    Age Sex    mood  raise group        City  year       sales\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n1     1 Alice    25 Female happy no    young_female Miami sales_2020   100\n2     1 Alice    25 Female happy no    young_female Miami sales_2021   110\n3     1 Alice    25 Female happy no    young_female Miami sales_2022   120\n4     1 Alice    25 Female happy no    young_female Miami sales_2023   100\n5     2 Bob      30 Male   happy yes   mature_male  Miami sales_2020   200\n6     2 Bob      30 Male   happy yes   mature_male  Miami sales_2021   210\n\n\nWe can transform the year to integer.\n\ndf_sales_longer &lt;- df_sales_longer %&gt;% \n  mutate(year = str_remove(year, 'sales_') %&gt;% as.integer()) \n\nhead(df_sales_longer)\n\n# A tibble: 6 × 10\n     ID Name    Age Sex    mood  raise group        City   year sales\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1     1 Alice    25 Female happy no    young_female Miami  2020   100\n2     1 Alice    25 Female happy no    young_female Miami  2021   110\n3     1 Alice    25 Female happy no    young_female Miami  2022   120\n4     1 Alice    25 Female happy no    young_female Miami  2023   100\n5     2 Bob      30 Male   happy yes   mature_male  Miami  2020   200\n6     2 Bob      30 Male   happy yes   mature_male  Miami  2021   210\n\n\nMake the plot explained above (scatter and line plot over the sales development over the years for each person).\n\ndf_sales_longer %&gt;% \n  ggplot(aes(x = year, \n             y = sales, \n             color = Name)) + \n  geom_point() + \n  geom_line() + \n  theme_bw()\n\n\n\n\n\n\n\n# Saving the plot\n# ggsave('../out/sales_2_plot.png', width = 10.37, height = 7.55, units = 'in')\n\n\n\nPivot back into wide format\nThe pivot_wider function is used to get data to wide format.\n\ndf_sales_wider &lt;- df_sales_longer %&gt;% \n  pivot_wider(names_from = year, \n              values_from = sales,\n              names_prefix = 'sales_')\n\n# Same content\nhead(df_sales)\n\n# A tibble: 6 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female        100        110        120        100 happy\n2     2 Bob        30 Male          200        210        220        230 happy\n3     3 Charlie    22 Male          150        160        170        200 happy\n4     4 Sophie     35 Female        300        320        340        250 happy\n5     5 Eve        28 Female        250        240        250        270 happy\n6     6 Frank      NA Male           NA        260        270        280 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\nhead(df_sales_wider)\n\n# A tibble: 6 × 12\n     ID Name      Age Sex    mood  raise group       City  sales_2020 sales_2021\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1     1 Alice      25 Female happy no    young_fema… Miami        100        110\n2     2 Bob        30 Male   happy yes   mature_male Miami        200        210\n3     3 Charlie    22 Male   happy yes   young_male  LA           150        160\n4     4 Sophie     35 Female happy no    mature_fem… New …        300        320\n5     5 Eve        28 Female happy yes   young_fema… LA           250        240\n6     6 Frank      NA Male   happy yes   &lt;NA&gt;        New …         NA        260\n# ℹ 2 more variables: sales_2022 &lt;dbl&gt;, sales_2023 &lt;dbl&gt;",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#nesting",
    "href": "presentations/presentation2.html#nesting",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Nesting",
    "text": "Nesting\nThe long format can contain many repetitions e.g. information on the sales employee in df_sales_longer is repeated for every year. Instead of having many nearly identical rows we can use nesting to have just one row with the employee information and the associated sales data in its own ‘mini-tibble’.\nWe’ll group data by Name and nest year and sales into a single column that we will name sales_data.\n\ndf_sales_longer_nested &lt;- df_sales_longer %&gt;%  \n  group_by(Name) %&gt;% \n  nest(sales_data = c(year, sales)) %&gt;% \n  ungroup()\n\nhead(df_sales_longer_nested)\n\n# A tibble: 6 × 9\n     ID Name      Age Sex    mood  raise group         City     sales_data      \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;    &lt;list&gt;          \n1     1 Alice      25 Female happy no    young_female  Miami    &lt;tibble [4 × 2]&gt;\n2     2 Bob        30 Male   happy yes   mature_male   Miami    &lt;tibble [4 × 2]&gt;\n3     3 Charlie    22 Male   happy yes   young_male    LA       &lt;tibble [4 × 2]&gt;\n4     4 Sophie     35 Female happy no    mature_female New York &lt;tibble [4 × 2]&gt;\n5     5 Eve        28 Female happy yes   young_female  LA       &lt;tibble [4 × 2]&gt;\n6     6 Frank      NA Male   happy yes   &lt;NA&gt;          New York &lt;tibble [4 × 2]&gt;\n\n\nYou can see that the newly made column sales_data has the data type list because it contains not one value per row, like City or group do, but instead an entire little tibble.\nNow we have a structured dataset which is more readable.\nNote: Nested data cannot be exported as an Excel or CSV file. Instead, you need to export it as an RDS file, a format specifically designed to save R objects.\nWe can extract the sales information for a particular employee using the pull function.\n\ndf_sales_longer_nested %&gt;% \n  filter(Name == 'Bob') %&gt;% \n  pull(sales_data)\n\n[[1]]\n# A tibble: 4 × 2\n   year sales\n  &lt;int&gt; &lt;dbl&gt;\n1  2020   200\n2  2021   210\n3  2022   220\n4  2023   230\n\n\nFor operations on the information contained in nested columns they first need to be unnested:\n\ndf_sales_longer_nested %&gt;%\n  unnest(sales_data) %&gt;%\n  summarise(mean_sales = mean(sales, na.rm = T))\n\n# A tibble: 1 × 1\n  mean_sales\n       &lt;dbl&gt;\n1       297.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#tidyverse-helpers-across-and-where",
    "href": "presentations/presentation2.html#tidyverse-helpers-across-and-where",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "Tidyverse helpers: across() and where()",
    "text": "Tidyverse helpers: across() and where()\n\nUsing across() to select columns\nYou probably noticed that we used a function to help us to summarise() all columns in Presentation 1:\n\ndf_tidyverse %&gt;% summarise(across(everything(), ~ sum(is.na(.))))\n\nIn this section we will say a bit more about the so called tidyverse helpers such as across(), where(), and starts_with(). These helpers are useful when we want to apply a functions, i.e. summarise(), or mutate() to several columns.\nLet’s have an example. We know we can calculate the mean of each sales column like so:\n\ndf_sales %&gt;%\n  summarise(mean(sales_2020),\n            mean(sales_2021),\n            mean(sales_2022),\n            mean(sales_2023))\n\n# A tibble: 1 × 4\n  `mean(sales_2020)` `mean(sales_2021)` `mean(sales_2022)` `mean(sales_2023)`\n               &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1                 NA                300                 NA                305\n\n\nNote: We got some NAs because sales_2020 and 2022 contain NA values and we didn’t specify na.rm=TRUE. We will continue to see these in the below examples. Don’t worry about them for now, we will show you how to deal with them later!\nBut then we need to name every column we want to apply summarise to. across() instead lets us select the columns across which we want to apply summarise in a dynamic fashion:\n\ndf_sales %&gt;%\n  summarise(across(everything(), mean))\n\n# A tibble: 1 × 12\n     ID  Name   Age   Sex sales_2020 sales_2021 sales_2022 sales_2023  mood\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1   5.5    NA    NA    NA         NA        300         NA        305    NA\n# ℹ 3 more variables: raise &lt;dbl&gt;, group &lt;dbl&gt;, City &lt;dbl&gt;\n\n\nWe put the columns we want to select inside the brackets of across(). everything(), as you have probably guessed means all columns.\nWe will probably not want to calculate means on non-numeric columns, so let’s select only numeric columns. For that we need another helper caller where() that lets us select columns based on their properties, like data type.\n\ndf_sales %&gt;%\n  summarise(across(where(is.numeric), mean))\n\n# A tibble: 1 × 6\n     ID   Age sales_2020 sales_2021 sales_2022 sales_2023\n  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1   5.5    NA         NA        300         NA        305\n\n\nThere is another group of helpers that refers to column names:\n\nstarts_with()\nends_with()\ncontains()\n\nAnd we can use them to select only columns starting with ‘sales’:\n\ndf_sales %&gt;%\n  summarise(across(starts_with('sales'), mean))\n\n# A tibble: 1 × 4\n  sales_2020 sales_2021 sales_2022 sales_2023\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1         NA        300         NA        305\n\n\nIf the column names follow some pattern like ‘sales_XXXX’ we can also employ num_range to specify them:\n\ndf_sales %&gt;%\n  summarise(across(num_range('sales_', 2020:2023), mean))\n\n# A tibble: 1 × 4\n  sales_2020 sales_2021 sales_2022 sales_2023\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1         NA        300         NA        305\n\n\nLastly, we can always straight up supply the names of the columns we want to select in a vector:\n\ndf_sales %&gt;%\n  summarise(across(c(sales_2020, sales_2021), mean))\n\n# A tibble: 1 × 2\n  sales_2020 sales_2021\n       &lt;dbl&gt;      &lt;dbl&gt;\n1         NA        300\n\n\nAll these ways can be used to select columns in tidyverse, also outside of across(). As an example, you’ve already see starts_with() in the Long Format section when we selected the columns to convert with pivot_longer():\n\ndf_sales %&gt;% \n  pivot_longer(cols = starts_with(\"sales_\"),\n               names_to = \"year\",\n               values_to = \"sales\")\n\n\n\nsummarise() becomes more powerful!\nAlright, so we now know how save ourselves from having to name every column we want to operate on, but what if we want to calculate several summary stats? There’s more to numbers than means!\nNow that we have across() we can supply summarise with a list of summary functions to execute:\n\ndf_sales %&gt;%\n  summarise(across(starts_with(\"sales\"), list(mean, sd, min, max)))\n\n# A tibble: 1 × 16\n  sales_2020_1 sales_2020_2 sales_2020_3 sales_2020_4 sales_2021_1 sales_2021_2\n         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1           NA           NA           NA           NA          300         131.\n# ℹ 10 more variables: sales_2021_3 &lt;dbl&gt;, sales_2021_4 &lt;dbl&gt;,\n#   sales_2022_1 &lt;dbl&gt;, sales_2022_2 &lt;dbl&gt;, sales_2022_3 &lt;dbl&gt;,\n#   sales_2022_4 &lt;dbl&gt;, sales_2023_1 &lt;dbl&gt;, sales_2023_2 &lt;dbl&gt;,\n#   sales_2023_3 &lt;dbl&gt;, sales_2023_4 &lt;dbl&gt;\n\n\nNow we get one long row with mean, sd, min and max for every column starting with sales. We’re probably not super happy with the column names sales_2020_1, sales_2020_2, ect, so let’s add names that contain the function we’re executing (mean, ect). In order for this to work we must also name the functions:\n\ndf_sales %&gt;%\n  summarise(across(starts_with(\"sales\"), \n                   list(mean = mean, sd = sd, min = min, max = max),\n                   .names = \"{.col}-{.fn}\"))\n\n# A tibble: 1 × 16\n  `sales_2020-mean` `sales_2020-sd` `sales_2020-min` `sales_2020-max`\n              &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n1                NA              NA               NA               NA\n# ℹ 12 more variables: `sales_2021-mean` &lt;dbl&gt;, `sales_2021-sd` &lt;dbl&gt;,\n#   `sales_2021-min` &lt;dbl&gt;, `sales_2021-max` &lt;dbl&gt;, `sales_2022-mean` &lt;dbl&gt;,\n#   `sales_2022-sd` &lt;dbl&gt;, `sales_2022-min` &lt;dbl&gt;, `sales_2022-max` &lt;dbl&gt;,\n#   `sales_2023-mean` &lt;dbl&gt;, `sales_2023-sd` &lt;dbl&gt;, `sales_2023-min` &lt;dbl&gt;,\n#   `sales_2023-max` &lt;dbl&gt;\n\n\nStill not your preferred format? You can probably pivot your way out of that!\n\ndf_sales %&gt;%\n  #run summarise on all sales columns\n  summarise(across(starts_with(\"sales\"), \n                   list(mean = mean, sd = sd, min = min, max = max),\n                   .names = \"{.col}-{.fn}\")) %&gt;%\n  #add reformating\n  pivot_longer(cols = everything(), \n               names_to = c(\"variable\", \"statistic\"), \n               names_sep = \"-\") %&gt;%\n  pivot_wider(names_from = statistic, values_from = value)\n\n# A tibble: 4 × 5\n  variable    mean    sd   min   max\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 sales_2020    NA   NA     NA    NA\n2 sales_2021   300  131.   110   510\n3 sales_2022    NA   NA     NA    NA\n4 sales_2023   305  131.   100   500",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation2.html#the-anonymous-function-and-.",
    "href": "presentations/presentation2.html#the-anonymous-function-and-.",
    "title": "Presentation 2: Advanced Data Wrangling",
    "section": "The anonymous function: ~ and .",
    "text": "The anonymous function: ~ and .\nBut wait! We still have those pesky NAs in our summary stats. Let’s just add the na.rm=TRUE argument. To not have too many things going on at once we’ll only do mean() for now:\n\ndf_sales %&gt;%\n  summarise(across(starts_with(\"sales\"), \n                   list(mean = mean(na.rm = TRUE)),\n                   .names = \"{.col}-{.fn}\"))\n\nError in `summarise()`:\nℹ In argument: `across(...)`.\nCaused by error in `mean.default()`:\n! argument \"x\" is missing, with no default\n\n\nBrrrtt! We may not.\n\n\n\n\n\nWhy? We are requesting a function call across several columns and we’re doing it in shorthand. This is only permitted is there are no arguments to the function (mean(), sd(), ect). You will also notice that we didn’t use brackets after their names, which is part of using the function short hand.\nIf we need to pass arguments to functions inside another function call (i.e. calling mean inside summarise) we need to invoke the anonymous function. Don’t worry, it is much less ominous than it sounds! It is written as a ~ and looks like this:\n\ndf_sales %&gt;%\n  summarise(across(starts_with(\"sales\"), \n                   list(mean = ~ mean(., na.rm = TRUE)),\n                   .names = \"{.col}-{.fn}\"))\n\n# A tibble: 1 × 4\n  `sales_2020-mean` `sales_2021-mean` `sales_2022-mean` `sales_2023-mean`\n              &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1              294.               300              288.               305\n\n\nThe observant reader will also have noticed that a . has appeared in the brackets behind mean(). It simply means ‘the data previously referred to’, in this case every column starting with ‘sales’. We need to use the . because mean when called as a proper function needs to have an argument (a vector of numbers) to work on:\n\nmean(df_sales$sales_2020,na.rm=TRUE)\n\n[1] 294.4444\n\n\nSo this is it, we invoke the anonymous function for every statistic we want to calculate and now we may pass arguments:\n\ndf_sales %&gt;%\n  #across and starts_with selects columns\n  summarise(across(starts_with(\"sales\"), \n                   #list the functions to execute\n                   list(mean = ~ mean(., na.rm=T),\n                        sd = ~ sd(., na.rm=T), \n                        min = ~ min(., na.rm=T), \n                        max = ~ max(., na.rm=T)),\n                   #specify names of output columns\n                   .names = \"{.col}-{.fn}\")) %&gt;%\n  \n  #add reformating\n  pivot_longer(cols = everything(), \n               names_to = c(\"variable\", \"statistic\"), \n               names_sep = \"-\") %&gt;%\n  pivot_wider(names_from = statistic, values_from = value)\n\n# A tibble: 4 × 5\n  variable    mean    sd   min   max\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 sales_2020  294.  136.   100   500\n2 sales_2021  300   131.   110   510\n3 sales_2022  288.  115.   120   470\n4 sales_2023  305   131.   100   500\n\n\n\nOther usage examples\nThe anonymous function and across are also useful inside mutate()! Our data has sales in thousands DKK, so lets multiply every value in every sales column with 1000:\n\ndf_sales %&gt;% head(n=3)\n\n# A tibble: 3 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female        100        110        120        100 happy\n2     2 Bob        30 Male          200        210        220        230 happy\n3     3 Charlie    22 Male          150        160        170        200 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\n\ndf_sales %&gt;%\n  mutate(across(starts_with(\"sales\"), ~ . * 1000)) %&gt;%\n  head(n=3)\n\n# A tibble: 3 × 12\n     ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n1     1 Alice      25 Female     100000     110000     120000     100000 happy\n2     2 Bob        30 Male       200000     210000     220000     230000 happy\n3     3 Charlie    22 Male       150000     160000     170000     200000 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\n\nWhat is happening here is we first select all columns starting with ‘sales’ by using across() and starts_with(). Then we say that we want to execute a function on each of these columns. The function shall be ‘multiply this column by 1000’. Multiplying by 1000 is written as * 1000 in R, ‘this column’ is . as we discussed before and ~ tells R that we’re executing a function.\nAnother cool example: Replacing NAs with 0s only in the columns starting with ‘sales’:\n\ndf_sales %&gt;%\n  mutate(across(starts_with(\"sales\"), ~ replace_na(.,0)))\n\n# A tibble: 10 × 12\n      ID Name      Age Sex    sales_2020 sales_2021 sales_2022 sales_2023 mood \n   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;\n 1     1 Alice      25 Female        100        110        120        100 happy\n 2     2 Bob        30 Male          200        210        220        230 happy\n 3     3 Charlie    22 Male          150        160        170        200 happy\n 4     4 Sophie     35 Female        300        320        340        250 happy\n 5     5 Eve        28 Female        250        240        250        270 happy\n 6     6 Frank      NA Male            0        260        270        280 happy\n 7     7 Grace      40 Female        400        420        430        450 happy\n 8     8 Hannah     29 Female        500        510          0        500 happy\n 9     9 Ian        21 Male          450        460        470        480 happy\n10    10 Jack       33 Male          300        310        320        290 happy\n# ℹ 3 more variables: raise &lt;chr&gt;, group &lt;chr&gt;, City &lt;chr&gt;\n\n\nThis is it for now but there will be user-defined functions later!",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 2: Advanced Data Wrangling"
    ]
  },
  {
    "objectID": "presentations/presentation4_functions.html",
    "href": "presentations/presentation4_functions.html",
    "title": "Presentation 4, Functions",
    "section": "",
    "text": "Here we show the contents of presentation4_functions.R:\n\n\n# Packages should be loaded in the main script.\n\n# Function to calculate BMI\ncalculate_bmi &lt;- function(weight_kg, height_m){\n  \n  bmi &lt;- weight_kg/height_m^2\n  \n  return(bmi)\n  \n}\n\n# Function to calculate BMI, with control points and error checking. \ncalculate_bmi_2 &lt;- function(weight_kg, height_m) {\n  \n  # Check if weight and height are numeric\n  if (!is.numeric(weight_kg) | !is.numeric(height_m)) {\n    stop(\"Both weight_kg and height_m must be numeric values.\")\n  }\n  \n  # Check if weight and height are positive\n  if (weight_kg &lt;= 0) {\n    stop(\"Weight must be a positive value.\")\n  }\n  if (height_m &lt;= 0) {\n    stop(\"Height must be a positive value.\")\n  }\n  \n  # Calculate BMI\n  bmi &lt;- weight_kg / height_m^2\n  \n  # Check if BMI is within a reasonable range\n  if (bmi &lt; 10 | bmi &gt; 60) {\n    warning(\"The calculated BMI is outside the normal range. Please check your input values.\")\n  }\n  \n  return(bmi)\n  \n}",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 4, Functions: Scripting in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html",
    "href": "presentations/presentation5.html",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "",
    "text": "In this section we’ll look at how to define and fit a model in R.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#load-packages",
    "href": "presentations/presentation5.html#load-packages",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(tidyverse)\nlibrary(caTools)\nlibrary(ModelMetrics)",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#load-data",
    "href": "presentations/presentation5.html#load-data",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Load data",
    "text": "Load data\nIn order to focus on the technical aspects we’ll use a very simple toy dataset. It contains the number of cigarettes smoked per day and how long the person lived. It is inspired by this paper if you want to take a look.\n\ndf_smoke &lt;- as_tibble(read.csv('../data/smoking_cat.csv'))\ndf_smoke\n\n# A tibble: 100 × 3\n   daily_cigarettes  life exercise\n              &lt;int&gt; &lt;int&gt;    &lt;int&gt;\n 1                7    76        0\n 2               11    73        0\n 3               27    72        1\n 4               23    71        0\n 5               13    74        0\n 6               11    76        1\n 7               20    71        0\n 8                6    76        1\n 9               23    72        1\n10               32    70        2\n# ℹ 90 more rows\n\n\nWe will use this to perform a linear regression.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#linear-regression",
    "href": "presentations/presentation5.html#linear-regression",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nSplit Data into Training and Test Set\nFirst, we will split our data into a test and a training set. There are numerous ways to do this. We here show sample_frac from dplyr:\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#add an ID column to keep track of observations\ndf_smoke$ID &lt;- 1:nrow(df_smoke)\n\ntrain &lt;- df_smoke %&gt;% sample_frac(.75)\nnrow(train)\n\n[1] 75\n\nhead(train)\n\n# A tibble: 6 × 4\n  daily_cigarettes  life exercise    ID\n             &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt;\n1               29    72        1    31\n2               16    73        0    79\n3                5    78        1    51\n4                3    77        0    14\n5                4    79        2    67\n6               23    71        1    42\n\n\nAs you can see, the ID’s in train are shuffled and it only has 75 rows since we asked for 75% of the data. Now all we have to do is identify the other 25%, i.e. the observations not in train. dpylr has a neat function called anti_join for that:\n\n#from df_smoke remove what is in train by checking the ID column\ntest  &lt;- anti_join(df_smoke, train, by = 'ID') \nnrow(test)\n\n[1] 25\n\nhead(test)\n\n# A tibble: 6 × 4\n  daily_cigarettes  life exercise    ID\n             &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt;\n1                7    76        0     1\n2               11    73        0     2\n3               27    72        1     3\n4               32    70        2    10\n5                8    75        0    11\n6               16    75        2    24\n\n\n\n\nDefining the model\nAs stated above, a linear regression model generally has the form of:\n\\[y=b_0+b_1*x_i\\]\nWhere we refer to \\(b_0\\) as the intercept and \\(b_1\\) as the coefficient. There will typically be one coefficient for each predictor. The goal of modelling is to estimate the values of \\(b_0\\) and all \\(b_i\\).\nWe need to tell R which of our variables is the outcome, \\(y\\) and which predictors \\(x_i\\) we want to include in the model. This is referred to in documentation as the model’s formula. Have a look:\n\n#the formula is written like so:\nlm(y ~ x_1 + x_2 + ...)\n#see the help\n?lm\n\nIn our case, \\(y\\) is the number of years lived and we have a singular predictor \\(x_1\\), the number of cigarettes smoked per day. So that will be our model formulation:\n\n#remember to select the training data subset we defined above! \nmodel &lt;- lm(life ~ daily_cigarettes, data = train)\n\n\n\nModelling results\nBy calling lm we have already trained our model! Lets have a look at the results. The summary gives us a lot of information about the model we trained:\n\n# View model summary\nsummary(model)\n\n\nCall:\nlm(formula = life ~ daily_cigarettes, data = train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.71479 -1.03035 -0.06517  0.82928  2.84669 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      78.71479    0.26847  293.20   &lt;2e-16 ***\ndaily_cigarettes -0.28074    0.01351  -20.77   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.251 on 73 degrees of freedom\nMultiple R-squared:  0.8553,    Adjusted R-squared:  0.8533 \nF-statistic: 431.5 on 1 and 73 DF,  p-value: &lt; 2.2e-16\n\n\nIt beings with Call which displays the formula used to fit the model.\nThe Residuals section summarizes the distribution of the residuals, which is the difference between the actual observed \\(y\\) values and the fitted \\(y\\) values.\nThe Coefficients table shows the estimated values for each coefficient including the intercept, along with their standard errors, t-values, and p-values. These help to determine the significance of each predictor. Smaller p-values indicate stronger evidence against the null hypothesis that the true coefficient is zero.\nIn the bottom section we have some information about how well model fits the training data. The Residual Standard Error (RSE) provides a measure of accuracy as it represents the average size of the residuals. The R-squared value indicates the proportion of variance explained by the model, with the Adjusted R-squared accounting for the number of predictors to prevent overfitting. Finally, the F-statistic and its p-value test whether the model as a whole explains a significant portion of the variance in the response variable (the outcome \\(y\\)).\nOverall, the summary helps us to assess the model fit and identify significant predictors and their effect size (size of the coefficient).\nWe can extract the model object’s components with $:\n\nmodel$coefficients\n\n     (Intercept) daily_cigarettes \n      78.7147894       -0.2807398 \n\nhist(model$residuals, breaks = 30, main = 'Histogram of residuals', \n     xlab = 'Residual')\n\n\n\n\n\n\n\n\n\n\nModel interpretation\nWhat do these results mean? Our model formulation is:\n\\[life=b_0+b_1*cigarettes\\]\nAnd we estimated these values:\n\nmodel$coefficients\n\n     (Intercept) daily_cigarettes \n      78.7147894       -0.2807398 \n\n\nTherefore:\n\nThe intercept \\(b_0\\) is the number of years we estimated a person in this dataset will live if they smoke 0 cigarettes. It is 78.7 years\nThe coefficient of cigarettes per day is -0.28. This means for every 1 unit increase in cigarettes (one additional cigarette per day) the life expectancy decreases by 0.28 years.\n\n\n\nModel performance\nWe now use our held out test data to evaluate the model performance. For that we will predict life expectancy for the 25 observations in test and compare with the actual values.\n\n#use the fitted model to make predictions for the test data\ny_pred &lt;- predict(model, test)\ny_pred\n\n       1        2        3        4        5        6        7        8 \n76.74961 75.62665 71.13481 69.73112 76.46887 74.22295 77.59183 70.29260 \n       9       10       11       12       13       14       15       16 \n73.38073 70.01186 76.46887 75.62665 75.34591 76.46887 73.38073 75.34591 \n      17       18       19       20       21       22       23       24 \n76.18813 71.41555 73.66147 71.13481 71.97703 75.34591 72.25777 75.90739 \n      25 \n78.71479 \n\n\nLet’s see how that fits with the known values.\n\npred &lt;- tibble(pred = y_pred, real = test$life)\n\nggplot(pred, aes(x=real, y=pred)) +\n  geom_point()\n\n\n\n\n\n\n\n\nNot too bad! We usually calculate the mean square error (mse) between predictions and the known true values to numerically evaluate regression performance:\n\nmse(pred$real,pred$pred)\n\n[1] 1.742902\n\n\nOur predictions are on average 1.7 years wrong.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#regression-with-categorical-features",
    "href": "presentations/presentation5.html#regression-with-categorical-features",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Regression with categorical features",
    "text": "Regression with categorical features\nNow that we know how to make a simple linear model, how can we include categorical variables and what is the interpretation of their coefficients? To investigate this we include the other predictor variable we have: Exercise level.\n\ndistinct(df_smoke, exercise)\n\n# A tibble: 3 × 1\n  exercise\n     &lt;int&gt;\n1        0\n2        1\n3        2\n\n\nAlright, we have three different levels of exercise. They are: low == 0, moderate == 1 and high == 2. Before we go on, let’s have a look if our data is represented correctly:\n\nstr(df_smoke)\n\ntibble [100 × 4] (S3: tbl_df/tbl/data.frame)\n $ daily_cigarettes: int [1:100] 7 11 27 23 13 11 20 6 23 32 ...\n $ life            : int [1:100] 76 73 72 71 74 76 71 76 72 70 ...\n $ exercise        : int [1:100] 0 0 1 0 0 1 0 1 1 2 ...\n $ ID              : int [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n\n\nWe can see that the exercise column is interpreted as an integer. However, it is actually a category! In R categorical variables are known as factors and have their own datatype. Let’s convert exercise to a factor:\n\ndf_smoke$exercise &lt;- as.factor(df_smoke$exercise)\nstr(df_smoke)\n\ntibble [100 × 4] (S3: tbl_df/tbl/data.frame)\n $ daily_cigarettes: int [1:100] 7 11 27 23 13 11 20 6 23 32 ...\n $ life            : int [1:100] 76 73 72 71 74 76 71 76 72 70 ...\n $ exercise        : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 1 2 1 1 2 1 2 2 3 ...\n $ ID              : int [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n\n\nAs before, before fitting the model we’ll split up the data in train and test. Since we’re using the same seed we should get the same observations, i.e. rows into training and test as above.\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#add an ID column to keep track of observations\ndf_smoke$ID &lt;- 1:nrow(df_smoke)\n\ntrain &lt;- df_smoke %&gt;% sample_frac(.75)\ntest  &lt;- anti_join(df_smoke, train, by = 'ID') \n\nAnd now we extend our previous model formula with the new predictor:\n\nmodel2 &lt;- lm(life ~ daily_cigarettes + exercise, data = train)\n\n\nsummary(model2)\n\n\nCall:\nlm(formula = life ~ daily_cigarettes + exercise, data = train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.58295 -0.53972 -0.01596  0.53773  1.70257 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      77.582954   0.234237 331.216  &lt; 2e-16 ***\ndaily_cigarettes -0.285521   0.009401 -30.372  &lt; 2e-16 ***\nexercise1         1.095475   0.249402   4.392 3.84e-05 ***\nexercise2         2.372227   0.260427   9.109 1.48e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8578 on 71 degrees of freedom\nMultiple R-squared:  0.9338,    Adjusted R-squared:  0.931 \nF-statistic: 333.7 on 3 and 71 DF,  p-value: &lt; 2.2e-16\n\n\nWhen we check the summary we see that it has two additional coefficients, exercise1 and exercise2. What are they?\nBecause exercise is a categorical variable it is dummy coded. That means our model formula mathematically looks something like this:\n\\[y=b_0+b_1*x_1 + b_2 *x_2 + b_3*x_3\\]\nwith:\n\n\n\nExercise level\n\\(x_2\\)\n\\(x_3\\)\n\n\n\n\n0\n0\n0\n\n\n1\n1\n0\n\n\n2\n0\n1\n\n\n\nAnd for our coefficients it means:\n\nmodel2$coefficients\n\n     (Intercept) daily_cigarettes        exercise1        exercise2 \n      77.5829543       -0.2855213        1.0954747        2.3722266 \n\n\n\nIntercept == \\(b_0\\): The life expectancy at 0 cigarettes and exercise level 0\ndaily_cigerettes == \\(b_1\\): The change in life expectancy for each additional cigarette.\nexercise1 == \\(b_2\\): The change in life expectancy if the exercise level is 1 (assuming the number of cigarettes stays constant).\nexercise2 == \\(b_3\\): The change in life expectancy if the exercise level is 2 (assuming the number of cigarettes stays constant).\n\nWhy is there no coefficient for exercise level 0 (low amount of exercise)? This case is covered in the Intercept. It is referred to as the reference level of the categorical variable. You can change which level is regarded as the reference and the effect of having this level will always be modelled in the intercept.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#classification",
    "href": "presentations/presentation5.html#classification",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Classification",
    "text": "Classification\nClassification is what we apply when the outcome has two or more classes.\nIn order to have a categorical outcome, we’ll add a column to our toy data that describes whether the person died before age 75 or not.\n\ndf_smoke &lt;- df_smoke %&gt;%\n  mutate(early_death = factor(ifelse(life &lt; 75, 'yes', 'no')))\n\ndf_smoke %&gt;%\n  count(early_death)\n\n# A tibble: 2 × 2\n  early_death     n\n  &lt;fct&gt;       &lt;int&gt;\n1 no             49\n2 yes            51\n\n\n\nTraining and Test set with class data\nLet’s remake our training and test data. This time we have classes that we would like to be in the same ratios in training and test set. Therefore, we cannot just grab 75% of the data as we did before. We’ll use sample.split from caTools to achieve balanced classes:\n\n# Set seed to ensure reproducibility\nset.seed(123)\n\nsplit &lt;- sample.split(df_smoke$early_death, SplitRatio = 0.75)\n\n#split is a vector of true and false values we can now directly apply to our tibble\nsplit\n\n  [1]  TRUE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE\n [13]  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE\n [25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE  TRUE\n [37] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE\n [49]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [61]  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE\n [73]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE\n [85]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n [97]  TRUE  TRUE  TRUE  TRUE\n\ntrain &lt;- df_smoke[split,]\ntest &lt;- df_smoke[!split,] #! negates the vector, so true becomes false and vice verse\n\ncount(train,early_death)\n\n# A tibble: 2 × 2\n  early_death     n\n  &lt;fct&gt;       &lt;int&gt;\n1 no             37\n2 yes            38\n\ncount(test, early_death)\n\n# A tibble: 2 × 2\n  early_death     n\n  &lt;fct&gt;       &lt;int&gt;\n1 no             12\n2 yes            13\n\n\nNow we can perform logistic regression to see whether there is an influence of the number of cigarettes and amount of exercise on the odds of the person dying before 75.\nLogistic regression belongs to the family of generalized linear models. They all look like this:\n\\[ y \\sim \\beta * X \\]\nwith:\n\n\\(y\\) the outcome\n\\(\\beta\\) the coefficient matrix\n\\(X\\) the matrix of predictors\n\\(\\sim\\) the link function\n\nIn a logistic regression model the link function is the logit. In a linear model the link function is the identity function (so ~ becomes =).\n\n\nLogistic regression: Math\nIn order to understand what that means we’ll need a tiny bit of math.\nWe see some issues right of the bat. Our \\(y\\) is either 0 or 1 (the person is either dead or not). However we cannot model that so instead we will model the probability of the outcome being 1: \\(P(earlydeath == 1)\\). Except probabilities are bounded between 0 and 1 which is mathematically difficult to impose (it means all \\(y\\)’s have to be between these two values and how are we gonna enforce that?) So instead, we will model the log-odds of early death:\n\\[ y = \\log(\\frac{P(earlydeath == 1)}{1-P(earlydeath == 1)})\\]\nIt may not look like it but we promise you this \\(y\\) is a well behaved number because it can be anywhere between - infinity and + infinity. So therefore our actual model is:\n\\[ \\log(\\frac{P(earlydeath == 1)}{1-P(earlydeath == 1)} =  \\beta * X\\]\nAnd if we want to know what the means for the probability of dying we just take the logit of \\(y\\) :\n\\[ P(earlydeath == 1) = \\frac{1}{1+ e^{(-y)}} \\]\nWhich makes the link between what we’re actually interested in (people’s chances of dying) and what we’re modelling the logit. End of math.\n\n\nModel formulation in R\nSo in order to fit a logistic regression we will use the function for generalized linear models, glm. We will specify that we want logistic regression (using the logit as the link) by setting family = binomial:\n\nmodel_log &lt;- glm(early_death ~ daily_cigarettes + exercise, data = train, family = \"binomial\")\nsummary(model_log)\n\n\nCall:\nglm(formula = early_death ~ daily_cigarettes + exercise, family = \"binomial\", \n    data = train)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-1.49830  -0.08900   0.00052   0.01900   2.64289  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)      -11.0307     4.0190  -2.745  0.00606 **\ndaily_cigarettes   0.8380     0.2836   2.955  0.00313 **\nexercise1         -1.6493     2.0986  -0.786  0.43191   \nexercise2         -2.5922     2.4751  -1.047  0.29497   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 103.959  on 74  degrees of freedom\nResidual deviance:  13.717  on 71  degrees of freedom\nAIC: 21.717\n\nNumber of Fisher Scoring iterations: 8\n\n\n\n\nModel interpretation\nWe see from looking at the summary that the coefficient of exercise level 1 and level 2 is not significant. This means that we are not confident that doing a high amount of exercise (level 3) has a significant impact on the probability of dying before 75 compare to doing moderate or low amounts of exercise. This does not mean that there can be no influence, merely that we do not have enough data to detect it if it is there.\nAre you surprised? Exercise level was significant when we modelled the number of years lived, which is arguably a more fine-grained information than the binary split and perhaps therefore we picked up the influence.\nWith the number of daily cigarettes predictor we have a high degree of certainty that it influences the probability of dying before 75 (in this dataset!), but what does a coefficient of 0.84 mean?\nWe know that:\n\\[ P(earlydeath == 1) = \\frac{1}{1+ e^{(-y)}} \\]\nand (leaving out the exercise level since it’s not significant):\n\\[ y = \\beta_0 + \\beta_1 * cigs \\]\nSo how does \\(y\\) change as \\(0.84 * cigs\\) becomes larger? Let’s agree that \\(y\\) becomes larger. What does that mean for the probability of dying? Is \\(e^{(-y)}\\) a large number if \\(y\\) is large? Luckily we have a calculator handy\n\n#exp(b) is e^b in R\n\nexp(-1)\n\n[1] 0.3678794\n\nexp(-10)\n\n[1] 4.539993e-05\n\nexp(-100)\n\n[1] 3.720076e-44\n\n\nWe see that \\(e^{(-y)}\\) becomes increasingly smaller with larger \\(y\\) which means that\n\\[ P(earlydeath == 1) = \\frac{1}{1+ small} \\sim \\frac{1}{1} \\]\nSo the larger \\(y\\) the smaller \\(e^{(-y)}\\) and the closer we get to \\(P(earlydeath == 1)\\) being 1. That was a lot of math for: If the coefficient is positive you increase the likelihood of getting the outcome, i.e. dying.",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "presentations/presentation5.html#clustering",
    "href": "presentations/presentation5.html#clustering",
    "title": "Presentation 5: Intro to Modelling in R",
    "section": "Clustering",
    "text": "Clustering",
    "crumbs": [
      "Course Material",
      "Presentations",
      "Presentation 5: Intro to Modelling in R"
    ]
  },
  {
    "objectID": "slides/Quarto_example.html",
    "href": "slides/Quarto_example.html",
    "title": "R for Data Science - How to Quarto",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "slides/Quarto_example.html#load-packages",
    "href": "slides/Quarto_example.html#load-packages",
    "title": "R for Data Science - How to Quarto",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "slides/Quarto_example.html#load-data",
    "href": "slides/Quarto_example.html#load-data",
    "title": "R for Data Science - How to Quarto",
    "section": "Load Data",
    "text": "Load Data\n\ndiabetes &lt;- read_excel('../data/diabetes_clinical_toy_messy.xlsx')"
  },
  {
    "objectID": "slides/Quarto_example.html#inspect-data",
    "href": "slides/Quarto_example.html#inspect-data",
    "title": "R for Data Science - How to Quarto",
    "section": "Inspect Data",
    "text": "Inspect Data\nCheck dimensions of data\n\ndim(diabetes)\n\n[1] 532   9\n\n\nCheck structure of data\n\nstr(diabetes)\n\ntibble [532 × 9] (S3: tbl_df/tbl/data.frame)\n $ ID              : num [1:532] 9046 51676 31112 60182 1665 ...\n $ Sex             : chr [1:532] \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ Age             : num [1:532] 34 25 30 50 27 35 31 52 54 41 ...\n $ BloodPressure   : num [1:532] 84 74 0 80 60 84 78 86 78 90 ...\n $ GeneticRisk     : num [1:532] 0.619 0.591 0.839 0.178 0.206 ...\n $ BMI             : num [1:532] 24.7 22.5 32.3 34.5 26.3 35 43.3 33.3 35.2 39.8 ...\n $ PhysicalActivity: num [1:532] 93 102 75 98 82 58 59 58 74 67 ...\n $ Smoker          : chr [1:532] \"Unknown\" \"Unknown\" \"Former\" \"Unknown\" ...\n $ Diabetes        : num [1:532] 0 0 1 1 0 1 1 1 1 1 ...\n\n\nCheck for NA’s in each column\n\ncolSums(is.na(diabetes))\n\n              ID              Sex              Age    BloodPressure \n               0                0                0                0 \n     GeneticRisk              BMI PhysicalActivity           Smoker \n               5                0                0                0 \n        Diabetes \n               0"
  },
  {
    "objectID": "slides/Quarto_example.html#exploratory-data-analysis",
    "href": "slides/Quarto_example.html#exploratory-data-analysis",
    "title": "R for Data Science - How to Quarto",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nPlot distribution of BMI\n\ndiabetes %&gt;% \n  ggplot(aes(x = BMI)) + \n  geom_histogram(bins = 10)"
  },
  {
    "objectID": "solutions/solution2.html",
    "href": "solutions/solution2.html",
    "title": "Exercise 2 - Solutions: Advanced Data Wrangling",
    "section": "",
    "text": "In this exercise you will do some more advance tidyverse operations such as pivoting and nesting.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 2 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution2.html#introduction",
    "href": "solutions/solution2.html#introduction",
    "title": "Exercise 2 - Solutions: Advanced Data Wrangling",
    "section": "",
    "text": "In this exercise you will do some more advance tidyverse operations such as pivoting and nesting.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 2 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution2.html#first-steps",
    "href": "solutions/solution2.html#first-steps",
    "title": "Exercise 2 - Solutions: Advanced Data Wrangling",
    "section": "First steps",
    "text": "First steps\n\nLoad packages.\n\n\nlibrary(tidyverse)\n\n\nLoad the joined diabetes data set you created in exercise 1 and the glucose dataset from the data folder.\n\n\ndiabetes_join &lt;- readxl::read_excel('../out/diabetes_join.xlsx')\ndf_glucose &lt;- readxl::read_excel('../data/df_glucose.xlsx')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 2 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution2.html#wrangling",
    "href": "solutions/solution2.html#wrangling",
    "title": "Exercise 2 - Solutions: Advanced Data Wrangling",
    "section": "Wrangling",
    "text": "Wrangling\n\nHave a look at the glucose dataset. It has three columns with measurements from a Oral Glucose Tolerance Test where blood glucose is measured at fasting (Glucose_0), 6 hours after glucose intake (Glucose_6), and 12 hours after (Glucose_12). The last columns is an ID column. Change the data type of the ID column to factor in both diabetes_join and df_glucose.\n\n\nhead(df_glucose)\n\n# A tibble: 6 × 4\n  Glucose_0 Glucose_60 Glucose_120    ID\n      &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1      6.65       8.04       10.0   9046\n2      4.49       5.40        6.22 51676\n3      5.76       6.52        7.22  1665\n4      6.13       6.94        8.09 12095\n5      6.84       6.92        7.01 12175\n6      6.84       7.62        8.42  8213\n\n\n\ndf_glucose$ID &lt;- as.factor(df_glucose$ID)\ndiabetes_join$ID &lt;- as.factor(diabetes_join$ID)\n\n\nRestructure the glucose dataset into a long format. Name the column that describes which measurement the row refers to, i.e. Glucose_0, Glucose_60 or Glucose_120, Measurement. How many rows are there per ID? Does that make sense?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember the flow:\n\npivot_longer(cols = LIST_WITH_COLUMNS_TO_PIVOT,\n             names_to = \"NEW_COLUMN_CONTAINING_COLUMN_NAMES\",\n             values_to = \"NEW_COLUMN_CONTAINING_COLUMN_VALUES\")\n\nHave a look at slide 16 for a visual overview.\n\n\n\n\ndf_glucose_long &lt;- df_glucose %&gt;% \n  pivot_longer(cols = starts_with(\"Glucose\"),\n               names_to = \"Measurement\",\n               values_to = \"Glucose (mmol/L)\"\n               )\n\nhead(df_glucose_long)\n\n# A tibble: 6 × 3\n  ID    Measurement `Glucose (mmol/L)`\n  &lt;fct&gt; &lt;chr&gt;                    &lt;dbl&gt;\n1 9046  Glucose_0                 6.65\n2 9046  Glucose_60                8.04\n3 9046  Glucose_120              10.0 \n4 51676 Glucose_0                 4.49\n5 51676 Glucose_60                5.40\n6 51676 Glucose_120               6.22\n\n\nThere are three rows for each ID, corresponding to the three glucose measurements\n\ndf_glucose_long %&gt;%\n  count(ID) %&gt;%\n  head()\n\n# A tibble: 6 × 2\n  ID        n\n  &lt;fct&gt; &lt;int&gt;\n1 129       3\n2 210       3\n3 491       3\n4 530       3\n5 621       3\n6 712       3\n\n\n\nIn your long format dataframe you should have one column that described which measurement the row refers to, i.e. Glucose_0, Glucose_60 or Glucose_120. Transform this column so that you only have the numerical part, i.e. only 0, 60 or 120. Then change the data type of that column to factor. Check the order of the factor levels and if necessary change them to the proper order.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe stringr packages is a part of tidyverse and has many functions for manipulating strings. Find a function that can split the string so you can extract the numbers on the other side of the underscore.\nHave a look at the help for factors ?factors to see how to influence the levels.\n\n\n\n\ndf_glucose_long &lt;- df_glucose_long %&gt;% \n  mutate(Measurement = str_split_i(Measurement, '_', 2) %&gt;% as.factor())\n\nhead(df_glucose_long)\n\n# A tibble: 6 × 3\n  ID    Measurement `Glucose (mmol/L)`\n  &lt;fct&gt; &lt;fct&gt;                    &lt;dbl&gt;\n1 9046  0                         6.65\n2 9046  60                        8.04\n3 9046  120                      10.0 \n4 51676 0                         4.49\n5 51676 60                        5.40\n6 51676 120                       6.22\n\n\nCheck factor levels:\n\nlevels(df_glucose_long$Measurement)\n\n[1] \"0\"   \"120\" \"60\" \n\n\nAdjust levels to proper order:\n\ndf_glucose_long$Measurement &lt;- factor(df_glucose_long$Measurement, levels = c('0', '60','120'))\n\n\nMerge the glucose dataset with the joined diabetes dataset.\n\n\ndiabetes_glucose &lt;- diabetes_join %&gt;% \n  left_join(df_glucose_long, by = 'ID')\n\nhead(diabetes_glucose)\n\n# A tibble: 6 × 13\n  ID    Sex     Age BloodPressure GeneticRisk   BMI PhysicalActivity Smoker \n  &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  \n1 9046  Male     34            84       0.619  24.7               93 Unknown\n2 9046  Male     34            84       0.619  24.7               93 Unknown\n3 9046  Male     34            84       0.619  24.7               93 Unknown\n4 51676 Male     25            74       0.591  22.5              102 Unknown\n5 51676 Male     25            74       0.591  22.5              102 Unknown\n6 51676 Male     25            74       0.591  22.5              102 Unknown\n# ℹ 5 more variables: Diabetes &lt;chr&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;,\n#   Measurement &lt;fct&gt;, `Glucose (mmol/L)` &lt;dbl&gt;\n\n\n\nPull the glucose measurements from your favorite ID.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFirst filter for your favorite ID and then pull the columns.\n\n\n\n\ndiabetes_glucose %&gt;% \n  filter(ID == 9046) %&gt;% \n  pull(Measurement,`Glucose (mmol/L)`)\n\n  6.652593325614 8.04416787019778  10.016298115626 \n               0               60              120 \nLevels: 0 60 120\n\n\n\nCalculate the mean glucose measure for each measurement timepoint.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use group_by(), and summarise().\n\n\n\n\ndiabetes_glucose %&gt;%\n  group_by(Measurement) %&gt;%\n  summarise(mean = mean(`Glucose (mmol/L)`))\n\n# A tibble: 3 × 2\n  Measurement  mean\n  &lt;fct&gt;       &lt;dbl&gt;\n1 0            8.06\n2 60           9.74\n3 120         11.1 \n\n\n\nCalculate mean and standard deviation for all numeric columns.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use summarise() and across(), selecting numeric columns.\n\n\n\n\ndiabetes_glucose %&gt;%\n  summarise(across(where(is.numeric), list(mean=mean, sd=sd), \n                   .names = \"{.col}-{.fn}\"))\n\n# A tibble: 1 × 12\n  `Age-mean` `Age-sd` `BloodPressure-mean` `BloodPressure-sd` `GeneticRisk-mean`\n       &lt;dbl&gt;    &lt;dbl&gt;                &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1       33.8     11.4                 72.7               12.9                 NA\n# ℹ 7 more variables: `GeneticRisk-sd` &lt;dbl&gt;, `BMI-mean` &lt;dbl&gt;, `BMI-sd` &lt;dbl&gt;,\n#   `PhysicalActivity-mean` &lt;dbl&gt;, `PhysicalActivity-sd` &lt;dbl&gt;,\n#   `Glucose (mmol/L)-mean` &lt;dbl&gt;, `Glucose (mmol/L)-sd` &lt;dbl&gt;\n\n\n\nNest the glucose measurements and values such that there is only one row per ID and call the nested column OGTT (Oral Glucose Tolerance Test). Display the resulting tibble to confirm that you have succeeded.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember the flow:\n\ngroup_by() %&gt;% \n  nest() %&gt;% \n  ungroup()\n\n\n\n\n\ndiabetes_glucose &lt;- diabetes_glucose %&gt;% \n  group_by(ID) %&gt;% \n  nest(OGTT = c(Measurement, `Glucose (mmol/L)`)) %&gt;% \n  ungroup()\n  \n#relocate the new nested column to after BMI so we can actually see it\nhead(relocate(diabetes_glucose, OGTT, .after = BMI))\n\n# A tibble: 6 × 12\n  ID    Sex      Age BloodPressure GeneticRisk   BMI OGTT     PhysicalActivity\n  &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;              &lt;dbl&gt;\n1 9046  Male      34            84       0.619  24.7 &lt;tibble&gt;               93\n2 51676 Male      25            74       0.591  22.5 &lt;tibble&gt;              102\n3 60182 Male      50            80       0.178  34.5 &lt;tibble&gt;               98\n4 1665  Female    27            60       0.206  26.3 &lt;tibble&gt;               82\n5 56669 Male      35            84       0.286  35   &lt;tibble&gt;               58\n6 53882 Female    31            78       1.22   43.3 &lt;tibble&gt;               59\n# ℹ 4 more variables: Smoker &lt;chr&gt;, Diabetes &lt;chr&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;\n\n\n\nExport the final dataset. Since the dataset is nested, you cannot export it as an excel file. Export the dataset as an .rds file. Have a guess at what the function is called.\n\n\nwrite_rds(diabetes_glucose, '../out/diabetes_glucose.rds')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 2 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html",
    "href": "solutions/solution4.html",
    "title": "Exercise 4 - Solutions",
    "section": "",
    "text": "In this exercise you will practice your scripting.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#getting-started",
    "href": "solutions/solution4.html#getting-started",
    "title": "Exercise 4 - Solutions",
    "section": "Getting started",
    "text": "Getting started\nLoad libaries and data\n\nlibrary(tidyverse)\nlibrary(glue)\n\n\ndiabetes_glucose &lt;- read_rds('../out/diabetes_glucose.rds')\ndiabetes_glucose\n\n# A tibble: 493 × 12\n   ID    Sex      Age BloodPressure GeneticRisk   BMI PhysicalActivity Smoker \n   &lt;fct&gt; &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  \n 1 9046  Male      34            84       0.619  24.7               93 Unknown\n 2 51676 Male      25            74       0.591  22.5              102 Unknown\n 3 60182 Male      50            80       0.178  34.5               98 Unknown\n 4 1665  Female    27            60       0.206  26.3               82 Never  \n 5 56669 Male      35            84       0.286  35                 58 Smoker \n 6 53882 Female    31            78       1.22   43.3               59 Smoker \n 7 10434 Male      52            86       1.15   33.3               58 Never  \n 8 27419 Female    54            78       0.692  35.2               74 Former \n 9 60491 Female    41            90       0.451  39.8               67 Smoker \n10 12109 Female    36            82       0.18   30.8               81 Smoker \n# ℹ 483 more rows\n# ℹ 4 more variables: Diabetes &lt;chr&gt;, Married &lt;chr&gt;, Work &lt;chr&gt;, OGTT &lt;list&gt;",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#if-else-statements",
    "href": "solutions/solution4.html#if-else-statements",
    "title": "Exercise 4 - Solutions",
    "section": "If-else statements",
    "text": "If-else statements\nIn these exercises we don’t use the dataframe yet, that comes later when we have loops. For this part, just declare variables to test your statements, e.g. bp &lt;- 120.\n\nWrite an if-else statement that prints whether a person has high (more than 100), low (lower than 50) or normal blood pressure (between 50 and 100).\n\n\nbp &lt;- 80\n\nif (bp &gt; 100){\n  print('High blood pressure')\n} else if (bp &lt; 50) {\n  print('Low blood pressure')\n} else {\n  print('Normal blood pressure')\n} \n\n[1] \"Normal blood pressure\"\n\n\n\nWrite an if-else statement that assigns people high, moderate or low diabetes risk based on their genetic risk score and BMI:\n\n\ngenetic Risk greater than 1 and BMI greater than 35 -&gt; high risk\ngenetic Risk greater than 1 or BMI greater than 35 -&gt; moderate risk\notherwise low risk\n\nVerify that your statement works for different combinations of risk score and BMI\n\nrisk &lt;- 0.9\nBMI &lt;- 40\n\nif (risk &gt; 1 & BMI &gt; 35){\n  print('High risk')\n} else if (risk &gt; 1 | BMI &gt; 35) {\n  print('Moderate risk')\n} else {\n  print('Low risk')\n}\n\n[1] \"Moderate risk\"",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#loops",
    "href": "solutions/solution4.html#loops",
    "title": "Exercise 4 - Solutions",
    "section": "Loops",
    "text": "Loops\n\nCreate a vector with at least 5 elements and loop over it.\n\n\nmy_v &lt;- c(1, 78, 5, 'hello', 7)\n\nfor (el in my_v) {\n  print(el)\n}\n\n[1] \"1\"\n[1] \"78\"\n[1] \"5\"\n[1] \"hello\"\n[1] \"7\"\n\n\n\nLoop over all column names of diabetes_glucose.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncolnames(df) creates a vector of column names.\n\n\n\n\nfor (col in colnames(diabetes_glucose)) {\n  print(col)\n}\n\n[1] \"ID\"\n[1] \"Sex\"\n[1] \"Age\"\n[1] \"BloodPressure\"\n[1] \"GeneticRisk\"\n[1] \"BMI\"\n[1] \"PhysicalActivity\"\n[1] \"Smoker\"\n[1] \"Diabetes\"\n[1] \"Married\"\n[1] \"Work\"\n[1] \"OGTT\"\n\n\n\nLoop over all rows of diabetes_glucose and determine whether the person’s blood pressure is high, low or normal with the same conditions as in 1.\n\n\n#We'll only show the first 10 rows here for brevity\n#for (i in 1:nrow(diabetes_glucose)) {\n\nfor (i in 1:10) {\n  bp &lt;- diabetes_glucose$BloodPressure[i]\n\n  if (bp &gt; 100){\n    print('High blood pressure')\n  } else if (bp &lt; 50) {\n    print('Low blood pressure')\n  } else {\n    print('Normal blood pressure')\n  } \n}\n\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n[1] \"Normal blood pressure\"\n\n\n\nLoop over all rows of diabetes_glucose and determine the risk based on genetic risk score and BMI, with the same conditions as in 2. Print the genetic risk score and BMI as well as the risk level to make it easier to see whether your code works correctly.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAn easy way to printing several variables is to pass a vector into print: print(c(this,and_that,and_this_too))\n\n\n\n\n#We'll only show the first 10 rows here for brevity\n#for (i in 1:nrow(diabetes_glucose)) {\n\nfor (i in 1:10) {\n  risk &lt;- diabetes_glucose$GeneticRisk[i]\n  BMI &lt;- diabetes_glucose$BMI[i]\n  \n  #skip rows where either of the values is NA\n  if (is.na(risk) | is.na(BMI)){\n    next\n  }\n    \n  if (risk &gt; 1 & BMI &gt; 35){\n    print(c(risk, BMI, 'High risk'))\n  } else if (risk &gt; 1 | BMI &gt; 35) {\n    print(c(risk, BMI,'Moderate risk'))\n  } else {\n    print(c(risk, BMI,'Low risk'))\n  }\n}",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#user-defined-functions",
    "href": "solutions/solution4.html#user-defined-functions",
    "title": "Exercise 4 - Solutions",
    "section": "User defined Functions",
    "text": "User defined Functions\nIn this part we will write some functions that create plots.\nSince we want to be able to pass the name of the column to plot as a variable we will need to use the syntax for aliased column names. We showed how to do that in the end of presentation 3 if you need a refresher.\n\nCreate a variable plot_column and assign “Age” to it. Now make a boxplot of that column. Switch plot_column to a different column in diabetes_glucose. Does it work?\n\n\n#the column we want to plot\nplot_column &lt;- 'Age'\n\n#make the plot\nggplot(diabetes_glucose, aes(y = .data[[plot_column]])) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nWrap your code for the boxplot into a function. The function should take two arguments: the dataframe to use and the name of the column to plot. Test your function. Add some customization to the plot like a theme of colors.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFunctions are good at returning objects so make your plot into an object and return that.\n\n\n\n\nmake_boxplot &lt;- function(df, plot_column){\n  \n  p &lt;- ggplot(df, aes(y = .data[[plot_column]])) +\n    geom_boxplot(fill = \"#03579A\") +\n    labs(title = paste(\"Boxplot of\", plot_column)) + \n    theme_bw()\n  \n  return(p)\n  \n}\n\nmake_boxplot(diabetes_glucose, 'Age')\n\n\n\n\n\n\n\n\n\nAdd a check to your function whether the supplied column is numeric. Note here that you need to test the data type of the column you want to plot, not the data type of it’s name. Confirm that your check works.\n\n\nmake_boxplot &lt;- function(df, plot_column){\n  \n  if (!is.numeric(df[[plot_column]])){\n    stop('The column to plot must be numcerial.')\n  }\n  \n  p &lt;- ggplot(df, aes(y = .data[[plot_column]])) +\n    geom_boxplot(fill = \"#03579A\") +\n    labs(title = paste(\"Boxplot of\", plot_column)) + \n    theme_bw()\n  \n  return(p)\n  \n}\n\nmake_boxplot(diabetes_glucose, 'Sex')\n\nError in make_boxplot(diabetes_glucose, \"Sex\"): The column to plot must be numcerial.\n\n\n\nWrite code to apply your boxplot function to each numerical column in the dataframe. There are different ways to achieve this.\n\n\n# Our Idea: Find names of all numeric columns and plug them into a for loop\n\nnum_cols &lt;- diabetes_glucose %&gt;%\n  select(where(is.numeric)) %&gt;%\n  colnames()\n\n#check if correct columns found\nnum_cols\n\n[1] \"Age\"              \"BloodPressure\"    \"GeneticRisk\"      \"BMI\"             \n[5] \"PhysicalActivity\"\n\n#iterate over numeric columns and display plots\nfor(col in num_cols){\n  my_plot &lt;- make_boxplot(diabetes_glucose, col)\n  print(my_plot)\n  #alternative: if you want to extport the plots to files use something like:\n  #ggsave(paste0('../figures/boxplot_diabetes_',col,'.png'), width = 7, height = 5)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate an R script file to contain your functions. Copy your functions there and remove them from your global environment with rm(list=\"name_of_your_function\"). Now source the function R script in your quarto document and test that the functions work.\n\n\n#remove function from global environment so we can test if it loads properly from the script\nrm(list = \"make_boxplot\")\n\n\nsource('solution4_functions.R')\n\n\nmake_boxplot(diabetes_glucose, 'Age')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution4.html#extra-exercises",
    "href": "solutions/solution4.html#extra-exercises",
    "title": "Exercise 4 - Solutions",
    "section": "Extra exercises",
    "text": "Extra exercises\nFirst, unnest diabetes_glucose so you get back the Measurement and Glucose columns.\n\ndiabetes_glucose_unnest &lt;- diabetes_glucose %&gt;%\n  unnest(OGTT)\n\ne1. Calculate the mean Glucose (mmol/L) for each measuring time point (i.e. one value for 0, 60 and 120). Now stratify this mean by a second variable, Sex. You should have 6 mean values since there are 6 groups (0_female, 0_male, 60_female, ect). Now, create a variable category to which you pass the name of the column to stratify by (e.g. category &lt;- 'Sex') and use category in your code instead of the literal variable name.\n\ncategory &lt;- 'Sex'\n\nglucose_group_mean &lt;- diabetes_glucose_unnest %&gt;%\n  group_by(Measurement, .data[[category]]) %&gt;%\n  summarize(glucose_mean = mean(`Glucose (mmol/L)`), .groups = \"drop\")\n\nglucose_group_mean\n\n# A tibble: 6 × 3\n  Measurement Sex    glucose_mean\n  &lt;fct&gt;       &lt;chr&gt;         &lt;dbl&gt;\n1 0           Female         8.10\n2 0           Male           8.01\n3 60          Female         9.71\n4 60          Male           9.77\n5 120         Female        11.0 \n6 120         Male          11.2 \n\n\ne2. We would like to make a plot that shows the means you calculated above. Again, use your category variable instead of the literal column name.\n\nglucose_group_mean %&gt;%\n    ggplot(aes(x = Measurement,\n               y = glucose_mean, \n               color = .data[[category]],\n               group = .data[[category]])) +\n    geom_point() +\n    geom_line()\n\n\n\n\n\n\n\n\ne3. Wrap the code from e1 and e2 into a function show_mean_by_catergory so that you can call: show_mean_by_catergory(diabetes_glucose_unnest, 'Sex') and it will make you the plot. Test with different columns.\n\nshow_mean_by_catergory &lt;- function(df,category){\n  \n  glucose_group_mean &lt;- df %&gt;%\n    group_by(Measurement, .data[[category]]) %&gt;%\n    summarize(glucose_mean = mean(`Glucose (mmol/L)`), .groups = \"drop\")\n  \n  p &lt;-glucose_group_mean %&gt;%\n    ggplot(aes(x = Measurement,\n               y = glucose_mean, \n               color = .data[[category]],\n               group = .data[[category]])) +\n    geom_point() +\n    geom_line()\n  \n  return(p)\n}\n\n\nshow_mean_by_catergory(diabetes_glucose_unnest, 'Smoker')",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 4 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution5.html",
    "href": "solutions/solution5.html",
    "title": "Exercise 5 - Solutions",
    "section": "",
    "text": "Load packages\nlibrary(tidyverse)\nlibrary(ModelMetrics)",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 5 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution5.html#part-1-linear-regression",
    "href": "solutions/solution5.html#part-1-linear-regression",
    "title": "Exercise 5 - Solutions",
    "section": "Part 1: Linear regression",
    "text": "Part 1: Linear regression\n\nLoad the data boston.csv\n\n\ndf &lt;- read.csv('../data/boston.csv')\nhead(df)\n\n     crim indus   nox    rm medv neighborhood\n1 0.00632  2.31 0.538 6.575 24.0     Suburban\n2 0.02731  7.07 0.469 6.421 21.6        Urban\n3 0.02729  7.07 0.469 7.185 34.7        Rural\n4 0.03237  2.18 0.458 6.998 33.4        Urban\n5 0.06905  2.18 0.458 7.147 36.2     Suburban\n6 0.02985  2.18 0.458 6.430 28.7     Suburban\n\n\n\nNeighborhood is a categorical variable. We could make it a factor but it will also work as a character column (in the case of using lm).\nSplit the dataset into test and training data.\n\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\n#add an ID column to keep track of observations\ndf$ID &lt;- 1:nrow(df)\n\ntrain &lt;- df %&gt;% sample_frac(.75)\ntest  &lt;- anti_join(df, train, by = 'ID') \n\n\nFit the model\n\n\nmodel &lt;- lm(medv ~ rm + crim + neighborhood, data = train)\n\n\nsummary(model)\n\n\nCall:\nlm(formula = medv ~ rm + crim + neighborhood, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.920  -3.167  -0.468   2.746  35.052 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -25.52560    3.08810  -8.266 2.43e-15 ***\nrm                     7.63165    0.49122  15.536  &lt; 2e-16 ***\ncrim                  -0.22845    0.03525  -6.482 2.86e-10 ***\nneighborhoodSuburban   0.07995    0.75050   0.107    0.915    \nneighborhoodUrban      3.66323    0.84058   4.358 1.70e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.183 on 375 degrees of freedom\nMultiple R-squared:  0.5573,    Adjusted R-squared:  0.5525 \nF-statistic:   118 on 4 and 375 DF,  p-value: &lt; 2.2e-16\n\n\n\nrm and crim have a significant influence on the house price. An increase in the number of rooms increases the price since the coefficient is positive, whereas an increase in crime rate reduces the price. There is a significant difference in price between Rural and Urban zones, but not between Rural and Suburban. Rural is the reference level. Lastly, houses with 0 rooms cost -25k dollar. Perhaps the predictors should be centered before fitting the model around 0 so rm == 0 is the average number of rooms for better interpretability.\nScale the numeric predictor columns and redo the modelling. What has changed?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThere is a scale function, see ?scale().\n\n\n\n\ndf &lt;- df %&gt;%\n  mutate(across(where(is.numeric), scale, .names = \"standardized_{.col}\"))\n\ndf\n\n        crim indus    nox    rm medv neighborhood  ID standardized_crim\n1    0.00632  2.31 0.5380 6.575 24.0     Suburban   1      -0.419366929\n2    0.02731  7.07 0.4690 6.421 21.6        Urban   2      -0.416926670\n3    0.02729  7.07 0.4690 7.185 34.7        Rural   3      -0.416928995\n4    0.03237  2.18 0.4580 6.998 33.4        Urban   4      -0.416338404\n5    0.06905  2.18 0.4580 7.147 36.2     Suburban   5      -0.412074053\n6    0.02985  2.18 0.4580 6.430 28.7     Suburban   6      -0.416631374\n7    0.08829  7.87 0.5240 6.012 22.9        Rural   7      -0.409837246\n8    0.14455  7.87 0.5240 6.172 27.1        Urban   8      -0.403296561\n9    0.21124  7.87 0.5240 5.631 16.5     Suburban   9      -0.395543302\n10   0.17004  7.87 0.5240 6.004 18.9        Rural  10      -0.400333140\n11   0.22489  7.87 0.5240 6.377 15.0        Urban  11      -0.393956378\n12   0.11747  7.87 0.5240 6.009 18.9        Rural  12      -0.406444832\n13   0.09378  7.87 0.5240 5.889 21.7        Rural  13      -0.409198989\n14   0.62976  8.14 0.5380 5.949 20.4        Rural  14      -0.346886928\n15   0.63796  8.14 0.5380 6.096 18.2        Rural  15      -0.345933611\n16   0.62739  8.14 0.5380 5.834 19.9     Suburban  16      -0.347162460\n17   1.05393  8.14 0.5380 5.935 23.1     Suburban  17      -0.297573695\n18   0.78420  8.14 0.5380 5.990 17.5        Rural  18      -0.328932014\n19   0.80271  8.14 0.5380 5.456 20.2     Suburban  19      -0.326780075\n20   0.72580  8.14 0.5380 5.727 18.2        Urban  20      -0.335721492\n21   1.25179  8.14 0.5380 5.570 13.6     Suburban  21      -0.274570851\n22   0.85204  8.14 0.5380 5.965 19.6     Suburban  22      -0.321045059\n23   1.23247  8.14 0.5380 6.142 15.2     Suburban  23      -0.276816959\n24   0.98843  8.14 0.5380 5.813 14.5        Urban  24      -0.305188606\n25   0.75026  8.14 0.5380 5.924 15.6     Suburban  25      -0.332877817\n26   0.84054  8.14 0.5380 5.599 13.9     Suburban  26      -0.322382028\n27   0.67191  8.14 0.5380 5.813 16.6     Suburban  27      -0.341986646\n28   0.95577  8.14 0.5380 6.047 14.8     Suburban  28      -0.308985598\n29   0.77299  8.14 0.5380 6.495 18.4        Rural  29      -0.330235268\n30   1.00245  8.14 0.5380 6.674 21.0     Suburban  30      -0.303558666\n31   1.13081  8.14 0.5380 5.713 12.7        Urban  31      -0.288635766\n32   1.35472  8.14 0.5380 6.072 14.5        Urban  32      -0.262604396\n33   1.38799  8.14 0.5380 5.950 13.2     Suburban  33      -0.258736486\n34   1.15172  8.14 0.5380 5.701 13.1     Suburban  34      -0.286204807\n35   1.61282  8.14 0.5380 6.096 13.5        Rural  35      -0.232598159\n36   0.06417  5.96 0.4990 5.933 18.9        Rural  36      -0.412641393\n37   0.09744  5.96 0.4990 5.841 20.0     Suburban  37      -0.408773484\n38   0.08014  5.96 0.4990 5.850 21.0     Suburban  38      -0.410784750\n39   0.17505  5.96 0.4990 5.966 24.7     Suburban  39      -0.399750686\n40   0.02763  2.95 0.4280 6.595 30.8     Suburban  40      -0.416889467\n41   0.03359  2.95 0.4280 7.024 34.9     Suburban  41      -0.416196569\n42   0.12744  6.91 0.4480 6.770 26.6        Rural  42      -0.405285738\n43   0.14150  6.91 0.4480 6.169 25.3        Rural  43      -0.403651148\n44   0.15936  6.91 0.4480 6.211 24.7     Suburban  44      -0.401574777\n45   0.12269  6.91 0.4480 6.069 21.2     Suburban  45      -0.405837965\n46   0.17142  6.91 0.4480 5.682 19.3        Rural  46      -0.400172703\n47   0.18836  6.91 0.4480 5.786 20.0        Rural  47      -0.398203290\n48   0.22927  6.91 0.4480 6.030 16.6        Rural  48      -0.393447167\n49   0.25387  6.91 0.4480 5.399 14.4        Rural  49      -0.390587216\n50   0.21977  6.91 0.4480 5.602 19.4     Suburban  50      -0.394551620\n51   0.08873  5.64 0.4390 5.963 19.7        Rural  51      -0.409786092\n52   0.04337  5.64 0.4390 6.115 20.5        Rural  52      -0.415059564\n53   0.05360  5.64 0.4390 6.511 25.0        Urban  53      -0.413870242\n54   0.04981  5.64 0.4390 5.998 23.4     Suburban  54      -0.414310861\n55   0.01360  4.00 0.4100 5.888 18.9     Suburban  55      -0.418520570\n56   0.01311  1.22 0.4030 7.249 35.4        Urban  56      -0.418577536\n57   0.02055  0.74 0.4100 6.383 24.7     Suburban  57      -0.417712575\n58   0.01432  1.32 0.4110 6.816 31.6        Urban  58      -0.418436864\n59   0.15445  5.13 0.4530 6.145 23.3        Urban  59      -0.402145605\n60   0.10328  5.13 0.4530 5.927 19.6        Rural  60      -0.408094536\n61   0.14932  5.13 0.4530 5.741 18.7     Suburban  61      -0.402742009\n62   0.17171  5.13 0.4530 5.966 16.0        Rural  62      -0.400138988\n63   0.11027  5.13 0.4530 6.456 22.2     Suburban  63      -0.407281891\n64   0.12650  5.13 0.4530 6.762 25.0     Suburban  64      -0.405395021\n65   0.01951  1.38 0.4161 7.104 33.0        Urban  65      -0.417833484\n66   0.03584  3.37 0.3980 6.290 23.5        Rural  66      -0.415934988\n67   0.04379  3.37 0.3980 5.787 19.4     Suburban  67      -0.415010735\n68   0.05789  6.07 0.4090 5.878 22.0        Urban  68      -0.413371495\n69   0.13554  6.07 0.4090 5.594 17.4     Suburban  69      -0.404344047\n70   0.12816  6.07 0.4090 5.885 20.9        Rural  70      -0.405202032\n71   0.08826 10.81 0.4130 6.417 24.2        Urban  71      -0.409840734\n72   0.15876 10.81 0.4130 5.961 21.7        Rural  72      -0.401644532\n73   0.09164 10.81 0.4130 6.065 22.8        Urban  73      -0.409447781\n74   0.19539 10.81 0.4130 6.245 23.4     Suburban  74      -0.397385995\n75   0.07896 12.83 0.4370 6.273 24.1        Rural  75      -0.410921935\n76   0.09512 12.83 0.4370 6.286 21.4     Suburban  76      -0.409043203\n77   0.10153 12.83 0.4370 6.279 20.0        Rural  77      -0.408297988\n78   0.08707 12.83 0.4370 6.140 20.8        Rural  78      -0.409979081\n79   0.05646 12.83 0.4370 6.232 21.2     Suburban  79      -0.413537744\n80   0.08387 12.83 0.4370 5.874 20.3     Suburban  80      -0.410351107\n81   0.04113  4.86 0.4260 6.727 28.0     Suburban  81      -0.415319982\n82   0.04462  4.86 0.4260 6.619 23.9        Rural  82      -0.414914241\n83   0.03659  4.86 0.4260 6.302 24.8        Rural  83      -0.415847794\n84   0.03551  4.86 0.4260 6.167 22.9        Urban  84      -0.415973353\n85   0.05059  4.49 0.4490 6.389 23.9     Suburban  85      -0.414220179\n86   0.05735  4.49 0.4490 6.630 26.6        Rural  86      -0.413434274\n87   0.05188  4.49 0.4490 6.015 22.5        Urban  87      -0.414070206\n88   0.07151  4.49 0.4490 6.121 22.2        Urban  88      -0.411788058\n89   0.05660  3.41 0.4890 7.007 23.6        Urban  89      -0.413521468\n90   0.05302  3.41 0.4890 7.079 28.7     Suburban  90      -0.413937672\n91   0.04684  3.41 0.4890 6.417 22.6     Suburban  91      -0.414656148\n92   0.03932  3.41 0.4890 6.405 22.0        Rural  92      -0.415530409\n93   0.04203 15.04 0.4640 6.442 22.9     Suburban  93      -0.415215350\n94   0.02875 15.04 0.4640 6.211 25.0        Rural  94      -0.416759258\n95   0.04294 15.04 0.4640 6.249 20.6     Suburban  95      -0.415109555\n96   0.12204  2.89 0.4450 6.625 28.4     Suburban  96      -0.405913532\n97   0.11504  2.89 0.4450 6.163 21.4        Urban  97      -0.406727340\n98   0.12083  2.89 0.4450 8.069 38.7        Urban  98      -0.406054205\n99   0.08187  2.89 0.4450 7.820 43.8        Urban  99      -0.410583624\n100  0.06860  2.89 0.4450 7.416 33.2        Rural 100      -0.412126370\n101  0.14866  8.56 0.5200 6.727 27.5        Rural 101      -0.402818740\n102  0.11432  8.56 0.5200 6.781 26.5     Suburban 102      -0.406811046\n103  0.22876  8.56 0.5200 6.405 18.6        Rural 103      -0.393506459\n104  0.21161  8.56 0.5200 6.137 19.3        Urban 104      -0.395500287\n105  0.13960  8.56 0.5200 6.167 20.1        Rural 105      -0.403872039\n106  0.13262  8.56 0.5200 5.851 19.5     Suburban 106      -0.404683521\n107  0.17120  8.56 0.5200 5.836 19.5        Urban 107      -0.400198280\n108  0.13117  8.56 0.5200 6.127 20.4        Rural 108      -0.404852095\n109  0.12802  8.56 0.5200 6.474 19.8        Rural 109      -0.405218308\n110  0.26363  8.56 0.5200 6.229 19.4        Rural 110      -0.389452536\n111  0.10793  8.56 0.5200 6.195 21.7        Urban 111      -0.407553935\n112  0.10084 10.01 0.5470 6.715 22.8     Suburban 112      -0.408378206\n113  0.12329 10.01 0.5470 5.913 18.8        Rural 113      -0.405768210\n114  0.22212 10.01 0.5470 6.092 18.7        Urban 114      -0.394278413\n115  0.14231 10.01 0.5470 6.254 18.5     Suburban 115      -0.403556979\n116  0.17134 10.01 0.5470 5.928 18.3        Rural 116      -0.400182004\n117  0.13158 10.01 0.5470 6.176 21.2        Rural 117      -0.404804429\n118  0.15098 10.01 0.5470 6.021 19.2        Urban 118      -0.402549021\n119  0.13058 10.01 0.5470 5.872 20.4        Rural 119      -0.404920687\n120  0.14476 10.01 0.5470 5.731 19.3        Rural 120      -0.403272146\n121  0.06899 25.65 0.5810 5.870 22.0        Rural 121      -0.412081029\n122  0.07165 25.65 0.5810 6.004 20.3     Suburban 122      -0.411771782\n123  0.09299 25.65 0.5810 5.961 20.5     Suburban 123      -0.409290833\n124  0.15038 25.65 0.5810 5.856 17.3        Rural 124      -0.402618775\n125  0.09849 25.65 0.5810 5.879 18.8        Rural 125      -0.408651413\n126  0.16902 25.65 0.5810 5.986 21.4        Urban 126      -0.400451723\n127  0.38735 25.65 0.5810 5.613 15.7        Rural 127      -0.375069074\n128  0.25915 21.89 0.6240 5.693 16.2        Rural 128      -0.389973373\n129  0.32543 21.89 0.6240 6.431 18.0        Rural 129      -0.382267781\n130  0.88125 21.89 0.6240 5.637 14.3     Suburban 130      -0.317649158\n131  0.34006 21.89 0.6240 6.458 19.2     Suburban 131      -0.380566923\n132  1.19294 21.89 0.6240 6.326 19.6     Suburban 132      -0.281412645\n133  0.59005 21.89 0.6240 6.372 23.0        Rural 133      -0.351503540\n134  0.32982 21.89 0.6240 5.822 18.4     Suburban 134      -0.381757407\n135  0.97617 21.89 0.6240 5.757 15.6     Suburban 135      -0.306613931\n136  0.55778 21.89 0.6240 6.335 18.1     Suburban 136      -0.355255192\n137  0.32264 21.89 0.6240 5.942 17.4     Suburban 137      -0.382592141\n138  0.35233 21.89 0.6240 6.454 17.1     Suburban 138      -0.379140436\n139  0.24980 21.89 0.6240 5.857 13.3        Urban 139      -0.391060387\n140  0.54452 21.89 0.6240 6.151 17.8        Rural 140      -0.356796775\n141  0.29090 21.89 0.6240 6.174 14.0        Rural 141      -0.386282176\n142  1.62864 21.89 0.6240 5.019 14.4        Rural 142      -0.230758955\n143  3.32105 19.58 0.8710 5.403 13.4        Rural 143      -0.034002444\n144  4.09740 19.58 0.8710 5.468 15.6        Rural 144       0.056254596\n145  2.77974 19.58 0.8710 4.903 11.8     Suburban 145      -0.096934161\n146  2.37934 19.58 0.8710 6.130 13.8        Rural 146      -0.143483937\n147  2.15505 19.58 0.8710 5.628 15.6        Rural 147      -0.169559485\n148  2.36862 19.58 0.8710 4.926 14.6        Rural 148      -0.144730225\n149  2.33099 19.58 0.8710 5.186 17.8        Rural 149      -0.149105020\n150  2.73397 19.58 0.8710 5.597 15.4     Suburban 150      -0.102255298\n151  1.65660 19.58 0.8710 6.122 21.5        Urban 151      -0.227508376\n152  1.49632 19.58 0.8710 5.404 19.6        Rural 152      -0.246142237\n153  1.12658 19.58 0.8710 5.012 15.3        Rural 153      -0.289127538\n154  2.14918 19.58 0.8710 5.709 19.4        Rural 154      -0.170241920\n155  1.41385 19.58 0.8710 6.129 17.0        Rural 155      -0.255730050\n156  3.53501 19.58 0.8710 6.152 15.6        Rural 156      -0.009127843\n157  2.44668 19.58 0.8710 5.272 13.1     Suburban 157      -0.135655111\n158  1.22358 19.58 0.6050 6.943 41.3        Urban 158      -0.277850494\n159  1.34284 19.58 0.6050 6.066 24.3        Rural 159      -0.263985543\n160  1.42502 19.58 0.8710 6.510 23.3     Suburban 160      -0.254431446\n161  1.27346 19.58 0.6050 6.250 27.0        Rural 161      -0.272051536\n162  1.46336 19.58 0.6050 7.489 50.0        Urban 162      -0.249974107\n163  1.83377 19.58 0.6050 7.802 50.0        Urban 163      -0.206910914\n164  1.51902 19.58 0.6050 8.375 50.0        Urban 164      -0.243503177\n165  2.24236 19.58 0.6050 5.854 22.7     Suburban 165      -0.159408983\n166  2.92400 19.58 0.6050 6.101 25.0        Rural 166      -0.080162756\n167  2.01019 19.58 0.6050 7.929 50.0        Urban 167      -0.186400645\n168  1.80028 19.58 0.6050 5.877 23.8     Suburban 168      -0.210804400\n169  2.30040 19.58 0.6050 6.319 23.8        Rural 169      -0.152661358\n170  2.44953 19.58 0.6050 6.402 22.3     Suburban 170      -0.135323775\n171  1.20742 19.58 0.6050 5.875 17.4     Suburban 171      -0.279729226\n172  2.31390 19.58 0.6050 5.880 19.1        Rural 172      -0.151091873\n173  0.13914  4.05 0.5100 5.572 23.1        Urban 173      -0.403925517\n174  0.09178  4.05 0.5100 6.416 23.6        Urban 174      -0.409431505\n175  0.08447  4.05 0.5100 5.859 22.6        Rural 175      -0.410281352\n176  0.06664  4.05 0.5100 6.546 29.4        Rural 176      -0.412354236\n177  0.07022  4.05 0.5100 6.020 23.2     Suburban 177      -0.411938031\n178  0.05425  4.05 0.5100 6.315 24.6        Rural 178      -0.413794675\n179  0.06642  4.05 0.5100 6.860 29.9        Urban 179      -0.412379812\n180  0.05780  2.46 0.4880 6.980 37.2        Urban 180      -0.413381958\n181  0.06588  2.46 0.4880 7.765 39.8        Rural 181      -0.412442592\n182  0.06888  2.46 0.4880 6.144 36.2        Urban 182      -0.412093817\n183  0.09103  2.46 0.4880 7.155 37.9        Urban 183      -0.409518699\n184  0.10008  2.46 0.4880 6.563 32.5     Suburban 184      -0.408466562\n185  0.08308  2.46 0.4880 5.604 26.4        Rural 185      -0.410442951\n186  0.06047  2.46 0.4880 6.153 29.6        Rural 186      -0.413071549\n187  0.05602  2.46 0.4880 7.831 50.0        Urban 187      -0.413588898\n188  0.07875  3.44 0.4370 6.782 32.0        Rural 188      -0.410946349\n189  0.12579  3.44 0.4370 6.556 29.8        Urban 189      -0.405477564\n190  0.08370  3.44 0.4370 7.185 34.9        Urban 190      -0.410370871\n191  0.09068  3.44 0.4370 6.951 37.0        Urban 191      -0.409559389\n192  0.06911  3.44 0.4370 6.739 30.5     Suburban 192      -0.412067078\n193  0.08664  3.44 0.4370 7.178 36.4     Suburban 193      -0.410029072\n194  0.02187  2.93 0.4010 6.800 31.1        Rural 194      -0.417559114\n195  0.01439  2.93 0.4010 6.604 29.1        Urban 195      -0.418428726\n196  0.01381  0.46 0.4220 7.875 50.0        Urban 196      -0.418496155\n197  0.04011  1.52 0.4040 7.287 33.3        Rural 197      -0.415438565\n198  0.04666  1.52 0.4040 7.107 30.3        Rural 198      -0.414677074\n199  0.03768  1.52 0.4040 7.274 34.6     Suburban 199      -0.415721073\n200  0.03150  1.47 0.4030 6.975 34.9        Rural 200      -0.416439548\n201  0.01778  1.47 0.4030 7.135 32.9     Suburban 201      -0.418034610\n202  0.03445  2.03 0.4150 6.162 24.1        Urban 202      -0.416096587\n203  0.02177  2.03 0.4150 7.610 42.3        Urban 203      -0.417570740\n204  0.03510  2.68 0.4161 7.853 48.5        Urban 204      -0.416021019\n205  0.02009  2.68 0.4161 8.034 50.0        Urban 205      -0.417766054\n206  0.13642 10.59 0.4890 5.891 22.6        Urban 206      -0.404241740\n207  0.22969 10.59 0.4890 6.326 24.4     Suburban 207      -0.393398339\n208  0.25199 10.59 0.4890 5.783 22.5     Suburban 208      -0.390805782\n209  0.13587 10.59 0.4890 6.064 24.4     Suburban 209      -0.404305682\n210  0.43571 10.59 0.4890 5.344 20.0        Rural 210      -0.369446828\n211  0.17446 10.59 0.4890 5.960 21.7        Rural 211      -0.399819278\n212  0.37578 10.59 0.4890 5.404 19.3        Rural 212      -0.376414181\n213  0.21719 10.59 0.4890 5.807 22.4     Suburban 213      -0.394851566\n214  0.14052 10.59 0.4890 6.375 28.1        Rural 214      -0.403765081\n215  0.28955 10.59 0.4890 5.412 23.7     Suburban 215      -0.386439124\n216  0.19802 10.59 0.4890 6.182 25.0        Urban 216      -0.397080236\n217  0.04560 13.89 0.5500 5.888 23.3     Suburban 217      -0.414800308\n218  0.07013 13.89 0.5500 6.642 28.7        Rural 218      -0.411948495\n219  0.11069 13.89 0.5500 5.951 21.5        Urban 219      -0.407233063\n220  0.11425 13.89 0.5500 6.373 23.0        Urban 220      -0.406819184\n221  0.35809  6.20 0.5070 6.951 26.7     Suburban 221      -0.378470788\n222  0.40771  6.20 0.5070 6.164 21.7        Urban 222      -0.372702057\n223  0.62356  6.20 0.5070 6.879 27.5        Urban 223      -0.347607729\n224  0.61470  6.20 0.5070 6.618 30.1        Rural 224      -0.348637776\n225  0.31533  6.20 0.5040 8.266 44.8        Urban 225      -0.383441988\n226  0.52693  6.20 0.5040 8.725 50.0        Urban 226      -0.358841757\n227  0.38214  6.20 0.5040 8.040 37.6        Urban 227      -0.375674779\n228  0.41238  6.20 0.5040 7.163 31.6        Rural 228      -0.372159132\n229  0.29819  6.20 0.5040 7.686 46.7        Urban 229      -0.385434654\n230  0.44178  6.20 0.5040 6.552 31.5        Urban 230      -0.368741141\n231  0.53700  6.20 0.5040 5.981 24.3        Rural 231      -0.357671037\n232  0.46296  6.20 0.5040 7.412 31.7        Rural 232      -0.366278793\n233  0.57529  6.20 0.5070 8.337 41.7        Urban 233      -0.353219511\n234  0.33147  6.20 0.5070 8.247 48.3        Urban 234      -0.381565581\n235  0.44791  6.20 0.5070 6.726 29.0     Suburban 235      -0.368028478\n236  0.33045  6.20 0.5070 6.086 24.0     Suburban 236      -0.381684165\n237  0.52058  6.20 0.5070 6.631 25.1     Suburban 237      -0.359579996\n238  0.51183  6.20 0.5070 7.358 31.5        Urban 238      -0.360597255\n239  0.08244  4.93 0.4280 6.481 23.7     Suburban 239      -0.410517356\n240  0.09252  4.93 0.4280 6.606 23.3        Urban 240      -0.409345474\n241  0.11329  4.93 0.4280 6.897 22.0        Rural 241      -0.406930791\n242  0.10612  4.93 0.4280 6.095 20.1        Rural 242      -0.407764363\n243  0.10290  4.93 0.4280 6.358 22.2     Suburban 243      -0.408138714\n244  0.12757  4.93 0.4280 6.393 23.7        Rural 244      -0.405270625\n245  0.20608  5.86 0.4310 5.593 17.6        Rural 245      -0.396143195\n246  0.19133  5.86 0.4310 5.605 18.5     Suburban 246      -0.397858003\n247  0.33983  5.86 0.4310 6.108 24.3     Suburban 247      -0.380593663\n248  0.19657  5.86 0.4310 6.226 20.5        Urban 248      -0.397248810\n249  0.16439  5.86 0.4310 6.433 24.5        Urban 249      -0.400989998\n250  0.19073  5.86 0.4310 6.718 26.2        Urban 250      -0.397927758\n251  0.14030  5.86 0.4310 6.487 24.4     Suburban 251      -0.403790658\n252  0.21409  5.86 0.4310 6.438 24.8     Suburban 252      -0.395211967\n253  0.08221  5.86 0.4310 6.957 29.6        Rural 253      -0.410544096\n254  0.36894  5.86 0.4310 8.259 42.8        Urban 254      -0.377209387\n255  0.04819  3.64 0.3920 6.108 21.9        Rural 255      -0.414499199\n256  0.03548  3.64 0.3920 5.876 20.9        Urban 256      -0.415976841\n257  0.01538  3.75 0.3940 7.454 44.0        Urban 257      -0.418313630\n258  0.61154  3.97 0.6470 8.704 50.0        Urban 258      -0.349005152\n259  0.66351  3.97 0.6470 7.333 36.0        Urban 259      -0.342963214\n260  0.65665  3.97 0.6470 6.842 30.1        Urban 260      -0.343760745\n261  0.54011  3.97 0.6470 7.203 33.8        Urban 261      -0.357309474\n262  0.53412  3.97 0.6470 7.520 43.1        Rural 262      -0.358005861\n263  0.52014  3.97 0.6470 8.398 48.8        Urban 263      -0.359631150\n264  0.82526  3.97 0.6470 7.327 31.0        Urban 264      -0.324158453\n265  0.55007  3.97 0.6470 7.206 36.5        Urban 265      -0.356151543\n266  0.76162  3.97 0.6470 5.560 22.8        Rural 266      -0.331557124\n267  0.78570  3.97 0.6470 7.014 30.7     Suburban 267      -0.328757627\n268  0.57834  3.97 0.5750 8.297 50.0        Urban 268      -0.352864924\n269  0.54050  3.97 0.5750 7.470 43.5        Urban 269      -0.357264133\n270  0.09065  6.96 0.4640 5.920 20.7        Rural 270      -0.409562877\n271  0.29916  6.96 0.4640 5.856 21.1        Urban 271      -0.385321883\n272  0.16211  6.96 0.4640 6.240 25.2     Suburban 272      -0.401255067\n273  0.11460  6.96 0.4640 6.538 24.4     Suburban 273      -0.406778493\n274  0.22188  6.96 0.4640 7.691 35.2        Urban 274      -0.394306315\n275  0.05644  6.41 0.4470 6.758 32.4        Urban 275      -0.413540069\n276  0.09604  6.41 0.4470 6.854 32.0        Urban 276      -0.408936245\n277  0.10469  6.41 0.4470 7.267 33.2        Urban 277      -0.407930612\n278  0.06127  6.41 0.4470 6.826 33.1        Rural 278      -0.412978542\n279  0.07978  6.41 0.4470 6.482 29.1     Suburban 279      -0.410826603\n280  0.21038  3.33 0.4429 6.812 35.1        Urban 280      -0.395643285\n281  0.03578  3.33 0.4429 7.820 45.4        Urban 281      -0.415941963\n282  0.03705  3.33 0.4429 6.968 35.4        Urban 282      -0.415794315\n283  0.06129  3.33 0.4429 7.645 46.0        Urban 283      -0.412976217\n284  0.01501  1.21 0.4010 7.923 50.0        Urban 284      -0.418356646\n285  0.00906  2.97 0.4000 7.088 32.2     Suburban 285      -0.419048382\n286  0.01096  2.25 0.3890 6.453 22.0     Suburban 286      -0.418827491\n287  0.01965  1.76 0.3850 6.230 20.1     Suburban 287      -0.417817208\n288  0.03871  5.32 0.4050 6.209 23.2     Suburban 288      -0.415601327\n289  0.04590  5.32 0.4050 6.315 22.3     Suburban 289      -0.414765430\n290  0.04297  5.32 0.4050 6.565 24.8        Rural 290      -0.415106067\n291  0.03502  4.95 0.4110 6.861 28.5     Suburban 291      -0.416030319\n292  0.07886  4.95 0.4110 7.148 37.3        Urban 292      -0.410933561\n293  0.03615  4.95 0.4110 6.630 27.9     Suburban 293      -0.415898948\n294  0.08265 13.92 0.4370 6.127 23.9        Urban 294      -0.410492942\n295  0.08199 13.92 0.4370 6.009 21.7        Urban 295      -0.410569673\n296  0.12932 13.92 0.4370 6.678 28.6        Urban 296      -0.405067173\n297  0.05372 13.92 0.4370 6.549 27.1        Urban 297      -0.413856291\n298  0.14103 13.92 0.4370 5.790 20.3     Suburban 298      -0.403705789\n299  0.06466  2.24 0.4000 6.345 22.5     Suburban 299      -0.412584427\n300  0.05561  2.24 0.4000 7.041 29.0        Urban 300      -0.413636563\n301  0.04417  2.24 0.4000 6.871 24.8        Urban 301      -0.414966557\n302  0.03537  6.09 0.4330 6.590 22.0     Suburban 302      -0.415989629\n303  0.09266  6.09 0.4330 6.495 26.4        Urban 303      -0.409329198\n304  0.10000  6.09 0.4330 6.982 33.1        Urban 304      -0.408475863\n305  0.05515  2.18 0.4720 7.236 36.1        Urban 305      -0.413690042\n306  0.05479  2.18 0.4720 6.616 28.4        Rural 306      -0.413731895\n307  0.07503  2.18 0.4720 7.420 33.4     Suburban 307      -0.411378829\n308  0.04932  2.18 0.4720 6.849 28.2     Suburban 308      -0.414367827\n309  0.49298  9.90 0.5440 6.635 22.8        Rural 309      -0.362788722\n310  0.34940  9.90 0.5440 5.972 20.3        Rural 310      -0.379481072\n311  2.63548  9.90 0.5440 4.973 16.1        Rural 311      -0.113705566\n312  0.79041  9.90 0.5440 6.122 22.1        Rural 312      -0.328210051\n313  0.26169  9.90 0.5440 6.023 19.4     Suburban 313      -0.389678077\n314  0.26938  9.90 0.5440 6.266 21.6     Suburban 314      -0.388784052\n315  0.36920  9.90 0.5440 6.567 23.8     Suburban 315      -0.377179160\n316  0.25356  9.90 0.5440 5.705 16.2     Suburban 316      -0.390623256\n317  0.31827  9.90 0.5440 5.914 17.8     Suburban 317      -0.383100189\n318  0.24522  9.90 0.5440 5.782 19.8        Rural 318      -0.391592849\n319  0.40202  9.90 0.5440 6.382 23.1     Suburban 319      -0.373363566\n320  0.47547  9.90 0.5440 6.113 21.0        Urban 320      -0.364824403\n321  0.16760  7.38 0.4930 6.426 23.8        Urban 321      -0.400616810\n322  0.18159  7.38 0.4930 6.376 23.1     Suburban 322      -0.398990358\n323  0.35114  7.38 0.4930 6.041 20.4     Suburban 323      -0.379278783\n324  0.28392  7.38 0.4930 5.708 18.5     Suburban 324      -0.387093658\n325  0.34109  7.38 0.4930 6.415 25.0     Suburban 325      -0.380447177\n326  0.19186  7.38 0.4930 6.431 24.6     Suburban 326      -0.397796386\n327  0.30347  7.38 0.4930 6.312 23.0        Urban 327      -0.384820810\n328  0.24103  7.38 0.4930 6.083 22.2     Suburban 328      -0.392079971\n329  0.06617  3.24 0.4600 5.868 19.3        Rural 329      -0.412408877\n330  0.06724  3.24 0.4600 6.333 22.6        Urban 330      -0.412284481\n331  0.04544  3.24 0.4600 6.144 19.8     Suburban 331      -0.414818909\n332  0.05023  6.06 0.4379 5.706 17.1        Rural 332      -0.414262032\n333  0.03466  6.06 0.4379 6.031 19.4     Suburban 333      -0.416072172\n334  0.05083  5.19 0.5150 6.316 22.2        Urban 334      -0.414192278\n335  0.03738  5.19 0.5150 6.310 20.7     Suburban 335      -0.415755950\n336  0.03961  5.19 0.5150 6.037 21.1        Rural 336      -0.415496694\n337  0.03427  5.19 0.5150 5.869 19.5     Suburban 337      -0.416117513\n338  0.03041  5.19 0.5150 5.895 18.5     Suburban 338      -0.416566270\n339  0.03306  5.19 0.5150 6.059 20.6        Rural 339      -0.416258185\n340  0.05497  5.19 0.5150 5.985 19.0        Urban 340      -0.413710969\n341  0.06151  5.19 0.5150 5.968 18.7        Rural 341      -0.412950640\n342  0.01301  1.52 0.4420 7.241 32.7     Suburban 342      -0.418589162\n343  0.02498  1.89 0.5180 6.540 16.5     Suburban 343      -0.417197552\n344  0.02543  3.78 0.4840 6.696 23.9     Suburban 344      -0.417145235\n345  0.03049  3.78 0.4840 6.874 31.2        Rural 345      -0.416556969\n346  0.03113  4.39 0.4420 6.014 17.5        Rural 346      -0.416482564\n347  0.06162  4.39 0.4420 5.898 17.2        Urban 347      -0.412937852\n348  0.01870  4.15 0.4290 6.516 23.1     Suburban 348      -0.417927653\n349  0.01501  2.01 0.4350 6.635 24.5     Suburban 349      -0.418356646\n350  0.02899  1.25 0.4290 6.939 26.6        Rural 350      -0.416731356\n351  0.06211  1.25 0.4290 6.490 22.9     Suburban 351      -0.412880885\n352  0.07950  1.69 0.4110 6.579 24.1        Urban 352      -0.410859155\n353  0.07244  1.69 0.4110 5.884 18.6     Suburban 353      -0.411679938\n354  0.01709  2.02 0.4100 6.728 30.1     Suburban 354      -0.418114829\n355  0.04301  1.91 0.4130 5.663 18.2     Suburban 355      -0.415101417\n356  0.10659  1.91 0.4130 5.936 20.6        Urban 356      -0.407709721\n357  8.98296 18.10 0.7700 6.212 17.8     Suburban 357       0.624240921\n358  3.84970 18.10 0.7700 6.395 21.7        Rural 358       0.027457444\n359  5.20177 18.10 0.7700 6.127 22.7     Suburban 359       0.184646645\n360  4.26131 18.10 0.7700 6.112 22.6        Urban 360       0.075310474\n361  4.54192 18.10 0.7700 6.398 25.0     Suburban 361       0.107933683\n362  3.83684 18.10 0.7700 6.251 19.9        Rural 362       0.025962364\n363  3.67822 18.10 0.7700 5.362 20.8        Urban 363       0.007521491\n364  4.22239 18.10 0.7700 5.803 16.8        Rural 364       0.070785706\n365  3.47428 18.10 0.7180 8.780 21.9     Suburban 365      -0.016188203\n366  4.55587 18.10 0.7180 3.561 27.5        Urban 366       0.109555485\n367  3.69695 18.10 0.7180 4.963 21.9     Suburban 367       0.009699007\n368 13.52220 18.10 0.6310 3.863 23.1     Suburban 368       1.151964713\n369  4.89822 18.10 0.6310 4.970 50.0        Urban 369       0.149356473\n370  5.66998 18.10 0.6310 6.683 50.0        Urban 370       0.239079888\n371  6.53876 18.10 0.6310 7.016 50.0        Urban 371       0.340082672\n372  9.23230 18.10 0.6310 6.216 50.0        Urban 372       0.653228737\n373  8.26725 18.10 0.6680 5.875 50.0        Rural 373       0.541033778\n374 11.10810 18.10 0.6680 4.906 13.8        Rural 374       0.871305835\n375 18.49820 18.10 0.6680 4.138 13.8     Suburban 375       1.730465429\n376 19.60910 18.10 0.6710 7.313 15.0        Urban 376       1.859616644\n377 15.28800 18.10 0.6710 6.649 13.9     Suburban 377       1.357253412\n378  9.82349 18.10 0.6710 6.794 13.3        Rural 378       0.721959412\n379 23.64820 18.10 0.6710 6.380 13.1        Rural 379       2.329195069\n380 17.86670 18.10 0.6710 6.223 10.2        Urban 380       1.657048387\n381 88.97620 18.10 0.6710 6.968 10.4     Suburban 381       9.924109610\n382 15.87440 18.10 0.6710 6.545 10.9     Suburban 382       1.425427210\n383  9.18702 18.10 0.7000 5.536 11.3        Rural 383       0.647964566\n384  7.99248 18.10 0.7000 5.520 12.3     Suburban 384       0.509089517\n385 20.08490 18.10 0.7000 4.368  8.8     Suburban 385       1.914932287\n386 16.81180 18.10 0.7000 5.277  7.2        Urban 386       1.534407630\n387 24.39380 18.10 0.7000 4.652 10.5        Rural 387       2.415877170\n388 22.59710 18.10 0.7000 5.000  7.4        Rural 388       2.206996093\n389 14.33370 18.10 0.7000 4.880 10.2        Rural 389       1.246308229\n390  8.15174 18.10 0.7000 5.390 11.5        Rural 390       0.527604795\n391  6.96215 18.10 0.7000 5.713 15.1        Urban 391       0.389305224\n392  5.29305 18.10 0.7000 6.051 23.2     Suburban 392       0.195258692\n393 11.57790 18.10 0.7000 5.036  9.7     Suburban 393       0.925923929\n394  8.64476 18.10 0.6930 6.193 13.8     Suburban 394       0.584922404\n395 13.35980 18.10 0.6930 5.887 12.7        Rural 395       1.133084385\n396  8.71675 18.10 0.6930 6.471 13.1        Rural 396       0.593291831\n397  5.87205 18.10 0.6930 6.405 12.5        Rural 397       0.262572179\n398  7.67202 18.10 0.6930 5.747  8.5        Rural 398       0.471833420\n399 38.35180 18.10 0.6930 5.453  5.0        Rural 399       4.038608880\n400  9.91655 18.10 0.6930 5.852  6.3        Urban 400       0.732778398\n401 25.04610 18.10 0.6930 5.987  5.6        Urban 401       2.491712382\n402 14.23620 18.10 0.6930 6.343  7.2        Rural 402       1.234973056\n403  9.59571 18.10 0.6930 6.404 12.1        Urban 403       0.695478123\n404 24.80170 18.10 0.6930 5.349  8.3     Suburban 404       2.463298882\n405 41.52920 18.10 0.6930 5.531  8.5        Rural 405       4.408007629\n406 67.92080 18.10 0.6930 5.683  5.0        Rural 406       7.476247076\n407 20.71620 18.10 0.6590 4.138 11.9     Suburban 407       1.988326078\n408 11.95110 18.10 0.6590 5.608 27.9     Suburban 408       0.969311483\n409  7.40389 18.10 0.5970 5.617 17.2        Rural 409       0.440661113\n410 14.43830 18.10 0.5970 6.852 27.5        Rural 410       1.258468834\n411 51.13580 18.10 0.5970 5.757 15.0        Rural 411       5.524853484\n412 14.05070 18.10 0.5970 6.657 17.2     Suburban 412       1.213407163\n413 18.81100 18.10 0.5970 4.628 17.9        Rural 413       1.766830989\n414 28.65580 18.10 0.5970 5.155 16.3        Rural 414       2.911369543\n415 45.74610 18.10 0.6930 4.519  7.0        Rural 415       4.898256758\n416 18.08460 18.10 0.6790 6.434  7.2        Rural 416       1.682381045\n417 10.83420 18.10 0.6790 6.782  7.5        Urban 417       0.839462719\n418 25.94060 18.10 0.6790 5.304 10.4        Rural 418       2.595705326\n419 73.53410 18.10 0.6790 5.957  8.8        Rural 419       8.128839131\n420 11.81230 18.10 0.7180 6.824  8.4        Rural 420       0.953174847\n421 11.08740 18.10 0.7180 6.411 16.7     Suburban 421       0.868899291\n422  7.02259 18.10 0.7180 6.006 14.2     Suburban 422       0.396331868\n423 12.04820 18.10 0.6140 5.648 20.8        Rural 423       0.980600153\n424  7.05042 18.10 0.6140 6.103 13.4        Rural 424       0.399567334\n425  8.79212 18.10 0.5840 5.565 11.7     Suburban 425       0.602054210\n426 15.86030 18.10 0.6790 5.896  8.3     Suburban 426       1.423787970\n427 12.24720 18.10 0.5840 5.837 10.2        Rural 427       1.003735531\n428 37.66190 18.10 0.6790 6.202 10.9        Rural 428       3.958402360\n429  7.36711 18.10 0.6790 6.193 11.0        Rural 429       0.436385137\n430  9.33889 18.10 0.6790 6.380  9.5     Suburban 430       0.665620696\n431  8.49213 18.10 0.5840 6.348 14.5        Urban 431       0.567177918\n432 10.06230 18.10 0.5840 6.833 14.1     Suburban 432       0.749723028\n433  6.44405 18.10 0.5840 6.425 16.1        Rural 433       0.329071860\n434  5.58107 18.10 0.7130 6.436 14.3        Urban 434       0.228743373\n435 13.91340 18.10 0.7130 6.208 11.7        Rural 435       1.197444914\n436 11.16040 18.10 0.7400 6.629 13.4     Suburban 436       0.877386138\n437 14.42080 18.10 0.7400 6.461  9.6        Rural 437       1.256434316\n438 15.17720 18.10 0.7400 6.152  8.7        Rural 438       1.344372005\n439 13.67810 18.10 0.7400 5.935  8.4        Rural 439       1.170089364\n440  9.39063 18.10 0.7400 5.627 12.8        Rural 440       0.671635895\n441 22.05110 18.10 0.7400 5.818 10.5        Rural 441       2.143519126\n442  9.72418 18.10 0.7400 6.406 17.1     Suburban 442       0.710413811\n443  5.66637 18.10 0.7400 6.219 18.4     Suburban 443       0.238660196\n444  9.96654 18.10 0.7400 6.485 15.4        Rural 444       0.738590145\n445 12.80230 18.10 0.7400 5.854 10.8     Suburban 445       1.068270448\n446 10.67180 18.10 0.7400 6.459 11.8     Suburban 446       0.820582390\n447  6.28807 18.10 0.7400 6.341 14.9     Suburban 447       0.310937908\n448  9.92485 18.10 0.7400 6.251 12.6        Rural 448       0.733743341\n449  9.32909 18.10 0.7130 6.185 14.1        Rural 449       0.664481366\n450  7.52601 18.10 0.7130 6.417 13.0     Suburban 450       0.454858563\n451  6.71772 18.10 0.7130 6.749 13.4     Suburban 451       0.360888236\n452  5.44114 18.10 0.7130 6.655 15.2        Rural 452       0.212475366\n453  5.09017 18.10 0.7130 6.297 16.1        Rural 453       0.171672232\n454  8.24809 18.10 0.7130 7.393 17.8        Rural 454       0.538806271\n455  9.51363 18.10 0.7130 6.728 14.9        Rural 455       0.685935651\n456  4.75237 18.10 0.7130 6.525 14.1     Suburban 456       0.132400217\n457  4.66883 18.10 0.7130 5.976 12.7     Suburban 457       0.122688009\n458  8.20058 18.10 0.7130 5.936 13.5     Suburban 458       0.533282845\n459  7.75223 18.10 0.7130 6.301 14.9        Rural 459       0.481158489\n460  6.80117 18.10 0.7130 6.081 20.0        Rural 460       0.370589982\n461  4.81213 18.10 0.7130 6.701 16.4        Urban 461       0.139347806\n462  3.69311 18.10 0.7130 6.376 17.7        Rural 462       0.009252575\n463  6.65492 18.10 0.7130 6.317 19.5        Rural 463       0.353587222\n464  5.82115 18.10 0.7130 6.513 20.2     Suburban 464       0.256654638\n465  7.83932 18.10 0.6550 6.209 21.4        Rural 465       0.491283414\n466  3.16360 18.10 0.6550 5.759 19.9        Rural 466      -0.052307295\n467  3.77498 18.10 0.6550 5.952 19.0        Rural 467       0.018770633\n468  4.42228 18.10 0.5840 6.003 19.1     Suburban 468       0.094024554\n469 15.57570 18.10 0.5800 5.926 19.1        Rural 469       1.390700891\n470 13.07510 18.10 0.5800 5.713 20.1        Urban 470       1.099985680\n471  4.34879 18.10 0.5800 6.167 19.9        Rural 471       0.085480740\n472  4.03841 18.10 0.5320 6.229 19.6     Suburban 472       0.049396526\n473  3.56868 18.10 0.5800 6.437 23.2        Rural 473      -0.005213430\n474  4.64689 18.10 0.6140 6.980 29.8        Urban 474       0.120137304\n475  8.05579 18.10 0.5840 5.427 13.8     Suburban 475       0.516449822\n476  6.39312 18.10 0.5840 6.162 13.3        Rural 476       0.323150830\n477  4.87141 18.10 0.6140 6.484 16.7     Suburban 477       0.146239592\n478 15.02340 18.10 0.6140 5.304 12.0        Rural 478       1.326491497\n479 10.23300 18.10 0.6140 6.185 14.6        Rural 479       0.769568300\n480 14.33370 18.10 0.6140 6.229 21.4        Urban 480       1.246308229\n481  5.82401 18.10 0.5320 6.242 23.0     Suburban 481       0.256987136\n482  5.70818 18.10 0.5320 6.750 23.7        Urban 482       0.243520951\n483  5.73116 18.10 0.5320 7.061 25.0     Suburban 483       0.246192564\n484  2.81838 18.10 0.5320 5.762 21.8        Rural 484      -0.092441945\n485  2.37857 18.10 0.5830 5.871 20.6        Urban 485      -0.143573456\n486  3.67367 18.10 0.5830 6.312 21.2     Suburban 486       0.006992516\n487  5.69175 18.10 0.5830 6.114 19.1        Rural 487       0.241610829\n488  4.83567 18.10 0.5830 5.905 20.6        Rural 488       0.142084524\n489  0.15086 27.74 0.6090 5.454 15.2        Rural 489      -0.402562972\n490  0.18337 27.74 0.6090 5.414  7.0     Suburban 490      -0.398783418\n491  0.20746 27.74 0.6090 5.093  8.1        Urban 491      -0.395982758\n492  0.10574 27.74 0.6090 5.983 13.6        Rural 492      -0.407808541\n493  0.11132 27.74 0.6090 5.983 20.1        Rural 493      -0.407159820\n494  0.17331  9.69 0.5850 5.707 21.8        Urban 494      -0.399952975\n495  0.27957  9.69 0.5850 5.926 24.5     Suburban 495      -0.387599381\n496  0.17899  9.69 0.5850 5.670 23.1        Urban 496      -0.399292629\n497  0.28960  9.69 0.5850 5.390 19.7        Rural 497      -0.386433311\n498  0.26838  9.69 0.5850 5.794 18.3        Rural 498      -0.388900310\n499  0.23912  9.69 0.5850 6.019 21.2        Rural 499      -0.392302024\n500  0.17783  9.69 0.5850 5.569 17.5     Suburban 500      -0.399427488\n501  0.22438  9.69 0.5850 6.027 16.8        Rural 501      -0.394015670\n502  0.06263 11.93 0.5730 6.593 22.4     Suburban 502      -0.412820431\n503  0.04527 11.93 0.5730 6.120 20.6     Suburban 503      -0.414838673\n504  0.06076 11.93 0.5730 6.976 23.9     Suburban 504      -0.413037834\n505  0.10959 11.93 0.5730 6.794 22.0     Suburban 505      -0.407360947\n506  0.04741 11.93 0.5730 6.030 11.9        Rural 506      -0.414589880\n    standardized_indus standardized_nox standardized_rm standardized_medv\n1          -1.28663623      -0.14407485     0.413262920       0.159527789\n2          -0.59279438      -0.73953036     0.194082387      -0.101423917\n3          -0.59279438      -0.73953036     1.281445551       1.322937477\n4          -1.30558569      -0.83445805     1.015297761       1.181588636\n5          -1.30558569      -0.83445805     1.227362043       1.486032293\n6          -1.30558569      -0.83445805     0.206891639       0.670558212\n7          -0.47618230      -0.26489191    -0.388026950       0.039924923\n8          -0.47618230      -0.26489191    -0.160306916       0.496590409\n9          -0.47618230      -0.26489191    -0.930285282      -0.655946292\n10         -0.47618230      -0.26489191    -0.399412952      -0.394994586\n11         -0.47618230      -0.26489191     0.131459378      -0.819041108\n12         -0.47618230      -0.26489191    -0.392296701      -0.394994586\n13         -0.47618230      -0.26489191    -0.563086727      -0.090550930\n14         -0.43682573      -0.14407485    -0.477691714      -0.231899770\n15         -0.43682573      -0.14407485    -0.268473932      -0.471105500\n16         -0.43682573      -0.14407485    -0.641365488      -0.286264709\n17         -0.43682573      -0.14407485    -0.497617217       0.061670899\n18         -0.43682573      -0.14407485    -0.419338455      -0.547216415\n19         -0.43682573      -0.14407485    -1.179354069      -0.253645746\n20         -0.43682573      -0.14407485    -0.793653261      -0.471105500\n21         -0.43682573      -0.14407485    -1.017103545      -0.971262937\n22         -0.43682573      -0.14407485    -0.454919710      -0.318883672\n23         -0.43682573      -0.14407485    -0.203004422      -0.797295133\n24         -0.43682573      -0.14407485    -0.671253743      -0.873406047\n25         -0.43682573      -0.14407485    -0.513272969      -0.753803182\n26         -0.43682573      -0.14407485    -0.975829289      -0.938643973\n27         -0.43682573      -0.14407485    -0.671253743      -0.645073304\n28         -0.43682573      -0.14407485    -0.338213193      -0.840787084\n29         -0.43682573      -0.14407485     0.299402903      -0.449359525\n30         -0.43682573      -0.14407485     0.554164692      -0.166661844\n31         -0.43682573      -0.14407485    -0.813578764      -1.069119826\n32         -0.43682573      -0.14407485    -0.302631937      -0.873406047\n33         -0.43682573      -0.14407485    -0.476268464      -1.014754888\n34         -0.43682573      -0.14407485    -0.830657767      -1.025627875\n35         -0.43682573      -0.14407485    -0.268473932      -0.982135924\n36         -0.75459363      -0.48063666    -0.500463717      -0.394994586\n37         -0.75459363      -0.48063666    -0.631402737      -0.275391721\n38         -0.75459363      -0.48063666    -0.618593485      -0.166661844\n39         -0.75459363      -0.48063666    -0.453496460       0.235638703\n40         -1.19334657      -1.09335175     0.441727925       0.898890955\n41         -1.19334657      -1.09335175     1.052302267       1.344683452\n42         -0.61611679      -0.92075595     0.690796712       0.442225470\n43         -0.61611679      -0.92075595    -0.164576667       0.300876629\n44         -0.61611679      -0.92075595    -0.104800158       0.235638703\n45         -0.61611679      -0.92075595    -0.306901688      -0.144915868\n46         -0.61611679      -0.92075595    -0.857699521      -0.351502635\n47         -0.61611679      -0.92075595    -0.709681499      -0.275391721\n48         -0.61611679      -0.92075595    -0.362408446      -0.645073304\n49         -0.61611679      -0.92075595    -1.260479332      -0.884279035\n50         -0.61611679      -0.92075595    -0.971559538      -0.340629648\n51         -0.80123846      -0.99842406    -0.457766211      -0.308010684\n52         -0.80123846      -0.99842406    -0.241432178      -0.221026782\n53         -0.80123846      -0.99842406     0.322174907       0.268257666\n54         -0.80123846      -0.99842406    -0.407952453       0.094289862\n55         -1.04029322      -1.24868797    -0.564509977      -0.394994586\n56         -1.44552019      -1.30909650     1.372533565       1.399048391\n57         -1.51548743      -1.24868797     0.139998879       0.235638703\n58         -1.43094368      -1.24005818     0.756266222       0.985874857\n59         -0.87557866      -0.87760700    -0.198734672       0.083416874\n60         -0.87557866      -0.87760700    -0.509003218      -0.318883672\n61         -0.87557866      -0.87760700    -0.773727758      -0.416740562\n62         -0.87557866      -0.87760700    -0.453496460      -0.710311231\n63         -0.87557866      -0.87760700     0.243896145      -0.036185991\n64         -0.87557866      -0.87760700     0.679410711       0.268257666\n65         -1.42219777      -1.19604625     1.166162284       1.138096685\n66         -1.13212523      -1.35224545     0.007636609       0.105162850\n67         -1.13212523      -1.35224545    -0.708258248      -0.340629648\n68         -0.73855947      -1.25731776    -0.578742479      -0.057931966\n69         -0.73855947      -1.25731776    -0.982945540      -0.558089402\n70         -0.73855947      -1.25731776    -0.568779727      -0.177534831\n71         -0.04763292      -1.22279860     0.188389387       0.181273764\n72         -0.04763292      -1.22279860    -0.460612711      -0.090550930\n73         -0.04763292      -1.22279860    -0.312594689       0.029051936\n74         -0.04763292      -1.22279860    -0.056409650       0.094289862\n75          0.24681257      -1.01568364    -0.016558644       0.170400776\n76          0.24681257      -1.01568364     0.001943608      -0.123169893\n77          0.24681257      -1.01568364    -0.008019143      -0.275391721\n78          0.24681257      -1.01568364    -0.205850923      -0.188407819\n79          0.24681257      -1.01568364    -0.074911903      -0.144915868\n80          0.24681257      -1.01568364    -0.584435480      -0.242772758\n81         -0.91493524      -1.11061133     0.629596953       0.594447298\n82         -0.91493524      -1.11061133     0.475885930       0.148654801\n83         -0.91493524      -1.11061133     0.024715612       0.246511690\n84         -0.91493524      -1.11061133    -0.167423167       0.039924923\n85         -0.96886832      -0.91212616     0.148538381       0.148654801\n86         -0.96886832      -0.91212616     0.491541682       0.442225470\n87         -0.96886832      -0.91212616    -0.383757200      -0.003567028\n88         -0.96886832      -0.91212616    -0.232892677      -0.036185991\n89         -1.12629463      -0.56693456     1.028107013       0.116035838\n90         -1.12629463      -0.56693456     1.130581029       0.670558212\n91         -1.12629463      -0.56693456     0.188389387       0.007305960\n92         -1.12629463      -0.56693456     0.171310384      -0.057931966\n93          0.56895343      -0.78267931     0.223970642       0.039924923\n94          0.56895343      -0.78267931    -0.104800158       0.268257666\n95          0.56895343      -0.78267931    -0.050716649      -0.210153795\n96         -1.20209248      -0.94664532     0.484425431       0.637939249\n97         -1.20209248      -0.94664532    -0.173116168      -0.123169893\n98         -1.20209248      -0.94664532     2.539598741       1.757856987\n99         -1.20209248      -0.94664532     2.185209437       2.312379361\n100        -1.20209248      -0.94664532     1.610216351       1.159842661\n101        -0.37560439      -0.29941107     0.629596953       0.540082359\n102        -0.37560439      -0.29941107     0.706452465       0.431352482\n103        -0.37560439      -0.29941107     0.171310384      -0.427613550\n104        -0.37560439      -0.29941107    -0.210120673      -0.351502635\n105        -0.37560439      -0.29941107    -0.167423167      -0.264518733\n106        -0.37560439      -0.29941107    -0.617170235      -0.329756660\n107        -0.37560439      -0.29941107    -0.638518988      -0.329756660\n108        -0.37560439      -0.29941107    -0.224353176      -0.231899770\n109        -0.37560439      -0.29941107     0.269514649      -0.297137697\n110        -0.37560439      -0.29941107    -0.079181654      -0.340629648\n111        -0.37560439      -0.29941107    -0.127572161      -0.090550930\n112        -0.16424500      -0.06640675     0.612517950       0.029051936\n113        -0.16424500      -0.06640675    -0.528928721      -0.405867574\n114        -0.16424500      -0.06640675    -0.274166933      -0.416740562\n115        -0.16424500      -0.06640675    -0.043600398      -0.438486537\n116        -0.16424500      -0.06640675    -0.507579968      -0.460232513\n117        -0.16424500      -0.06640675    -0.154613915      -0.144915868\n118        -0.16424500      -0.06640675    -0.375217698      -0.362375623\n119        -0.16424500      -0.06640675    -0.587281980      -0.231899770\n120        -0.16424500      -0.06640675    -0.787960260      -0.351502635\n121         2.11552109       0.22700611    -0.590128481      -0.057931966\n122         2.11552109       0.22700611    -0.399412952      -0.242772758\n123         2.11552109       0.22700611    -0.460612711      -0.221026782\n124         2.11552109       0.22700611    -0.610053984      -0.568962390\n125         2.11552109       0.22700611    -0.577319229      -0.405867574\n126         2.11552109       0.22700611    -0.425031456      -0.123169893\n127         2.11552109       0.22700611    -0.955903786      -0.742930194\n128         1.56744433       0.59808708    -0.842043769      -0.688565255\n129         1.56744433       0.59808708     0.208314890      -0.492851476\n130         1.56744433       0.59808708    -0.921745781      -0.895152022\n131         1.56744433       0.59808708     0.246742645      -0.362375623\n132         1.56744433       0.59808708     0.058873617      -0.318883672\n133         1.56744433       0.59808708     0.124343127       0.050797911\n134         1.56744433       0.59808708    -0.658444491      -0.449359525\n135         1.56744433       0.59808708    -0.750955755      -0.753803182\n136         1.56744433       0.59808708     0.071682869      -0.481978488\n137         1.56744433       0.59808708    -0.487654465      -0.558089402\n138         1.56744433       0.59808708     0.241049645      -0.590708366\n139         1.56744433       0.59808708    -0.608630733      -1.003881900\n140         1.56744433       0.59808708    -0.190195170      -0.514597451\n141         1.56744433       0.59808708    -0.157460416      -0.927770986\n142         1.56744433       0.59808708    -1.801314413      -0.884279035\n143         1.23072696       2.72964520    -1.254786331      -0.993008912\n144         1.23072696       2.72964520    -1.162275067      -0.753803182\n145         1.23072696       2.72964520    -1.966411438      -1.166976716\n146         1.23072696       2.72964520    -0.220083425      -0.949516961\n147         1.23072696       2.72964520    -0.934555033      -0.753803182\n148         1.23072696       2.72964520    -1.933676683      -0.862533059\n149         1.23072696       2.72964520    -1.563631627      -0.514597451\n150         1.23072696       2.72964520    -0.978675789      -0.775549157\n151         1.23072696       2.72964520    -0.231469427      -0.112296905\n152         1.23072696       2.72964520    -1.253363081      -0.318883672\n153         1.23072696       2.72964520    -1.811277165      -0.786422145\n154         1.23072696       2.72964520    -0.819271765      -0.340629648\n155         1.23072696       2.72964520    -0.221506675      -0.601581353\n156         1.23072696       2.72964520    -0.188771920      -0.753803182\n157         1.23072696       2.72964520    -1.441232109      -1.025627875\n158         1.23072696       0.43412107     0.937018999       2.040554668\n159         1.23072696       0.43412107    -0.311171439       0.192146752\n160         1.23072696       2.72964520     0.320751657       0.083416874\n161         1.23072696       0.43412107    -0.049293399       0.485717421\n162         1.23072696       0.43412107     1.714113616       2.986504601\n163         1.23072696       0.43412107     2.159590934       2.986504601\n164         1.23072696       0.43412107     2.975113306       2.986504601\n165         1.23072696       0.43412107    -0.612900484       0.018178948\n166         1.23072696       0.43412107    -0.261357681       0.268257666\n167         1.23072696       0.43412107     2.340343711       2.986504601\n168         1.23072696       0.43412107    -0.580165729       0.137781813\n169         1.23072696       0.43412107     0.048910866       0.137781813\n170         1.23072696       0.43412107     0.167040633      -0.025313003\n171         1.23072696       0.43412107    -0.583012230      -0.558089402\n172         1.23072696       0.43412107    -0.575895979      -0.373248611\n173        -1.03300497      -0.38570897    -1.014257045       0.061670899\n174        -1.03300497      -0.38570897     0.186966136       0.116035838\n175        -1.03300497      -0.38570897    -0.605784233       0.007305960\n176        -1.03300497      -0.38570897     0.371988664       0.746669127\n177        -1.03300497      -0.38570897    -0.376640949       0.072543887\n178        -1.03300497      -0.38570897     0.043217865       0.224765715\n179        -1.03300497      -0.38570897     0.818889232       0.801034065\n180        -1.26477147      -0.57556435     0.989679257       1.594762170\n181        -1.26477147      -0.57556435     2.106930676       1.877459852\n182        -1.26477147      -0.57556435    -0.200157922       1.486032293\n183        -1.26477147      -0.57556435     1.238748045       1.670873085\n184        -1.26477147      -0.57556435     0.396183918       1.083731747\n185        -1.26477147      -0.57556435    -0.968713038       0.420479494\n186        -1.26477147      -0.57556435    -0.187348670       0.768415102\n187        -1.26477147      -0.57556435     2.200865190       2.986504601\n188        -1.12192167      -1.01568364     0.707875715       1.029366808\n189        -1.12192167      -1.01568364     0.386221166       0.790161078\n190        -1.12192167      -1.01568364     1.281445551       1.344683452\n191        -1.12192167      -1.01568364     0.948405001       1.573016195\n192        -1.12192167      -1.01568364     0.646675956       0.866271992\n193        -1.12192167      -1.01568364     1.271482800       1.507778268\n194        -1.19626187      -1.32635608     0.733494219       0.931509918\n195        -1.19626187      -1.32635608     0.454537177       0.714050163\n196        -1.55630166      -1.14513049     2.263488199       2.986504601\n197        -1.40179066      -1.30046671     1.426617073       1.170715648\n198        -1.40179066      -1.30046671     1.170432035       0.844526016\n199        -1.40179066      -1.30046671     1.408114820       1.312064489\n200        -1.40907891      -1.30909650     0.982563006       1.344683452\n201        -1.40907891      -1.30909650     1.210283041       1.127223698\n202        -1.32745046      -1.20553902    -0.174539418       0.170400776\n203        -1.32745046      -1.20553902     1.886326892       2.149284545\n204        -1.23270315      -1.19604625     2.232176694       2.823409785\n205        -1.23270315      -1.19604625     2.489784983       2.986504601\n206        -0.07970124      -0.56693456    -0.560240226       0.007305960\n207        -0.07970124      -0.56693456     0.058873617       0.203019739\n208        -0.07970124      -0.56693456    -0.713951249      -0.003567028\n209        -0.07970124      -0.56693456    -0.314017939       0.203019739\n210        -0.07970124      -0.56693456    -1.338758093      -0.275391721\n211        -0.07970124      -0.56693456    -0.462035961      -0.090550930\n212        -0.07970124      -0.56693456    -1.253363081      -0.351502635\n213        -0.07970124      -0.56693456    -0.679793244      -0.014440015\n214        -0.07970124      -0.56693456     0.128612878       0.605320286\n215        -0.07970124      -0.56693456    -1.241977079       0.126908825\n216        -0.07970124      -0.56693456    -0.146074414       0.268257666\n217         0.40132357      -0.04051738    -0.564509977       0.083416874\n218         0.40132357      -0.04051738     0.508620685       0.670558212\n219         0.40132357      -0.04051738    -0.474845213      -0.112296905\n220         0.40132357      -0.04051738     0.125766377       0.050797911\n221        -0.71961001      -0.41159834     0.948405001       0.453098458\n222        -0.71961001      -0.41159834    -0.171692918      -0.090550930\n223        -0.71961001      -0.41159834     0.845930986       0.540082359\n224        -0.71961001      -0.41159834     0.474462680       0.822780041\n225        -0.71961001      -0.43748771     2.819979033       2.421109239\n226        -0.71961001      -0.43748771     3.473250881       2.986504601\n227        -0.71961001      -0.43748771     2.498324485       1.638254121\n228        -0.71961001      -0.43748771     1.250134047       0.985874857\n229        -0.71961001      -0.43748771     1.994493909       2.627696006\n230        -0.71961001      -0.43748771     0.380528166       0.975001869\n231        -0.71961001      -0.43748771    -0.432147707       0.192146752\n232        -0.71961001      -0.43748771     1.604523350       0.996747845\n233        -0.71961001      -0.41159834     2.921029798       2.084046619\n234        -0.71961001      -0.41159834     2.792937279       2.801663810\n235        -0.71961001      -0.41159834     0.628173703       0.703177176\n236        -0.71961001      -0.41159834    -0.282706434       0.159527789\n237        -0.71961001      -0.41159834     0.492964932       0.279130654\n238        -0.71961001      -0.41159834     1.527667838       0.975001869\n239        -0.90473168      -1.09335175     0.279477400       0.126908825\n240        -0.90473168      -1.09335175     0.457383677       0.083416874\n241        -0.90473168      -1.09335175     0.871549489      -0.057931966\n242        -0.90473168      -1.09335175    -0.269897182      -0.264518733\n243        -0.90473168      -1.09335175     0.104417624      -0.036185991\n244        -0.90473168      -1.09335175     0.154231381       0.126908825\n245        -0.76917014      -1.06746238    -0.984368790      -0.536343427\n246        -0.76917014      -1.06746238    -0.967289788      -0.438486537\n247        -0.76917014      -1.06746238    -0.251394930       0.192146752\n248        -0.76917014      -1.06746238    -0.083451404      -0.221026782\n249        -0.76917014      -1.06746238     0.211161390       0.213892727\n250        -0.76917014      -1.06746238     0.616787701       0.398733519\n251        -0.76917014      -1.06746238     0.288016902       0.203019739\n252        -0.76917014      -1.06746238     0.218277641       0.246511690\n253        -0.76917014      -1.06746238     0.956944502       0.768415102\n254        -0.76917014      -1.06746238     2.810016281       2.203649484\n255        -1.09276866      -1.40402419    -0.251394930      -0.068804954\n256        -1.09276866      -1.40402419    -0.581588979      -0.177534831\n257        -1.07673449      -1.38676461     1.664299859       2.334125337\n258        -1.04466617       0.79657225     3.443362627       2.986504601\n259        -1.04466617       0.79657225     1.492086583       1.464286318\n260        -1.04466617       0.79657225     0.793270728       0.822780041\n261        -1.04466617       0.79657225     1.307064055       1.225080587\n262        -1.04466617       0.79657225     1.758234373       2.236268447\n263        -1.04466617       0.79657225     3.007848061       2.856028748\n264        -1.04466617       0.79657225     1.483547082       0.920636930\n265        -1.04466617       0.79657225     1.311333806       1.518651256\n266        -1.04466617       0.79657225    -1.031336047       0.029051936\n267        -1.04466617       0.79657225     1.038069765       0.888017967\n268        -1.04466617       0.17522737     2.864099790       2.986504601\n269        -1.04466617       0.17522737     1.687071862       2.279760398\n270        -0.60882854      -0.78267931    -0.518965970      -0.199280807\n271        -0.60882854      -0.78267931    -0.610053984      -0.155788856\n272        -0.60882854      -0.78267931    -0.063525901       0.290003641\n273        -0.60882854      -0.78267931     0.360602663       0.203019739\n274        -0.60882854      -0.78267931     2.001610160       1.377302416\n275        -0.68899934      -0.92938574     0.673717710       1.072858759\n276        -0.68899934      -0.92938574     0.810349730       1.029366808\n277        -0.68899934      -0.92938574     1.398152069       1.159842661\n278        -0.68899934      -0.92938574     0.770498724       1.148969673\n279        -0.68899934      -0.92938574     0.280900651       0.714050163\n280        -1.13795583      -0.96476788     0.750573221       1.366429428\n281        -1.13795583      -0.96476788     2.185209437       2.486347165\n282        -1.13795583      -0.96476788     0.972600255       1.399048391\n283        -1.13795583      -0.96476788     1.936140650       2.551585092\n284        -1.44697784      -1.32635608     2.331804209       2.986504601\n285        -1.19043127      -1.33498587     1.143390280       1.051112783\n286        -1.29538214      -1.42991356     0.239626394      -0.057931966\n287        -1.36680703      -1.46443272    -0.077758404      -0.264518733\n288        -0.84788329      -1.29183692    -0.107646658       0.072543887\n289        -0.84788329      -1.29183692     0.043217865      -0.025313003\n290        -0.84788329      -1.29183692     0.399030418       0.246511690\n291        -0.90181638      -1.24005818     0.820312482       0.648812237\n292        -0.90181638      -1.24005818     1.228785293       1.605635158\n293        -0.90181638      -1.24005818     0.491541682       0.583574310\n294         0.40569652      -1.01568364    -0.224353176       0.148654801\n295         0.40569652      -1.01568364    -0.392296701      -0.090550930\n296         0.40569652      -1.01568364     0.559857693       0.659685225\n297         0.40569652      -1.01568364     0.376258415       0.496590409\n298         0.40569652      -1.01568364    -0.703988498      -0.242772758\n299        -1.29683979      -1.33498587     0.085915371      -0.003567028\n300        -1.29683979      -1.33498587     1.076497520       0.703177176\n301        -1.29683979      -1.33498587     0.834544984       0.246511690\n302        -0.73564417      -1.05020280     0.434611674      -0.057931966\n303        -0.73564417      -1.05020280     0.299402903       0.420479494\n304        -0.73564417      -1.05020280     0.992525758       1.148969673\n305        -1.30558569      -0.71364099     1.354031312       1.475159305\n306        -1.30558569      -0.71364099     0.471616179       0.637939249\n307        -1.30558569      -0.71364099     1.615909352       1.181588636\n308        -1.30558569      -0.71364099     0.803233479       0.616193274\n309        -0.18027916      -0.09229612     0.498657933       0.029051936\n310        -0.18027916      -0.09229612    -0.444956959      -0.242772758\n311        -0.18027916      -0.09229612    -1.866783923      -0.699438243\n312        -0.18027916      -0.09229612    -0.231469427      -0.047058979\n313        -0.18027916      -0.09229612    -0.372371198      -0.340629648\n314        -0.18027916      -0.09229612    -0.026521396      -0.101423917\n315        -0.18027916      -0.09229612     0.401876919       0.137781813\n316        -0.18027916      -0.09229612    -0.824964766      -0.688565255\n317        -0.18027916      -0.09229612    -0.527505471      -0.514597451\n318        -0.18027916      -0.09229612    -0.715374500      -0.297137697\n319        -0.18027916      -0.09229612     0.138575629       0.061670899\n320        -0.18027916      -0.09229612    -0.244278679      -0.166661844\n321        -0.54760720      -0.53241540     0.201198639       0.137781813\n322        -0.54760720      -0.53241540     0.130036128       0.061670899\n323        -0.54760720      -0.53241540    -0.346752694      -0.231899770\n324        -0.54760720      -0.53241540    -0.820695015      -0.438486537\n325        -0.54760720      -0.53241540     0.185542886       0.268257666\n326        -0.54760720      -0.53241540     0.208314890       0.224765715\n327        -0.54760720      -0.53241540     0.038948114       0.050797911\n328        -0.54760720      -0.53241540    -0.286976185      -0.036185991\n329        -1.15107469      -0.81719847    -0.592974981      -0.351502635\n330        -1.15107469      -0.81719847     0.068836369       0.007305960\n331        -1.15107469      -0.81719847    -0.200157922      -0.297137697\n332        -0.74001712      -1.00791683    -0.823541516      -0.590708366\n333        -0.74001712      -1.00791683    -0.360985196      -0.340629648\n334        -0.86683276      -0.34256002     0.044641115      -0.036185991\n335        -0.86683276      -0.34256002     0.036101614      -0.199280807\n336        -0.86683276      -0.34256002    -0.352445695      -0.155788856\n337        -0.86683276      -0.34256002    -0.591551731      -0.329756660\n338        -0.86683276      -0.34256002    -0.554547225      -0.438486537\n339        -0.86683276      -0.34256002    -0.321134190      -0.210153795\n340        -0.86683276      -0.34256002    -0.426454706      -0.384121599\n341        -0.86683276      -0.34256002    -0.450649960      -0.416740562\n342        -1.40179066      -0.97253469     1.361147563       1.105477722\n343        -1.34785757      -0.31667065     0.363449163      -0.655946292\n344        -1.07236154      -0.61008351     0.585476196       0.148654801\n345        -1.07236154      -0.61008351     0.838814735       0.942382906\n346        -0.98344483      -0.97253469    -0.385180450      -0.547216415\n347        -0.98344483      -0.97253469    -0.550277475      -0.579835378\n348        -1.01842846      -1.08472196     0.329291158       0.061670899\n349        -1.33036576      -1.03294322     0.498657933       0.213892727\n350        -1.44114723      -1.08472196     0.931325998       0.442225470\n351        -1.44114723      -1.08472196     0.292286652       0.039924923\n352        -1.37701059      -1.24005818     0.418955921       0.170400776\n353        -1.37701059      -1.24005818    -0.570202978      -0.427613550\n354        -1.32890811      -1.24868797     0.631020203       0.822780041\n355        -1.34494227      -1.22279860    -0.884741275      -0.471105500\n356        -1.34494227      -1.22279860    -0.496193967      -0.210153795\n357         1.01499462       1.85803641    -0.103376907      -0.514597451\n358         1.01499462       1.85803641     0.157077882      -0.090550930\n359         1.01499462       1.85803641    -0.224353176       0.018178948\n360         1.01499462       1.85803641    -0.245701929       0.007305960\n361         1.01499462       1.85803641     0.161347633       0.268257666\n362         1.01499462       1.85803641    -0.047870149      -0.286264709\n363         1.01499462       1.85803641    -1.313139590      -0.188407819\n364         1.01499462       1.85803641    -0.685486245      -0.623327329\n365         1.01499462       1.40928733     3.551529643      -0.068804954\n366         1.01499462       1.40928733    -3.876413226       0.540082359\n367         1.01499462       1.40928733    -1.881016425      -0.068804954\n368         1.01499462       0.65849561    -3.446591661       0.061670899\n369         1.01499462       0.65849561    -1.871053674       2.986504601\n370         1.01499462       0.65849561     0.566973944       2.986504601\n371         1.01499462       0.65849561     1.040916265       2.986504601\n372         1.01499462       0.65849561    -0.097683907       2.986504601\n373         1.01499462       0.97779784    -0.583012230       2.986504601\n374         1.01499462       0.97779784    -1.962141687      -0.949516961\n375         1.01499462       0.97779784    -3.055197852      -0.949516961\n376         1.01499462       1.00368721     1.463621579      -0.819041108\n377         1.01499462       1.00368721     0.518583436      -0.938643973\n378         1.01499462       1.00368721     0.724954717      -1.003881900\n379         1.01499462       1.00368721     0.135729129      -1.025627875\n380         1.01499462       1.00368721    -0.087721155      -1.340944520\n381         1.01499462       1.00368721     0.972600255      -1.319198544\n382         1.01499462       1.00368721     0.370565414      -1.264833606\n383         1.01499462       1.25395112    -1.065494052      -1.221341655\n384         1.01499462       1.25395112    -1.088266056      -1.112611777\n385         1.01499462       1.25395112    -2.727850303      -1.493166348\n386         1.01499462       1.25395112    -1.434115858      -1.667134152\n387         1.01499462       1.25395112    -2.323647242      -1.308325557\n388         1.01499462       1.25395112    -1.828356167      -1.645388177\n389         1.01499462       1.25395112    -1.999146193      -1.340944520\n390         1.01499462       1.25395112    -1.273288584      -1.199595679\n391         1.01499462       1.25395112    -0.813578764      -0.808168120\n392         1.01499462       1.25395112    -0.332520192       0.072543887\n393         1.01499462       1.25395112    -1.777119159      -1.395309459\n394         1.01499462       1.19354259    -0.130418661      -0.949516961\n395         1.01499462       1.19354259    -0.565933227      -1.069119826\n396         1.01499462       1.19354259     0.265244898      -1.025627875\n397         1.01499462       1.19354259     0.171310384      -1.090865802\n398         1.01499462       1.19354259    -0.765188257      -1.525785311\n399         1.01499462       1.19354259    -1.183623820      -1.906339882\n400         1.01499462       1.19354259    -0.615746985      -1.764991042\n401         1.01499462       1.19354259    -0.423608206      -1.841101956\n402         1.01499462       1.19354259     0.083068871      -1.667134152\n403         1.01499462       1.19354259     0.169887134      -1.134357753\n404         1.01499462       1.19354259    -1.331641842      -1.547531287\n405         1.01499462       1.19354259    -1.072610303      -1.525785311\n406         1.01499462       1.19354259    -0.856276271      -1.906339882\n407         1.01499462       0.90012973    -3.055197852      -1.156103728\n408         1.01499462       0.90012973    -0.963020037       0.583574310\n409         1.01499462       0.36508275    -0.950210785      -0.579835378\n410         1.01499462       0.36508275     0.807503230       0.540082359\n411         1.01499462       0.36508275    -0.750955755      -0.819041108\n412         1.01499462       0.36508275     0.529969438      -0.579835378\n413         1.01499462       0.36508275    -2.357805247      -0.503724464\n414         1.01499462       0.36508275    -1.607752384      -0.677692268\n415         1.01499462       1.19354259    -2.512939520      -1.688880128\n416         1.01499462       1.07272553     0.212584640      -1.667134152\n417         1.01499462       1.07272553     0.707875715      -1.634515189\n418         1.01499462       1.07272553    -1.395688102      -1.319198544\n419         1.01499462       1.07272553    -0.466305712      -1.493166348\n420         1.01499462       1.40928733     0.767652224      -1.536658299\n421         1.01499462       1.40928733     0.179849885      -0.634200317\n422         1.01499462       1.40928733    -0.396566452      -0.906025010\n423         1.01499462       0.51178918    -0.906090028      -0.188407819\n424         1.01499462       0.51178918    -0.258511181      -0.993008912\n425         1.01499462       0.25289548    -1.024219796      -1.177849704\n426         1.01499462       1.07272553    -0.553123975      -1.547531287\n427         1.01499462       0.25289548    -0.637095738      -1.340944520\n428         1.01499462       1.07272553    -0.117609410      -1.264833606\n429         1.01499462       1.07272553    -0.130418661      -1.253960618\n430         1.01499462       1.07272553     0.135729129      -1.417055434\n431         1.01499462       0.25289548     0.090185122      -0.873406047\n432         1.01499462       0.25289548     0.780461476      -0.916897998\n433         1.01499462       0.25289548     0.199775388      -0.699438243\n434         1.01499462       1.36613839     0.215431141      -0.895152022\n435         1.01499462       1.36613839    -0.109069908      -1.177849704\n436         1.01499462       1.59914271     0.490118432      -0.993008912\n437         1.01499462       1.59914271     0.251012396      -1.406182446\n438         1.01499462       1.59914271    -0.188771920      -1.504039336\n439         1.01499462       1.59914271    -0.497617217      -1.536658299\n440         1.01499462       1.59914271    -0.935978283      -1.058246839\n441         1.01499462       1.59914271    -0.664137492      -1.308325557\n442         1.01499462       1.59914271     0.172733634      -0.590708366\n443         1.01499462       1.59914271    -0.093414156      -0.449359525\n444         1.01499462       1.59914271     0.285170401      -0.775549157\n445         1.01499462       1.59914271    -0.612900484      -1.275706593\n446         1.01499462       1.59914271     0.248165896      -1.166976716\n447         1.01499462       1.59914271     0.080222370      -0.829914096\n448         1.01499462       1.59914271    -0.047870149      -1.079992814\n449         1.01499462       1.36613839    -0.141804663      -0.916897998\n450         1.01499462       1.36613839     0.188389387      -1.036500863\n451         1.01499462       1.36613839     0.660908458      -0.993008912\n452         1.01499462       1.36613839     0.527122938      -0.797295133\n453         1.01499462       1.36613839     0.017599361      -0.699438243\n454         1.01499462       1.36613839     1.577481596      -0.514597451\n455         1.01499462       1.36613839     0.631020203      -0.829914096\n456         1.01499462       1.36613839     0.342100410      -0.916897998\n457         1.01499462       1.36613839    -0.439263958      -1.069119826\n458         1.01499462       1.36613839    -0.496193967      -0.982135924\n459         1.01499462       1.36613839     0.023292362      -0.829914096\n460         1.01499462       1.36613839    -0.289822685      -0.275391721\n461         1.01499462       1.36613839     0.592592447      -0.666819280\n462         1.01499462       1.36613839     0.130036128      -0.525470439\n463         1.01499462       1.36613839     0.046064365      -0.329756660\n464         1.01499462       1.36613839     0.325021407      -0.253645746\n465         1.01499462       0.86561057    -0.107646658      -0.123169893\n466         1.01499462       0.86561057    -0.748109254      -0.286264709\n467         1.01499462       0.86561057    -0.473421963      -0.384121599\n468         1.01499462       0.25289548    -0.400836202      -0.373248611\n469         1.01499462       0.21837632    -0.510426469      -0.373248611\n470         1.01499462       0.21837632    -0.813578764      -0.264518733\n471         1.01499462       0.21837632    -0.167423167      -0.286264709\n472         1.01499462      -0.19585359    -0.079181654      -0.318883672\n473         1.01499462       0.21837632     0.216854391       0.072543887\n474         1.01499462       0.51178918     0.989679257       0.790161078\n475         1.01499462       0.25289548    -1.220628326      -0.949516961\n476         1.01499462       0.25289548    -0.174539418      -1.003881900\n477         1.01499462       0.51178918     0.283747151      -0.634200317\n478         1.01499462       0.51178918    -1.395688102      -1.145230740\n479         1.01499462       0.51178918    -0.141804663      -0.862533059\n480         1.01499462       0.51178918    -0.079181654      -0.123169893\n481         1.01499462      -0.19585359    -0.060679401       0.050797911\n482         1.01499462      -0.19585359     0.662331708       0.126908825\n483         1.01499462      -0.19585359     1.104962525       0.268257666\n484         1.01499462      -0.19585359    -0.743839504      -0.079677942\n485         1.01499462       0.24426569    -0.588705230      -0.210153795\n486         1.01499462       0.24426569     0.038948114      -0.144915868\n487         1.01499462       0.24426569    -0.242855428      -0.373248611\n488         1.01499462       0.24426569    -0.540314723      -0.210153795\n489         2.42017014       0.46864023    -1.182200570      -0.797295133\n490         2.42017014       0.46864023    -1.239130578      -1.688880128\n491         2.42017014       0.46864023    -1.695993897      -1.569277262\n492         2.42017014       0.46864023    -0.429301206      -0.971262937\n493         2.42017014       0.46864023    -0.429301206      -0.264518733\n494        -0.21088983       0.26152527    -0.822118266      -0.079677942\n495        -0.21088983       0.26152527    -0.510426469       0.213892727\n496        -0.21088983       0.26152527    -0.874778524       0.061670899\n497        -0.21088983       0.26152527    -1.273288584      -0.308010684\n498        -0.21088983       0.26152527    -0.698295497      -0.460232513\n499        -0.21088983       0.26152527    -0.378064199      -0.144915868\n500        -0.21088983       0.26152527    -1.018526795      -0.547216415\n501        -0.21088983       0.26152527    -0.366678197      -0.623327329\n502         0.11562398       0.15796779     0.438881424      -0.014440015\n503         0.11562398       0.15796779    -0.234315927      -0.210153795\n504         0.11562398       0.15796779     0.983986256       0.148654801\n505         0.11562398       0.15796779     0.724954717      -0.057931966\n506         0.11562398       0.15796779    -0.362408446      -1.156103728\n    standardized_ID\n1      -1.726922180\n2      -1.720082884\n3      -1.713243588\n4      -1.706404292\n5      -1.699564997\n6      -1.692725701\n7      -1.685886405\n8      -1.679047109\n9      -1.672207814\n10     -1.665368518\n11     -1.658529222\n12     -1.651689926\n13     -1.644850631\n14     -1.638011335\n15     -1.631172039\n16     -1.624332743\n17     -1.617493448\n18     -1.610654152\n19     -1.603814856\n20     -1.596975560\n21     -1.590136264\n22     -1.583296969\n23     -1.576457673\n24     -1.569618377\n25     -1.562779081\n26     -1.555939786\n27     -1.549100490\n28     -1.542261194\n29     -1.535421898\n30     -1.528582603\n31     -1.521743307\n32     -1.514904011\n33     -1.508064715\n34     -1.501225420\n35     -1.494386124\n36     -1.487546828\n37     -1.480707532\n38     -1.473868237\n39     -1.467028941\n40     -1.460189645\n41     -1.453350349\n42     -1.446511053\n43     -1.439671758\n44     -1.432832462\n45     -1.425993166\n46     -1.419153870\n47     -1.412314575\n48     -1.405475279\n49     -1.398635983\n50     -1.391796687\n51     -1.384957392\n52     -1.378118096\n53     -1.371278800\n54     -1.364439504\n55     -1.357600209\n56     -1.350760913\n57     -1.343921617\n58     -1.337082321\n59     -1.330243026\n60     -1.323403730\n61     -1.316564434\n62     -1.309725138\n63     -1.302885842\n64     -1.296046547\n65     -1.289207251\n66     -1.282367955\n67     -1.275528659\n68     -1.268689364\n69     -1.261850068\n70     -1.255010772\n71     -1.248171476\n72     -1.241332181\n73     -1.234492885\n74     -1.227653589\n75     -1.220814293\n76     -1.213974998\n77     -1.207135702\n78     -1.200296406\n79     -1.193457110\n80     -1.186617815\n81     -1.179778519\n82     -1.172939223\n83     -1.166099927\n84     -1.159260632\n85     -1.152421336\n86     -1.145582040\n87     -1.138742744\n88     -1.131903448\n89     -1.125064153\n90     -1.118224857\n91     -1.111385561\n92     -1.104546265\n93     -1.097706970\n94     -1.090867674\n95     -1.084028378\n96     -1.077189082\n97     -1.070349787\n98     -1.063510491\n99     -1.056671195\n100    -1.049831899\n101    -1.042992604\n102    -1.036153308\n103    -1.029314012\n104    -1.022474716\n105    -1.015635421\n106    -1.008796125\n107    -1.001956829\n108    -0.995117533\n109    -0.988278237\n110    -0.981438942\n111    -0.974599646\n112    -0.967760350\n113    -0.960921054\n114    -0.954081759\n115    -0.947242463\n116    -0.940403167\n117    -0.933563871\n118    -0.926724576\n119    -0.919885280\n120    -0.913045984\n121    -0.906206688\n122    -0.899367393\n123    -0.892528097\n124    -0.885688801\n125    -0.878849505\n126    -0.872010210\n127    -0.865170914\n128    -0.858331618\n129    -0.851492322\n130    -0.844653027\n131    -0.837813731\n132    -0.830974435\n133    -0.824135139\n134    -0.817295843\n135    -0.810456548\n136    -0.803617252\n137    -0.796777956\n138    -0.789938660\n139    -0.783099365\n140    -0.776260069\n141    -0.769420773\n142    -0.762581477\n143    -0.755742182\n144    -0.748902886\n145    -0.742063590\n146    -0.735224294\n147    -0.728384999\n148    -0.721545703\n149    -0.714706407\n150    -0.707867111\n151    -0.701027816\n152    -0.694188520\n153    -0.687349224\n154    -0.680509928\n155    -0.673670632\n156    -0.666831337\n157    -0.659992041\n158    -0.653152745\n159    -0.646313449\n160    -0.639474154\n161    -0.632634858\n162    -0.625795562\n163    -0.618956266\n164    -0.612116971\n165    -0.605277675\n166    -0.598438379\n167    -0.591599083\n168    -0.584759788\n169    -0.577920492\n170    -0.571081196\n171    -0.564241900\n172    -0.557402605\n173    -0.550563309\n174    -0.543724013\n175    -0.536884717\n176    -0.530045421\n177    -0.523206126\n178    -0.516366830\n179    -0.509527534\n180    -0.502688238\n181    -0.495848943\n182    -0.489009647\n183    -0.482170351\n184    -0.475331055\n185    -0.468491760\n186    -0.461652464\n187    -0.454813168\n188    -0.447973872\n189    -0.441134577\n190    -0.434295281\n191    -0.427455985\n192    -0.420616689\n193    -0.413777394\n194    -0.406938098\n195    -0.400098802\n196    -0.393259506\n197    -0.386420211\n198    -0.379580915\n199    -0.372741619\n200    -0.365902323\n201    -0.359063027\n202    -0.352223732\n203    -0.345384436\n204    -0.338545140\n205    -0.331705844\n206    -0.324866549\n207    -0.318027253\n208    -0.311187957\n209    -0.304348661\n210    -0.297509366\n211    -0.290670070\n212    -0.283830774\n213    -0.276991478\n214    -0.270152183\n215    -0.263312887\n216    -0.256473591\n217    -0.249634295\n218    -0.242795000\n219    -0.235955704\n220    -0.229116408\n221    -0.222277112\n222    -0.215437816\n223    -0.208598521\n224    -0.201759225\n225    -0.194919929\n226    -0.188080633\n227    -0.181241338\n228    -0.174402042\n229    -0.167562746\n230    -0.160723450\n231    -0.153884155\n232    -0.147044859\n233    -0.140205563\n234    -0.133366267\n235    -0.126526972\n236    -0.119687676\n237    -0.112848380\n238    -0.106009084\n239    -0.099169789\n240    -0.092330493\n241    -0.085491197\n242    -0.078651901\n243    -0.071812605\n244    -0.064973310\n245    -0.058134014\n246    -0.051294718\n247    -0.044455422\n248    -0.037616127\n249    -0.030776831\n250    -0.023937535\n251    -0.017098239\n252    -0.010258944\n253    -0.003419648\n254     0.003419648\n255     0.010258944\n256     0.017098239\n257     0.023937535\n258     0.030776831\n259     0.037616127\n260     0.044455422\n261     0.051294718\n262     0.058134014\n263     0.064973310\n264     0.071812605\n265     0.078651901\n266     0.085491197\n267     0.092330493\n268     0.099169789\n269     0.106009084\n270     0.112848380\n271     0.119687676\n272     0.126526972\n273     0.133366267\n274     0.140205563\n275     0.147044859\n276     0.153884155\n277     0.160723450\n278     0.167562746\n279     0.174402042\n280     0.181241338\n281     0.188080633\n282     0.194919929\n283     0.201759225\n284     0.208598521\n285     0.215437816\n286     0.222277112\n287     0.229116408\n288     0.235955704\n289     0.242795000\n290     0.249634295\n291     0.256473591\n292     0.263312887\n293     0.270152183\n294     0.276991478\n295     0.283830774\n296     0.290670070\n297     0.297509366\n298     0.304348661\n299     0.311187957\n300     0.318027253\n301     0.324866549\n302     0.331705844\n303     0.338545140\n304     0.345384436\n305     0.352223732\n306     0.359063027\n307     0.365902323\n308     0.372741619\n309     0.379580915\n310     0.386420211\n311     0.393259506\n312     0.400098802\n313     0.406938098\n314     0.413777394\n315     0.420616689\n316     0.427455985\n317     0.434295281\n318     0.441134577\n319     0.447973872\n320     0.454813168\n321     0.461652464\n322     0.468491760\n323     0.475331055\n324     0.482170351\n325     0.489009647\n326     0.495848943\n327     0.502688238\n328     0.509527534\n329     0.516366830\n330     0.523206126\n331     0.530045421\n332     0.536884717\n333     0.543724013\n334     0.550563309\n335     0.557402605\n336     0.564241900\n337     0.571081196\n338     0.577920492\n339     0.584759788\n340     0.591599083\n341     0.598438379\n342     0.605277675\n343     0.612116971\n344     0.618956266\n345     0.625795562\n346     0.632634858\n347     0.639474154\n348     0.646313449\n349     0.653152745\n350     0.659992041\n351     0.666831337\n352     0.673670632\n353     0.680509928\n354     0.687349224\n355     0.694188520\n356     0.701027816\n357     0.707867111\n358     0.714706407\n359     0.721545703\n360     0.728384999\n361     0.735224294\n362     0.742063590\n363     0.748902886\n364     0.755742182\n365     0.762581477\n366     0.769420773\n367     0.776260069\n368     0.783099365\n369     0.789938660\n370     0.796777956\n371     0.803617252\n372     0.810456548\n373     0.817295843\n374     0.824135139\n375     0.830974435\n376     0.837813731\n377     0.844653027\n378     0.851492322\n379     0.858331618\n380     0.865170914\n381     0.872010210\n382     0.878849505\n383     0.885688801\n384     0.892528097\n385     0.899367393\n386     0.906206688\n387     0.913045984\n388     0.919885280\n389     0.926724576\n390     0.933563871\n391     0.940403167\n392     0.947242463\n393     0.954081759\n394     0.960921054\n395     0.967760350\n396     0.974599646\n397     0.981438942\n398     0.988278237\n399     0.995117533\n400     1.001956829\n401     1.008796125\n402     1.015635421\n403     1.022474716\n404     1.029314012\n405     1.036153308\n406     1.042992604\n407     1.049831899\n408     1.056671195\n409     1.063510491\n410     1.070349787\n411     1.077189082\n412     1.084028378\n413     1.090867674\n414     1.097706970\n415     1.104546265\n416     1.111385561\n417     1.118224857\n418     1.125064153\n419     1.131903448\n420     1.138742744\n421     1.145582040\n422     1.152421336\n423     1.159260632\n424     1.166099927\n425     1.172939223\n426     1.179778519\n427     1.186617815\n428     1.193457110\n429     1.200296406\n430     1.207135702\n431     1.213974998\n432     1.220814293\n433     1.227653589\n434     1.234492885\n435     1.241332181\n436     1.248171476\n437     1.255010772\n438     1.261850068\n439     1.268689364\n440     1.275528659\n441     1.282367955\n442     1.289207251\n443     1.296046547\n444     1.302885842\n445     1.309725138\n446     1.316564434\n447     1.323403730\n448     1.330243026\n449     1.337082321\n450     1.343921617\n451     1.350760913\n452     1.357600209\n453     1.364439504\n454     1.371278800\n455     1.378118096\n456     1.384957392\n457     1.391796687\n458     1.398635983\n459     1.405475279\n460     1.412314575\n461     1.419153870\n462     1.425993166\n463     1.432832462\n464     1.439671758\n465     1.446511053\n466     1.453350349\n467     1.460189645\n468     1.467028941\n469     1.473868237\n470     1.480707532\n471     1.487546828\n472     1.494386124\n473     1.501225420\n474     1.508064715\n475     1.514904011\n476     1.521743307\n477     1.528582603\n478     1.535421898\n479     1.542261194\n480     1.549100490\n481     1.555939786\n482     1.562779081\n483     1.569618377\n484     1.576457673\n485     1.583296969\n486     1.590136264\n487     1.596975560\n488     1.603814856\n489     1.610654152\n490     1.617493448\n491     1.624332743\n492     1.631172039\n493     1.638011335\n494     1.644850631\n495     1.651689926\n496     1.658529222\n497     1.665368518\n498     1.672207814\n499     1.679047109\n500     1.685886405\n501     1.692725701\n502     1.699564997\n503     1.706404292\n504     1.713243588\n505     1.720082884\n506     1.726922180\n\n\n\n# Set seed to ensure reproducibility\nset.seed(123)  \n\ntrain &lt;- df %&gt;% sample_frac(.75)\ntest  &lt;- anti_join(df, train, by = 'ID') \n\n\nmodel_std &lt;- lm(medv ~ standardized_rm + standardized_crim + neighborhood, data = train)\nsummary(model_std)\n\n\nCall:\nlm(formula = medv ~ standardized_rm + standardized_crim + neighborhood, \n    data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.920  -3.167  -0.468   2.746  35.052 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          21.61103    0.52360  41.274  &lt; 2e-16 ***\nstandardized_rm       5.36213    0.34514  15.536  &lt; 2e-16 ***\nstandardized_crim    -1.96504    0.30317  -6.482 2.86e-10 ***\nneighborhoodSuburban  0.07995    0.75050   0.107    0.915    \nneighborhoodUrban     3.66323    0.84058   4.358 1.70e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.183 on 375 degrees of freedom\nMultiple R-squared:  0.5573,    Adjusted R-squared:  0.5525 \nF-statistic:   118 on 4 and 375 DF,  p-value: &lt; 2.2e-16\n\n\nAll significance observations stay the same since scaling can never affect that. The size of the coefficients will usually change since the range of the predictor (that they are multiplied with in the formula) has changed, but their direction stays the same. Now a house with the average number of rooms (rm == 0) costs 21k.",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 5 - Solution"
    ]
  },
  {
    "objectID": "solutions/solution5.html#part-2-logistic-regression",
    "href": "solutions/solution5.html#part-2-logistic-regression",
    "title": "Exercise 5 - Solutions",
    "section": "Part 2: Logistic regression",
    "text": "Part 2: Logistic regression",
    "crumbs": [
      "Course Material",
      "Solutions",
      "Exercise 5 - Solution"
    ]
  }
]
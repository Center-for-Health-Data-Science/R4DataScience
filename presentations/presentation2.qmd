---
title: "Presentation 2: Summary Statistics and Data Wrangling"
format: html
project:
 type: website
 output-dir: ../docs
---

Now that we've cleaned our data, it’s time to dig deeper into the actual contents of our dataset. Lets do some Exploratory Data Analysis (EDA). It is an essential step in any data analysis or modeling workflow.

## Load Packages and Data

Let’s begin by loading the packages we’ll need for data wrangling and plotting:

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(factoextra)
# library(ggforce) 
```

Next, bring in the cleaned dataset we prepared earlier:

```{r message=FALSE}
load("../data/Ovarian_comb_clean.RData")

# Check the structure and first few rows
class(df_comb)
df_comb %>% slice(1:5)

df_comb <- df_comb %>%
  select(-percent_not_cancer_cells)
```

## Data Overview and `ggplot2` Recap

Depending on how we want to investigate the variables, there are many ways in EDA toolkit to explore variables:

-   Use histograms or boxplots for single variables

-   Use scatterplots or barplots to check relationships between variables

Let’s revisit some of the variables. This is also a good chance to refresh your **ggplot2** skills. If you need a detailed refresher, refer to the [From Excel to R: Presentation 3](https://center-for-health-data-science.github.io/FromExceltoR/Presentations/presentation3.html).

```{r warning=FALSE}
# Distribution of tumor cell percentage
ggplot(df_comb, 
       aes(x = percent_tumor_cells)) +
  geom_histogram(bins = 30, fill="#482878FF") +
  theme_bw()

# Tumor percentage by summary grade
ggplot(df_comb, 
       aes(x = grade, 
           y = percent_tumor_cells, 
           fill = grade)) +
  geom_boxplot() +
  theme_bw() + 
  scale_fill_viridis_d(na.value = "gray90")

# Count with barplot
ggplot(df_comb, 
       aes(x = grade, 
           fill = grade)) +
  geom_bar() +
  theme_bw() + 
  scale_fill_viridis_d(na.value = "gray90")
```

These simple plots give us an initial overview of the distribution of some of the variables - on their own and stratified by groups.

### Pipe into `ggplot` and save the object

Tired of cluttering your environment with dozens of intermediate data frames? There’s a solution: you can pipe (`%>%`) your filtered data directly into `ggplot()` without saving it first. When you do this, you don’t need to specify the `data = ...` argument inside `ggplot()` — the data is being *piped* into the function automatically.

```{r warning=FALSE}
awesome_plot <-  df_comb %>%
  filter(sample_recode  == "Tumor") %>%
  ggplot(aes(x = COL10A1, 
             y = COL11A1, 
             color = summarygrade)) + 
  geom_point() +
  scale_color_viridis_d(na.value = "gray90") +
  theme_bw()
```

Just like data frames, `ggplot` plots are R objects. You can assign them to variables and display them later:

```{r}
print(awesome_plot)
```

## Formats: long and wide

Now, let’s say we want to create a single plot and compare several **COL gene expression levels** across different categories.

To plot and analyze more effectively, we need to reshape the data into **long format**, where each row represents a single observation:

The data can be reformatted to long format using `pivot_longer()`:

```{r}
df_comb_long <- df_comb %>% 
  pivot_longer(cols = starts_with('COL1'),
               names_to = "gene",
               values_to = "value")

df_comb_long %>% select(unique_patient_ID, age_at_initial_path_diagn, gene, value) %>% head() 
```

```{r}
# one line per gene per person
nrow(df_comb)
nrow(df_comb_long)
```

### The Long Format is ggplot’s Best Friend

With the reshaped `df_comb_long`, we can now create one **combined plot** that shows distributions for **all genes** in **a single** `ggplot` call. More context: add color-stratification by `summarygrade` and compare distributions side-by-side:

```{r}
ggplot(na.omit(df_comb_long), 
       aes(x = gene, y = value, fill = summarygrade)) +
  geom_boxplot() +
  scale_fill_viridis_d() + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

Want histograms for all genes?

```{r}
ggplot(df_comb_long, 
       aes(x = value, fill = gene)) +
  geom_histogram(bins = 30) +
  facet_wrap(vars(gene), nrow = 3) + 
  scale_fill_viridis_d() + 
  theme_minimal()
```

This plot gives us a histogram for each gene, all in one go.

-   No need to write separate plots manually.

-   Much easier to compare variables side-by-side.

### Pivot back into wide format

The `pivot_wider` function is used to transform data to wide format.

```{r eval=FALSE}
df_comb_wide <- df_comb_long %>% 
  pivot_wider(names_from = gene, 
              values_from = value)

head(df_comb_wide)
head(df_comb)
```

## Exploring Factors (Categorical Variables)

When working with factor variables, we often want to know:

-   Which **levels** (categories) exist

-   Whether groups are **balanced**

-   How **missing** **data** overlaps

Let's have a look at the `vital_status` variable. It looks fairly balanced.

```{r}
table(df_comb$vital_status, useNA = "ifany")
```

Now, let's see how the `vital_status` levels are distributed across the `tumorstage` levels.

```{r}
table(df_comb$vital_status, df_comb$stage, useNA = "ifany")
```

Some stage categories could be merged for more power and clearer groups:

```{r}
# Relabel factor levels
df_comb <- df_comb %>%
  mutate(stage = fct_recode(stage,
                            "1" = "1-b",
                            "1" = "1-c",
                            "2" = "2-b",
                            "2" = "2-c",
                            "4" = "4-NA",
                            NULL = "NA-NA"))
```

Let’s see how other categorical variables relate to `vital_status`:

```{r}
# Plot faceted bar plots colored by vital_status

df_comb %>% 
  select(where(is.factor), vital_status) %>% 
  drop_na() %>% 
  pivot_longer(cols = -vital_status, names_to = "variable", values_to = "value") %>% 
  ggplot(aes(x = value, fill = vital_status)) +
  geom_bar() +
  facet_wrap(vars(variable), scales = "free_x") +
  scale_fill_viridis_d() +
  theme_minimal() 
```

After reviewing our categorical variables, we observed the following:

-   **`Tumorstage` and `grade`** are unbalanced. With certain stages and grades (e.g., 1 or 4) having low sample counts. This limits our ability to make reliable comparisons across all detailed levels. So we may combine levels into broader groups.

-   **`Batch` is evenly represented**, which reduces concerns about batch effects.

<!-- -->

-   **`Vital_status` is nicely balanced** making it well-suited for comparisons and modeling.

These insights help us design our downstream analysis in a statistically sound and interpretable way.

## Summary Statistics

Even after initial data cleaning and harmonization, it’s important to make sure our variables are well-behaved and ready for downstream analysis and modeling.

For this, let’s say we want to compute the mean of several columns. A basic (but tedious) approach might look like this:

```{r}
df_comb %>%
  summarise(mean_COL10A1 = mean(COL10A1),
            mean_COL11A1 = mean(COL11A1),
            mean_COL13A1 = mean(COL13A1),
            mean_COL17A1 = mean(COL17A1),
            mean_age_at_diagn = mean(age_at_initial_path_diagn))
```

This works, but we need to name every column we want to apply `summarise` to. It’s verbose and error-prone — especially if you have dozens of variables.

Instead of looking at individual variable, we’ll introduce some tidyverse helper functions: `across()`, `where()`and `starts_with()` - that make summarizing variables much more efficient and scalable — so you don’t have to write repetitive code for every column.

These helpers are useful when we want to apply a functions, i.e. `summarise()` or `mutate()` to several columns.

### Using `across()` and `everything()` to select columns

Lets select the columns which we want to apply `summarise` **across** in a dynamic fashion:

```{r warning=FALSE, message=FALSE}
df_comb %>%
  summarise(across(.cols = everything(), # Columns to run fuction on 
                   .fns = mean)) %>% # Function 
  select(15:25)
```

### Using `where()` and `starts_with()` to select numeric columns

We will probably not want to calculate means on non-numeric columns, so let's select only numeric columns. For that we need another helper caller `where()` that lets us select columns based on their properties, like data type.

```{r}
df_comb %>%
  summarise(across(.cols = where(fn = is.numeric), # fn is a function that returns TRUE or FALSE
                   .fns = mean)) %>% 
  select(5:15)
```

We can use `starts_with()` to select only columns starting with 'COL':

```{r}
# Columns that start with "COL"
df_comb %>%
  summarise(across(starts_with('COL'), mean))
```

These helpers make your code cleaner, more scalable, and easier to maintain. They can be used to select columns in tidyverse, also outside of `across()`.

### `summarise()` becomes more powerful!

So far, we've only applied a single function. But why stop at the mean? What if you want **multiple statistics** like mean, SD, min, and max - all in one go?

With `across()`, you can pass a **list of functions**:

```{r}
df_comb %>%
  summarise(across(.cols = starts_with("COL"), 
                   .fns = list(mean, sd, min, max)))
```

This gives you one wide row per column, with new columns like `COL10A1_1`, `COL11A1_2`, etc. A bit cryptic, right?

Let’s clean it up by naming the functions and columns:

```{r}
gene_summary <- df_comb %>%
  summarise(across(.cols = starts_with("COL"), 
                   .fns = list(mean = mean, 
                               sd = sd, 
                               min = min, 
                               max = max),
                   .names = "{.col}-{.fn}"))

gene_summary
```

Much better! Now the column names are readable and include both the variable and the statistic.

But still not your preferred format? You can probably pivot your way out of that!

```{r}
gene_summary %>%
  pivot_longer(cols = everything(), 
               names_to = c("gene", "statistic"), 
               names_sep = "-") %>%
  pivot_wider(names_from = statistic, 
              values_from = value)
```

Now you get a long format table with one row per variable and all your stats in columns — clean, tidy, and ready for interpretation.

![](../figures/satisfying_meme.jpg){fig-align="center" width="200"}

### The anonymous function: `~` and `.`

We promised to get back to handling the `NA`s when doing summary stats. Let's just add the `na.rm=TRUE` argument. To not have too many things going on at once we'll only do `mean()` for now:

```{r error=TRUE}
df_comb %>%
  summarise(across(.cols = where(is.numeric), 
                   .fns = list(mean = mean(na.rm = TRUE)),
                   .names = "{.col}-{.fn}"))
```

Brrrtt! We may not.

Why doesn’t this work?

When you pass functions directly into `across()` using the **shorthand syntax** (`mean`, `sd`, etc.), you're only allowed to use the **bare function with default arguments**. You will also notice that we didn't use brackets after their names, which is part of using the function shorthanded. Once you try to add something like `na.rm = TRUE`, the shorthandness breaks.

To pass arguments to a function that is called inside another function (i.e. calling `mean` inside `summarise`), we need to use what’s called an **anonymous function**. Don't worry — it’s not as scary as it sounds.

It is written as a `~` and looks like this:

```{r}
df_comb %>%
  summarise(across(.cols = where(is.numeric), 
                   .fns = list(mean = ~ mean(., na.rm = TRUE)),
                   .names = "{.col}-{.fn}"))
```

Let’s break it down:

-   `~` to define the function. `~ mean(., na.rm = TRUE)` tells R:\
    *“for each column, compute the mean, ignoring NAs”*

-   `.` is a placeholder for the current column being operated or 'the data previously referred to'. We need to use the `.` because `mean` when called as a proper function needs to have an argument (a vector of numbers) to work on.

Compare it to this:

```{r}
mean(df_comb$age_at_initial_path_diagn, na.rm = TRUE)
```

In both cases, the column must be explicitly passed in and `.` serves that role inside anonymous functions.

### Multiple Summary Statistics with `na.rm = TRUE`

Now let’s compute **several** stats per column, all with `na.rm = TRUE`. Here we chose just the integer columns:

```{r}
stats <- df_comb %>%
  summarise(across(.cols = where(is.integer),
                   .fns = list(mean = ~ mean(., na.rm = TRUE),  
                               sd = ~ sd(., na.rm = TRUE), 
                               min = ~ min(., na.rm = TRUE), 
                               max = ~ max(., na.rm = TRUE)),
                   .names = "{.col}-{.fn}")) %>%
  # add reformating
  pivot_longer(cols = everything(), 
               names_to = c("variable", "statistic"), 
               names_sep = "-") %>%
  mutate(value = round(value, 1)) %>%
  pivot_wider(names_from = statistic, 
              values_from = value) 

print(stats)
```

This produces a tidy table with one row per gene and columns for `mean`, `sd`, `min`, and `max`.

The helper functions can be used in other tidyverse operation such as `mutate` and `select`.

## Handling Outliers

Now that we’ve explored summary statistics, it's time to consider **outliers** — data points that differ markedly from the rest.

Let’s use our tidyverse skills to **calculate some basic stats** and **visualize potential outliers**.

```{r warning=FALSE}
stats <- stats %>% 
  mutate(thr_upper = mean + 2 * sd,
         thr_lower = mean - 2 * sd) %>%
  pivot_longer(cols = c(thr_lower, thr_upper), names_to = "thr_type", values_to = "threshold")

print(stats)

df_comb_longer <- df_comb %>% 
  pivot_longer(cols = where(is.integer),
               names_to = "variable",
               values_to = "value")
```

```{r warning=FALSE}
ggplot(df_comb_longer, 
       aes(x = value)) +
  geom_histogram(bins = 30, fill="#482878FF") +
  geom_vline(data = stats, 
             aes(xintercept = threshold),
             color = "red", linetype = "dashed") +
  facet_wrap(vars(variable), ncol = 3, scales = "free") + 
  theme_minimal()
```

Sometimes, visualizing values in relation to other variables can make potential outliers easier to spot. Below, you’ll notice that a patient with 0% stromal cells and 0% tumor cells likely represents an outlier:

```{r warning=FALSE}
# Bivariate scatter plot colored by stromal cell percentage
ggplot(df_comb, 
       aes(x = percent_tumor_cells, 
           y = percent_stromal_cells, 
           color = percent_normal_cells)) +
  geom_point() + 
  scale_color_viridis_c() +
  theme_bw()
```

We probably want to remove patients where both `percent_tumor_cells` and `percent_stromal_cells` are 0%.

```{r warning=FALSE}
df_comb %>%
  filter(percent_tumor_cells == 0 & percent_stromal_cells == 0)

df_comb <- df_comb %>%
  filter(
    (percent_tumor_cells != 0 | is.na(percent_tumor_cells) & 
            percent_stromal_cells != 0) | is.na(percent_stromal_cells))
```

## Sample vs variable outliers

There are many ways to detect and handle outliers. Instead of checking each variable separately, we can also look at **all samples across multiple variables** to spot unusual patterns.

One useful approach for datasets with many numeric or integer variables is to create a **dendrogram** using **hierarchical clustering**. This helps reveal samples that **stand out** from the rest.

Let´s try it, first, we select all integer columns and drop rows with missing values (they don’t help clustering).

```{r}
df_int <- df_comb %>%
  select(where(is.integer)) %>%
  drop_na()

df_int %>% head()

```

Next, we **scale the data** (details in *Presentation 3*), calculate pairwise distances between all pairs of scaled variables, and run **hierarchical clustering** to build a **dendrogram**.

This tree-like plot helps reveal samples that cluster far from the rest — potential outliers.

```{r}
# Euclidean pairwise distances
df_int_dist <- df_int %>% 
  mutate(across(everything(), scale)) %>%
  dist(., method = 'euclidean')

# Hierarchical clustering with Ward's distance metric
hclust_int <- hclust(df_int_dist, method = 'average')

```

> If the plot is hard to see:
>
> -   Copy-paste the code into the console to open it in the **Plots** pane.
>
> -   Click *Export → Copy to Clipboard***…** and enlarge it as needed.
>
> Or save it as a high-resolution file and inspect it outside RStudio.

```{r warning=FALSE}
# Plot the result of clustering
# png("dendrogram_plot.png", width = 2000, height = 500)
# plot(hclust_int, main = "Clustering based on scaled integer values", cex = 0.7)
# dev.off()
fviz_dend(hclust_int, h = 10)
```

From the dendrogram, we can see a few samples that branch off far from the main cluster — these long **branch lengths (Height)** may indicate outliers.

Let’s identify samples with unusually large heights and inspect them:

```{r}
# Set a high threshold (top 0.1%)
threshold <- quantile(hclust_int$height, 0.99)
#threshold <- 4
# Find their order in the clustering
ord_inx <- hclust_int$order[hclust_int$height > threshold]
ord_inx
# See which samples they are
df_int %>% slice(ord_inx)
```

Next, we’ll bring back our **summary statistics table** to see whether these measurements fall outside what’s typical for the dataset.

```{r}
stats
```

Now we can compare these flagged samples to our summary statistics to understand why they stand out - and decide if they should be removed.

For these samples:

-   Age at diagnosis and days to death are within a normal range.

-   However, percent stromal cells and percent tumor cells are unusually low.

-   These samples have uncharacteristically high normal cell proportions, which is extreme for this dataset.

Given that they show extreme values across several key variables, it’s reasonable to treat them as outliers and remove them to avoid bias in our analysis.

```{r}
df_comb <- df_comb %>%
  filter(!(
    (percent_normal_cells == 30 & days_to_death == 3622) |
      (percent_normal_cells == 40 & days_to_death == 2621) |
      (percent_normal_cells == 50 & days_to_death == 506) |
      (percent_normal_cells == 35 & days_to_death == 1354) |
      (percent_normal_cells == 30 & days_to_death == 192)
  ) |
    is.na(percent_normal_cells) | is.na(days_to_death))

```

> **Be cautious when removing data**: Outlier removal should always be guided by domain knowledge and clear justification. Removing too much — or for the wrong reasons — can distort your analysis.

## Handling Missing Data

Missing data is common in most real-world datasets and can significantly affect the quality of our analysis. During EDA, it's essential to **identify**, **understand**, and **properly handle** missing values to avoid biased or misleading conclusions.

Let’s inspect rows with the most missing values:

```{r}
df_comb %>%
  mutate(na_count = rowSums(is.na(.))) %>%
  arrange(desc(na_count)) %>%
  slice_head(n = 10)
```

Looking at our missing values, we see that most missingness comes from samples labeled as `Healthy`(`sample_recode`).

This makes sense: Healthy tissue lacks tumor-specific details like **tumor stage** or **percent tumor cells**. This is an example of MAR (Missing At Random) — the missingness is related to an observed category (healthy vs. tumor tissue).

Since our focus is on tumor samples, not healthy tissue (few samples), we can remove these samples to clean up our data and avoid noise.

```{r}
df_comb <- df_comb %>% filter(sample_recode == "Tumor")

# Let’s inspect rows with the most missing values again.
df_comb %>%
  mutate(na_count = rowSums(is.na(.))) %>%
  arrange(desc(na_count)) %>%
  slice_head(n = 10)
```

There are two main approaches when deciding what to do:

-   **Remove rows** with missing values

-   **Impute values**

In our case:

We’ll replace numeric missing values with the median of each variable. We’ll replace missing factor levels with the most common category.

```{r}
df_comb <- df_comb %>%
  mutate(across(
    c(
      percent_normal_cells,
      percent_stromal_cells,
      percent_tumor_cells,
      age_at_initial_path_diagn,
      days_to_death,
      days_to_tumor_recurrence
    ),
    ~ if_else(is.na(.x), as.integer(median(.x, na.rm = TRUE)), as.integer(.x))
  ))

df_comb <- df_comb %>%
  mutate(across(
    c(stage, grade),
    ~ fct_explicit_na(.x, na_level = names(sort(table(.x), decreasing = TRUE))[1])
  ))
```

We’ll keep the remaining `NA`s as-is for now.

> However always consider the impact of missing data. Even after imputing, missing data can cause uncertainty and bias so understands the result with caution.

<br>

### In Summary

We conducted an initial **exploratory data analysis (EDA)** and, overall, the dataset looks clean and well-structured.

-   **Reshaped data** — switched between wide and long formats to easily plot multiple variables together.

-   **Checked factors** — reviewed category balance, merged sparse groups, and visualized how factors relate.

-   **Generated and inspected summary statistics** — used tidyverse helpers to calculate means, standard deviations, and more for many columns at once, confirming that values align with biological expectations.

-   **Detected and removed outliers** — used clustering to identify and exclude extreme or inconsistent samples with unusually high normal cell content.

-   **Handled missing data thoughtfully** — removed irrelevant samples and imputed remaining gaps where appropriate.

<br>

### Key Takeaways

-   Long format is your best friend when plotting or modeling.

-   Use `across()` and helpers to write clean, scalable summaries.

-   Visual checks are as important as statistical checks.

-   EDA is not optional — it’s the foundation of trustworthy analysis.

-   Keep your workflow reproducible and tidy for future modeling stages.

```{r}
save(df_comb, file="../data/Ovarian_comb_prep_Col.RData")
```
